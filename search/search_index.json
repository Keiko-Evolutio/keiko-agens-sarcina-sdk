{"config":{"lang":["de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"KEI-Agent Python SDK","text":"<p>Willkommen zur offiziellen Dokumentation des KEI-Agent Python SDK - einem Enterprise-Grade Framework f\u00fcr Multi-Agent-Systeme mit umfassender Protokoll-Unterst\u00fctzung.</p>"},{"location":"#uberblick","title":"\ud83d\ude80 \u00dcberblick","text":"<p>Das KEI-Agent Python SDK bietet eine einheitliche, typisierte API f\u00fcr die Entwicklung von intelligenten Agenten mit Unterst\u00fctzung f\u00fcr:</p> <ul> <li>Multi-Protocol Support: KEI-RPC, KEI-Stream, KEI-Bus und KEI-MCP</li> <li>Enterprise Security: Umfassende Authentifizierung und Input-Validierung</li> <li>Production Monitoring: Structured Logging und Health Checks</li> <li>Developer Experience: Vollst\u00e4ndige Type Hints und deutsche Dokumentation</li> <li>High Availability: Automatische Fallback-Mechanismen und Circuit Breaker</li> </ul>"},{"location":"#quick-start","title":"\u26a1 Quick Start","text":"<pre><code>from kei_agent import UnifiedKeiAgentClient, AgentClientConfig\n\n# Konfiguration\nconfig = AgentClientConfig(\n    base_url=\"https://api.kei-framework.com\",\n    api_token=\"your-api-token\",\n    agent_id=\"my-agent\"\n)\n\n# Client verwenden\nasync with UnifiedKeiAgentClient(config=config) as client:\n    # Plan erstellen\n    plan = await client.plan_task(\"Erstelle einen Quartalsbericht\")\n\n    # Aktion ausf\u00fchren\n    result = await client.execute_action(\"generate_report\", {\n        \"format\": \"pdf\",\n        \"quarter\": \"Q4-2024\"\n    })\n\n    # Health Check\n    health = await client.health_check()\n    print(f\"System Status: {health['status']}\")\n</code></pre>"},{"location":"#architektur-highlights","title":"\ud83c\udfd7\ufe0f Architektur-Highlights","text":""},{"location":"#refactored-design","title":"Refactored Design","text":"<p>Das SDK wurde vollst\u00e4ndig refactored f\u00fcr Enterprise-Einsatz:</p> <ul> <li>Clean Code: Alle Module \u2264200 Zeilen, Funktionen \u226420 Zeilen</li> <li>Type Safety: 100% Type Hints f\u00fcr alle APIs</li> <li>Modularity: Klare Trennung von Protokoll-Clients, Security und Utilities</li> <li>Testability: 85%+ Test-Coverage mit deterministischen Tests</li> </ul>"},{"location":"#multi-protocol-architecture","title":"Multi-Protocol Architecture","text":"<pre><code>graph TB\n    subgraph \"KEI-Agent SDK\"\n        UC[UnifiedKeiAgentClient]\n        PS[ProtocolSelector]\n\n        subgraph \"Protocol Clients\"\n            RPC[KEI-RPC&lt;br/&gt;Sync Operations]\n            STREAM[KEI-Stream&lt;br/&gt;Real-time]\n            BUS[KEI-Bus&lt;br/&gt;Async Messages]\n            MCP[KEI-MCP&lt;br/&gt;Tool Integration]\n        end\n\n        subgraph \"Enterprise Features\"\n            LOG[Structured Logging]\n            HEALTH[Health Checks]\n            VALID[Input Validation]\n            SEC[Security Manager]\n        end\n    end\n\n    UC --&gt; PS\n    PS --&gt; RPC\n    PS --&gt; STREAM\n    PS --&gt; BUS\n    PS --&gt; MCP\n    UC --&gt; LOG\n    UC --&gt; HEALTH\n    UC --&gt; VALID\n    UC --&gt; SEC</code></pre>"},{"location":"#hauptfeatures","title":"\ud83c\udfaf Hauptfeatures","text":""},{"location":"#multi-protocol-support","title":"\ud83d\udd0c Multi-Protocol Support","text":"<ul> <li>KEI-RPC: Synchrone Request-Response Operationen</li> <li>KEI-Stream: Bidirektionale Real-time Kommunikation</li> <li>KEI-Bus: Asynchrone Message-Bus Integration</li> <li>KEI-MCP: Model Context Protocol f\u00fcr Tool-Integration</li> </ul>"},{"location":"#enterprise-security","title":"\ud83d\udee1\ufe0f Enterprise Security","text":"<ul> <li>Multi-Auth: Bearer Token, OIDC, mTLS</li> <li>Input Validation: Umfassende Sanitization und Validierung</li> <li>Audit Logging: Vollst\u00e4ndige Nachverfolgbarkeit</li> <li>RBAC: Role-Based Access Control</li> </ul>"},{"location":"#production-monitoring","title":"\ud83d\udcca Production Monitoring","text":"<ul> <li>Structured Logging: JSON-Format mit Correlation-IDs</li> <li>Health Checks: Database, API, Memory, Custom</li> <li>Performance Metrics: Built-in Timing und Resource-Monitoring</li> <li>Distributed Tracing: OpenTelemetry-Integration</li> </ul>"},{"location":"#developer-experience","title":"\ud83d\udd27 Developer Experience","text":"<ul> <li>Type Safety: Vollst\u00e4ndige Type Hints f\u00fcr IntelliSense</li> <li>Deutsche Dokumentation: Umfassende Guides und API-Referenz</li> <li>Auto-Completion: IDE-Unterst\u00fctzung f\u00fcr alle APIs</li> <li>Error Messages: Klare, actionable Fehlermeldungen</li> </ul>"},{"location":"#dokumentations-navigation","title":"\ud83d\udcda Dokumentations-Navigation","text":""},{"location":"#erste-schritte","title":"Erste Schritte","text":"<ul> <li>Installation - Schritt-f\u00fcr-Schritt Setup</li> <li>Quick Start - Erste Schritte in 5 Minuten</li> <li>Konfiguration - Client-Setup und Optionen</li> </ul>"},{"location":"#benutzerhandbuch","title":"Benutzerhandbuch","text":"<ul> <li>Basis-Konzepte - Grundlagen verstehen</li> <li>Client-Verwendung - Praktische Anwendung</li> <li>Protokolle - Multi-Protocol Features</li> </ul>"},{"location":"#enterprise-features","title":"Enterprise Features","text":"<ul> <li>Structured Logging - Production-Logging</li> <li>Health Checks - System-Monitoring</li> <li>Security - Sicherheits-Features</li> </ul>"},{"location":"#api-referenz","title":"API-Referenz","text":"<ul> <li>Unified Client - Haupt-API-Klasse</li> <li>Protocol Types - Konfigurationen und Enums</li> <li>Enterprise Logging - Logging-APIs</li> </ul>"},{"location":"#migration","title":"\ud83d\udd04 Migration","text":"<p>Migrieren Sie von der Legacy-Version? Unser Migration Guide hilft Ihnen bei einem reibungslosen \u00dcbergang zur neuen Enterprise-Architektur.</p>"},{"location":"#community-support","title":"\ud83e\udd1d Community &amp; Support","text":"<ul> <li>GitHub Repository: kei-framework/kei-agent</li> <li>Issues &amp; Bugs: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>PyPI Package: kei-agent-sdk</li> </ul>"},{"location":"#lizenz","title":"\ud83d\udcc4 Lizenz","text":"<p>Das KEI-Agent Python SDK ist unter der MIT-Lizenz ver\u00f6ffentlicht.</p> <p>Bereit loszulegen? Beginnen Sie mit der Installation oder springen Sie direkt zum Quick Start Guide!</p>"},{"location":"api/","title":"API-Referenz","text":"<p>Vollst\u00e4ndige Referenz aller \u00f6ffentlichen Klassen, Methoden und Funktionen des KEI-Agent Python SDK.</p>"},{"location":"api/#ubersicht","title":"\ud83d\udcda \u00dcbersicht","text":"<p>Das KEI-Agent SDK ist in mehrere Module organisiert, die jeweils spezifische Funktionalit\u00e4ten bereitstellen:</p>"},{"location":"api/#core-module","title":"Core-Module","text":"<ul> <li>UnifiedKeiAgentClient - Haupt-API-Klasse f\u00fcr alle Agent-Operationen</li> <li>ProtocolTypes - Typ-Definitionen und Konfigurationsklassen</li> <li>SecurityManager - Authentifizierung und Token-Management</li> </ul>"},{"location":"api/#protocol-module","title":"Protocol-Module","text":"<ul> <li>ProtocolClients - KEI-RPC, Stream, Bus und MCP Clients</li> <li>ProtocolSelector - Intelligente Protokoll-Auswahl</li> </ul>"},{"location":"api/#enterprise-module","title":"Enterprise-Module","text":"<ul> <li>EnterpriseLogging - Strukturiertes JSON-Logging</li> <li>HealthChecks - System-Monitoring und Health-Checks</li> <li>InputValidation - Input-Validierung und Sanitization</li> </ul>"},{"location":"api/#utility-module","title":"Utility-Module","text":"<ul> <li>Exceptions - SDK-spezifische Exception-Klassen</li> </ul>"},{"location":"api/#quick-reference","title":"\ud83d\ude80 Quick Reference","text":""},{"location":"api/#hauptklassen","title":"Hauptklassen","text":"<pre><code>from kei_agent import (\n    # Core\n    UnifiedKeiAgentClient,\n    AgentClientConfig,\n    ProtocolConfig,\n    SecurityConfig,\n\n    # Enums\n    ProtocolType,\n    AuthType,\n\n    # Enterprise\n    get_logger,\n    get_health_manager,\n    get_input_validator\n)\n</code></pre>"},{"location":"api/#basis-verwendung","title":"Basis-Verwendung","text":"<pre><code># Client erstellen\nconfig = AgentClientConfig(\n    base_url=\"https://api.kei-framework.com\",\n    api_token=\"your-token\",\n    agent_id=\"my-agent\"\n)\n\nasync with UnifiedKeiAgentClient(config=config) as client:\n    # Agent-Operationen\n    plan = await client.plan_task(\"Objective\")\n    result = await client.execute_action(\"action\", {\"param\": \"value\"})\n    health = await client.health_check()\n</code></pre>"},{"location":"api/#modul-details","title":"\ud83d\udcd6 Modul-Details","text":""},{"location":"api/#core-api","title":"Core API","text":"Klasse Beschreibung Dokumentation <code>UnifiedKeiAgentClient</code> Haupt-Client f\u00fcr alle Agent-Operationen Details \u2192 <code>AgentClientConfig</code> Basis-Konfiguration f\u00fcr Client Details \u2192 <code>ProtocolConfig</code> Protokoll-spezifische Konfiguration Details \u2192 <code>SecurityConfig</code> Sicherheitskonfiguration Details \u2192"},{"location":"api/#enums-und-typen","title":"Enums und Typen","text":"Enum/Typ Beschreibung Werte <code>ProtocolType</code> Verf\u00fcgbare Protokolle <code>RPC</code>, <code>STREAM</code>, <code>BUS</code>, <code>MCP</code>, <code>AUTO</code> <code>AuthType</code> Authentifizierungstypen <code>BEARER</code>, <code>OIDC</code>, <code>MTLS</code> <code>HealthStatus</code> Health-Check-Status <code>HEALTHY</code>, <code>DEGRADED</code>, <code>UNHEALTHY</code>, <code>UNKNOWN</code> <code>ValidationSeverity</code> Validierungsschweregrad <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code>"},{"location":"api/#enterprise-features","title":"Enterprise Features","text":"Feature Klasse Beschreibung Logging <code>EnterpriseLogger</code> Strukturiertes JSON-Logging Health Checks <code>HealthCheckManager</code> System-Monitoring Input Validation <code>InputValidator</code> Sichere Input-Verarbeitung Security <code>SecurityManager</code> Authentifizierung und Tokens"},{"location":"api/#suchindex","title":"\ud83d\udd0d Suchindex","text":""},{"location":"api/#nach-funktionalitat","title":"Nach Funktionalit\u00e4t","text":""},{"location":"api/#agent-operationen","title":"Agent-Operationen","text":"<ul> <li><code>plan_task()</code> - Plan erstellen</li> <li><code>execute_action()</code> - Aktion ausf\u00fchren</li> <li><code>observe_environment()</code> - Umgebung beobachten</li> <li><code>explain_reasoning()</code> - Reasoning erkl\u00e4ren</li> </ul>"},{"location":"api/#kommunikation","title":"Kommunikation","text":"<ul> <li><code>send_agent_message()</code> - Agent-to-Agent Nachrichten</li> <li><code>start_streaming_session()</code> - Real-time Streaming</li> <li><code>discover_available_tools()</code> - Tool-Discovery</li> <li><code>use_tool()</code> - Tool-Ausf\u00fchrung</li> </ul>"},{"location":"api/#monitoring","title":"Monitoring","text":"<ul> <li><code>health_check()</code> - System-Health pr\u00fcfen</li> <li><code>get_client_info()</code> - Client-Informationen</li> <li><code>get_available_protocols()</code> - Verf\u00fcgbare Protokolle</li> </ul>"},{"location":"api/#konfiguration","title":"Konfiguration","text":"<ul> <li><code>initialize()</code> - Client initialisieren</li> <li><code>close()</code> - Client schlie\u00dfen</li> <li><code>is_protocol_available()</code> - Protokoll-Verf\u00fcgbarkeit</li> </ul>"},{"location":"api/#nach-modul","title":"Nach Modul","text":""},{"location":"api/#kei_agentunified_client_refactored","title":"kei_agent.unified_client_refactored","text":"<ul> <li><code>UnifiedKeiAgentClient</code> - Haupt-Client-Klasse</li> </ul>"},{"location":"api/#kei_agentprotocol_types","title":"kei_agent.protocol_types","text":"<ul> <li><code>ProtocolType</code> - Protokoll-Enum</li> <li><code>AuthType</code> - Authentifizierungs-Enum</li> <li><code>AgentClientConfig</code> - Client-Konfiguration</li> <li><code>ProtocolConfig</code> - Protokoll-Konfiguration</li> <li><code>SecurityConfig</code> - Sicherheitskonfiguration</li> </ul>"},{"location":"api/#kei_agententerprise_logging","title":"kei_agent.enterprise_logging","text":"<ul> <li><code>EnterpriseLogger</code> - Logging-Klasse</li> <li><code>LogContext</code> - Logging-Kontext</li> <li><code>StructuredFormatter</code> - JSON-Formatter</li> <li><code>get_logger()</code> - Logger-Factory</li> <li><code>configure_logging()</code> - Logging-Konfiguration</li> </ul>"},{"location":"api/#kei_agenthealth_checks","title":"kei_agent.health_checks","text":"<ul> <li><code>HealthCheckManager</code> - Health-Check-Manager</li> <li><code>BaseHealthCheck</code> - Basis-Health-Check</li> <li><code>APIHealthCheck</code> - API-Health-Check</li> <li><code>DatabaseHealthCheck</code> - Database-Health-Check</li> <li><code>MemoryHealthCheck</code> - Memory-Health-Check</li> <li><code>get_health_manager()</code> - Manager-Factory</li> </ul>"},{"location":"api/#kei_agentinput_validation","title":"kei_agent.input_validation","text":"<ul> <li><code>InputValidator</code> - Input-Validator</li> <li><code>StringValidator</code> - String-Validierung</li> <li><code>NumberValidator</code> - Zahlen-Validierung</li> <li><code>JSONValidator</code> - JSON-Validierung</li> <li><code>CompositeValidator</code> - Composite-Validierung</li> <li><code>get_input_validator()</code> - Validator-Factory</li> </ul>"},{"location":"api/#verwendungspatterns","title":"\ud83c\udfaf Verwendungspatterns","text":""},{"location":"api/#async-context-manager-pattern","title":"Async Context Manager Pattern","text":"<pre><code>async with UnifiedKeiAgentClient(config) as client:\n    # Automatische Initialisierung und Cleanup\n    result = await client.plan_task(\"objective\")\n</code></pre>"},{"location":"api/#factory-pattern","title":"Factory Pattern","text":"<pre><code># Logger\nlogger = get_logger(\"my_component\")\n\n# Health Manager\nhealth_manager = get_health_manager()\n\n# Input Validator\nvalidator = get_input_validator()\n</code></pre>"},{"location":"api/#configuration-pattern","title":"Configuration Pattern","text":"<pre><code># Modulare Konfiguration\nagent_config = AgentClientConfig(...)\nprotocol_config = ProtocolConfig(...)\nsecurity_config = SecurityConfig(...)\n\nclient = UnifiedKeiAgentClient(\n    config=agent_config,\n    protocol_config=protocol_config,\n    security_config=security_config\n)\n</code></pre>"},{"location":"api/#error-handling-pattern","title":"Error Handling Pattern","text":"<pre><code>from kei_agent.exceptions import KeiSDKError, ProtocolError, SecurityError\n\ntry:\n    async with UnifiedKeiAgentClient(config) as client:\n        result = await client.plan_task(\"objective\")\nexcept SecurityError as e:\n    # Sicherheitsfehler behandeln\n    logger.error(\"Security error\", error=str(e))\nexcept ProtocolError as e:\n    # Protokollfehler behandeln\n    logger.error(\"Protocol error\", error=str(e))\nexcept KeiSDKError as e:\n    # Allgemeine SDK-Fehler behandeln\n    logger.error(\"SDK error\", error=str(e))\n</code></pre>"},{"location":"api/#konventionen","title":"\ud83d\udcdd Konventionen","text":""},{"location":"api/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Klassen: PascalCase (<code>UnifiedKeiAgentClient</code>)</li> <li>Methoden: snake_case (<code>plan_task</code>)</li> <li>Konstanten: UPPER_SNAKE_CASE (<code>PROTOCOL_TYPE</code>)</li> <li>Private Methoden: _snake_case (<code>_execute_with_protocol</code>)</li> </ul>"},{"location":"api/#type-hints","title":"Type Hints","text":"<p>Alle \u00f6ffentlichen APIs haben vollst\u00e4ndige Type Hints:</p> <pre><code>async def plan_task(\n    self,\n    objective: str,\n    context: Optional[Dict[str, Any]] = None,\n    protocol: Optional[ProtocolType] = None\n) -&gt; Dict[str, Any]:\n</code></pre>"},{"location":"api/#docstring-format","title":"Docstring Format","text":"<p>Deutsche Docstrings im Google-Format:</p> <pre><code>def method(self, param: str) -&gt; bool:\n    \"\"\"Kurze Beschreibung der Methode.\n\n    L\u00e4ngere Beschreibung falls n\u00f6tig.\n\n    Args:\n        param: Beschreibung des Parameters\n\n    Returns:\n        Beschreibung des R\u00fcckgabewerts\n\n    Raises:\n        ExceptionType: Beschreibung wann Exception auftritt\n    \"\"\"\n</code></pre> <p>Navigation: - UnifiedKeiAgentClient \u2192 - Haupt-API-Klasse - ProtocolTypes \u2192 - Konfigurationen und Enums - Enterprise Features \u2192 - Production-Features</p>"},{"location":"api/enterprise-logging/","title":"\ud83d\udcdd Enterprise-Logging API","text":"<p>Enterprise-grade Logging-Funktionen f\u00fcr umfassende Audit-Trails und Compliance-Anforderungen.</p>"},{"location":"api/enterprise-logging/#logging-architektur","title":"\ud83c\udfd7\ufe0f Logging-Architektur","text":"<pre><code>graph TB\n    subgraph \"Application Layer\"\n        API[API Endpoints]\n        AGENTS[Agent Services]\n        MCP[MCP Clients]\n    end\n\n    subgraph \"Logging Layer\"\n        STRUCT[Structured Logger]\n        AUDIT[Audit Logger]\n        SECURITY[Security Logger]\n    end\n\n    subgraph \"Processing\"\n        FILTER[Log Filters]\n        ENRICH[Log Enrichment]\n        ROUTE[Log Routing]\n    end\n\n    subgraph \"Storage\"\n        LOCAL[Local Files]\n        SIEM[SIEM Systems]\n        CLOUD[Cloud Storage]\n    end\n\n    API --&gt; STRUCT\n    AGENTS --&gt; AUDIT\n    MCP --&gt; SECURITY\n\n    STRUCT --&gt; FILTER\n    AUDIT --&gt; ENRICH\n    SECURITY --&gt; ROUTE\n\n    FILTER --&gt; LOCAL\n    ENRICH --&gt; SIEM\n    ROUTE --&gt; CLOUD</code></pre>"},{"location":"api/enterprise-logging/#logging-api","title":"\ud83d\udcca Logging-API","text":""},{"location":"api/enterprise-logging/#enterprise-logger-konfiguration","title":"Enterprise-Logger-Konfiguration","text":"<pre><code>import logging\nimport json\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\nfrom enum import Enum\n\nclass LogLevel(Enum):\n    DEBUG = \"DEBUG\"\n    INFO = \"INFO\"\n    WARNING = \"WARNING\"\n    ERROR = \"ERROR\"\n    CRITICAL = \"CRITICAL\"\n\nclass LogCategory(Enum):\n    SYSTEM = \"system\"\n    SECURITY = \"security\"\n    AUDIT = \"audit\"\n    PERFORMANCE = \"performance\"\n    BUSINESS = \"business\"\n\nclass EnterpriseLogger:\n    \"\"\"Enterprise-Logger mit erweiterten Funktionen.\"\"\"\n\n    def __init__(self, service_name: str, version: str):\n        self.service_name = service_name\n        self.version = version\n        self.logger = logging.getLogger(f\"keiko.{service_name}\")\n\n    async def log_event(\n        self,\n        level: LogLevel,\n        category: LogCategory,\n        message: str,\n        details: Optional[Dict[str, Any]] = None,\n        user_id: Optional[str] = None,\n        correlation_id: Optional[str] = None,\n        sensitive_data: bool = False\n    ):\n        \"\"\"Protokolliert Enterprise-Event.\"\"\"\n\n        log_entry = {\n            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n            \"service\": self.service_name,\n            \"version\": self.version,\n            \"level\": level.value,\n            \"category\": category.value,\n            \"message\": message,\n            \"details\": details or {},\n            \"user_id\": user_id,\n            \"correlation_id\": correlation_id,\n            \"sensitive_data\": sensitive_data\n        }\n\n        # Sensitive Daten maskieren\n        if sensitive_data:\n            log_entry = self._mask_sensitive_data(log_entry)\n\n        # Log-Entry ausgeben\n        getattr(self.logger, level.value.lower())(json.dumps(log_entry))\n\n    def _mask_sensitive_data(self, log_entry: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Maskiert sensitive Daten in Log-Entries.\"\"\"\n\n        sensitive_fields = ['password', 'token', 'api_key', 'secret']\n\n        def mask_dict(d: Dict[str, Any]) -&gt; Dict[str, Any]:\n            masked = {}\n            for key, value in d.items():\n                if any(field in key.lower() for field in sensitive_fields):\n                    masked[key] = \"***MASKED***\"\n                elif isinstance(value, dict):\n                    masked[key] = mask_dict(value)\n                else:\n                    masked[key] = value\n            return masked\n\n        if log_entry.get('details'):\n            log_entry['details'] = mask_dict(log_entry['details'])\n\n        return log_entry\n\n# Audit-Logger f\u00fcr Compliance\nclass AuditLogger(EnterpriseLogger):\n    \"\"\"Spezialisierter Audit-Logger f\u00fcr Compliance.\"\"\"\n\n    async def log_user_action(\n        self,\n        user_id: str,\n        action: str,\n        resource: str,\n        result: str,\n        details: Optional[Dict[str, Any]] = None,\n        correlation_id: Optional[str] = None\n    ):\n        \"\"\"Protokolliert Benutzer-Aktionen f\u00fcr Audit-Trail.\"\"\"\n\n        await self.log_event(\n            level=LogLevel.INFO,\n            category=LogCategory.AUDIT,\n            message=f\"User action: {action} on {resource}\",\n            details={\n                \"action\": action,\n                \"resource\": resource,\n                \"result\": result,\n                \"additional_details\": details or {}\n            },\n            user_id=user_id,\n            correlation_id=correlation_id\n        )\n\n    async def log_system_change(\n        self,\n        change_type: str,\n        component: str,\n        old_value: Any,\n        new_value: Any,\n        changed_by: str,\n        correlation_id: Optional[str] = None\n    ):\n        \"\"\"Protokolliert System-\u00c4nderungen.\"\"\"\n\n        await self.log_event(\n            level=LogLevel.WARNING,\n            category=LogCategory.AUDIT,\n            message=f\"System change: {change_type} in {component}\",\n            details={\n                \"change_type\": change_type,\n                \"component\": component,\n                \"old_value\": str(old_value),\n                \"new_value\": str(new_value),\n                \"changed_by\": changed_by\n            },\n            correlation_id=correlation_id\n        )\n\n# Security-Logger f\u00fcr Sicherheitsereignisse\nclass SecurityLogger(EnterpriseLogger):\n    \"\"\"Spezialisierter Security-Logger.\"\"\"\n\n    async def log_authentication_event(\n        self,\n        user_id: str,\n        event_type: str,\n        success: bool,\n        ip_address: str,\n        user_agent: str,\n        details: Optional[Dict[str, Any]] = None\n    ):\n        \"\"\"Protokolliert Authentifizierungs-Ereignisse.\"\"\"\n\n        level = LogLevel.INFO if success else LogLevel.WARNING\n\n        await self.log_event(\n            level=level,\n            category=LogCategory.SECURITY,\n            message=f\"Authentication {event_type}: {'success' if success else 'failure'}\",\n            details={\n                \"event_type\": event_type,\n                \"success\": success,\n                \"ip_address\": ip_address,\n                \"user_agent\": user_agent,\n                \"additional_details\": details or {}\n            },\n            user_id=user_id\n        )\n\n    async def log_security_violation(\n        self,\n        violation_type: str,\n        severity: str,\n        source_ip: str,\n        details: Dict[str, Any],\n        user_id: Optional[str] = None\n    ):\n        \"\"\"Protokolliert Sicherheitsverletzungen.\"\"\"\n\n        level_map = {\n            \"low\": LogLevel.WARNING,\n            \"medium\": LogLevel.ERROR,\n            \"high\": LogLevel.CRITICAL,\n            \"critical\": LogLevel.CRITICAL\n        }\n\n        await self.log_event(\n            level=level_map.get(severity, LogLevel.ERROR),\n            category=LogCategory.SECURITY,\n            message=f\"Security violation: {violation_type}\",\n            details={\n                \"violation_type\": violation_type,\n                \"severity\": severity,\n                \"source_ip\": source_ip,\n                \"violation_details\": details\n            },\n            user_id=user_id\n        )\n</code></pre>"},{"location":"api/enterprise-logging/#log-abfrage-api","title":"\ud83d\udd0d Log-Abfrage-API","text":""},{"location":"api/enterprise-logging/#log-query-endpunkte","title":"Log-Query-Endpunkte","text":"<pre><code>from fastapi import APIRouter, Query, Depends\nfrom typing import List, Optional\nfrom datetime import datetime, timedelta\n\nrouter = APIRouter(prefix=\"/api/v1/logs\", tags=[\"Enterprise Logging\"])\n\n@router.get(\"/audit\")\nasync def get_audit_logs(\n    start_time: Optional[datetime] = Query(None),\n    end_time: Optional[datetime] = Query(None),\n    user_id: Optional[str] = Query(None),\n    action: Optional[str] = Query(None),\n    resource: Optional[str] = Query(None),\n    limit: int = Query(100, le=1000),\n    offset: int = Query(0, ge=0)\n):\n    \"\"\"Ruft Audit-Logs ab.\"\"\"\n\n    # Standard-Zeitraum: letzte 24 Stunden\n    if not start_time:\n        start_time = datetime.utcnow() - timedelta(days=1)\n    if not end_time:\n        end_time = datetime.utcnow()\n\n    # Log-Abfrage implementieren\n    logs = await query_audit_logs(\n        start_time=start_time,\n        end_time=end_time,\n        user_id=user_id,\n        action=action,\n        resource=resource,\n        limit=limit,\n        offset=offset\n    )\n\n    return {\n        \"logs\": logs,\n        \"total\": len(logs),\n        \"start_time\": start_time.isoformat(),\n        \"end_time\": end_time.isoformat()\n    }\n\n@router.get(\"/security\")\nasync def get_security_logs(\n    start_time: Optional[datetime] = Query(None),\n    end_time: Optional[datetime] = Query(None),\n    severity: Optional[str] = Query(None),\n    event_type: Optional[str] = Query(None),\n    source_ip: Optional[str] = Query(None),\n    limit: int = Query(100, le=1000)\n):\n    \"\"\"Ruft Security-Logs ab.\"\"\"\n\n    logs = await query_security_logs(\n        start_time=start_time or datetime.utcnow() - timedelta(hours=1),\n        end_time=end_time or datetime.utcnow(),\n        severity=severity,\n        event_type=event_type,\n        source_ip=source_ip,\n        limit=limit\n    )\n\n    return {\"logs\": logs, \"total\": len(logs)}\n\n@router.get(\"/performance\")\nasync def get_performance_logs(\n    start_time: Optional[datetime] = Query(None),\n    end_time: Optional[datetime] = Query(None),\n    service: Optional[str] = Query(None),\n    min_duration: Optional[float] = Query(None),\n    limit: int = Query(100, le=1000)\n):\n    \"\"\"Ruft Performance-Logs ab.\"\"\"\n\n    logs = await query_performance_logs(\n        start_time=start_time or datetime.utcnow() - timedelta(hours=1),\n        end_time=end_time or datetime.utcnow(),\n        service=service,\n        min_duration=min_duration,\n        limit=limit\n    )\n\n    return {\"logs\": logs, \"total\": len(logs)}\n\n@router.post(\"/export\")\nasync def export_logs(\n    export_request: Dict[str, Any]\n):\n    \"\"\"Exportiert Logs in verschiedenen Formaten.\"\"\"\n\n    format_type = export_request.get(\"format\", \"json\")  # json, csv, xlsx\n    filters = export_request.get(\"filters\", {})\n\n    # Export-Task erstellen\n    export_task_id = await create_log_export_task(format_type, filters)\n\n    return {\n        \"export_task_id\": export_task_id,\n        \"status\": \"initiated\",\n        \"estimated_completion\": datetime.utcnow() + timedelta(minutes=5)\n    }\n</code></pre>"},{"location":"api/enterprise-logging/#log-metriken","title":"\ud83d\udcc8 Log-Metriken","text":""},{"location":"api/enterprise-logging/#logging-metriken","title":"Logging-Metriken","text":"<pre><code>from prometheus_client import Counter, Histogram, Gauge\n\n# Log-Metriken\nLOG_ENTRIES_TOTAL = Counter(\n    'keiko_log_entries_total',\n    'Gesamtanzahl der Log-Entries',\n    ['level', 'category', 'service']\n)\n\nLOG_PROCESSING_TIME = Histogram(\n    'keiko_log_processing_seconds',\n    'Zeit f\u00fcr Log-Verarbeitung',\n    ['category'],\n    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25]\n)\n\nAUDIT_EVENTS_TOTAL = Counter(\n    'keiko_audit_events_total',\n    'Gesamtanzahl der Audit-Events',\n    ['action', 'resource', 'result']\n)\n\nSECURITY_EVENTS_TOTAL = Counter(\n    'keiko_security_events_total',\n    'Gesamtanzahl der Security-Events',\n    ['event_type', 'severity']\n)\n\nLOG_STORAGE_SIZE = Gauge(\n    'keiko_log_storage_bytes',\n    'Gr\u00f6\u00dfe des Log-Storage in Bytes',\n    ['storage_type']\n)\n\ndef monitor_logging(func):\n    \"\"\"Decorator f\u00fcr Logging-Monitoring.\"\"\"\n\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        start_time = time.time()\n\n        try:\n            result = await func(*args, **kwargs)\n\n            # Metriken aufzeichnen\n            if hasattr(result, 'level') and hasattr(result, 'category'):\n                LOG_ENTRIES_TOTAL.labels(\n                    level=result.level,\n                    category=result.category,\n                    service=result.service\n                ).inc()\n\n            return result\n\n        finally:\n            duration = time.time() - start_time\n            category = kwargs.get('category', 'unknown')\n            LOG_PROCESSING_TIME.labels(category=category).observe(duration)\n\n    return wrapper\n</code></pre>"},{"location":"api/enterprise-logging/#log-sicherheit","title":"\ud83d\udd12 Log-Sicherheit","text":""},{"location":"api/enterprise-logging/#sichere-log-verarbeitung","title":"Sichere Log-Verarbeitung","text":"<pre><code>import hashlib\nimport hmac\nfrom cryptography.fernet import Fernet\n\nclass SecureLogProcessor:\n    \"\"\"Sichere Log-Verarbeitung mit Verschl\u00fcsselung und Integrit\u00e4t.\"\"\"\n\n    def __init__(self, encryption_key: bytes, signing_key: bytes):\n        self.cipher = Fernet(encryption_key)\n        self.signing_key = signing_key\n\n    def encrypt_log_entry(self, log_entry: Dict[str, Any]) -&gt; str:\n        \"\"\"Verschl\u00fcsselt Log-Entry.\"\"\"\n\n        log_json = json.dumps(log_entry, sort_keys=True)\n        encrypted_data = self.cipher.encrypt(log_json.encode())\n\n        # Signatur erstellen\n        signature = hmac.new(\n            self.signing_key,\n            encrypted_data,\n            hashlib.sha256\n        ).hexdigest()\n\n        return f\"{encrypted_data.decode()}:{signature}\"\n\n    def decrypt_log_entry(self, encrypted_log: str) -&gt; Dict[str, Any]:\n        \"\"\"Entschl\u00fcsselt Log-Entry und pr\u00fcft Integrit\u00e4t.\"\"\"\n\n        try:\n            encrypted_data, signature = encrypted_log.rsplit(':', 1)\n\n            # Signatur pr\u00fcfen\n            expected_signature = hmac.new(\n                self.signing_key,\n                encrypted_data.encode(),\n                hashlib.sha256\n            ).hexdigest()\n\n            if not hmac.compare_digest(signature, expected_signature):\n                raise ValueError(\"Log-Entry-Integrit\u00e4t verletzt\")\n\n            # Entschl\u00fcsseln\n            decrypted_data = self.cipher.decrypt(encrypted_data.encode())\n            return json.loads(decrypted_data.decode())\n\n        except Exception as e:\n            raise ValueError(f\"Fehler beim Entschl\u00fcsseln des Log-Entries: {e}\")\n</code></pre>"},{"location":"api/enterprise-logging/#compliance-features","title":"\ud83d\udccb Compliance-Features","text":""},{"location":"api/enterprise-logging/#gdpr-konforme-logging","title":"GDPR-konforme Logging","text":"<pre><code>class GDPRCompliantLogger(EnterpriseLogger):\n    \"\"\"GDPR-konformer Logger mit Datenminimierung.\"\"\"\n\n    def __init__(self, service_name: str, version: str):\n        super().__init__(service_name, version)\n        self.pii_fields = ['email', 'name', 'address', 'phone', 'ip_address']\n\n    async def log_with_privacy(\n        self,\n        level: LogLevel,\n        category: LogCategory,\n        message: str,\n        details: Optional[Dict[str, Any]] = None,\n        user_id: Optional[str] = None,\n        retention_period: Optional[int] = None  # Tage\n    ):\n        \"\"\"Protokolliert mit Datenschutz-Ber\u00fccksichtigung.\"\"\"\n\n        # PII-Daten pseudonymisieren\n        if details:\n            details = self._pseudonymize_pii(details)\n\n        # Retention-Metadaten hinzuf\u00fcgen\n        if retention_period:\n            if not details:\n                details = {}\n            details['_retention_days'] = retention_period\n            details['_delete_after'] = (\n                datetime.utcnow() + timedelta(days=retention_period)\n            ).isoformat()\n\n        await self.log_event(\n            level=level,\n            category=category,\n            message=message,\n            details=details,\n            user_id=self._hash_user_id(user_id) if user_id else None\n        )\n\n    def _pseudonymize_pii(self, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Pseudonymisiert PII-Daten.\"\"\"\n\n        def pseudonymize_value(value: str) -&gt; str:\n            return hashlib.sha256(value.encode()).hexdigest()[:16]\n\n        pseudonymized = {}\n        for key, value in data.items():\n            if any(pii_field in key.lower() for pii_field in self.pii_fields):\n                if isinstance(value, str):\n                    pseudonymized[f\"{key}_hash\"] = pseudonymize_value(value)\n                else:\n                    pseudonymized[key] = value\n            else:\n                pseudonymized[key] = value\n\n        return pseudonymized\n\n    def _hash_user_id(self, user_id: str) -&gt; str:\n        \"\"\"Hasht User-ID f\u00fcr Pseudonymisierung.\"\"\"\n        return hashlib.sha256(user_id.encode()).hexdigest()[:16]\n</code></pre> <p>Compliance-Hinweis</p> <p>Stellen Sie sicher, dass Ihre Logging-Konfiguration den geltenden Datenschutz- und Compliance-Anforderungen entspricht.</p> <p>Log-Retention</p> <p>Implementieren Sie automatische Log-Rotation und -L\u00f6schung basierend auf Retention-Richtlinien und rechtlichen Anforderungen.</p>"},{"location":"api/health-checks/","title":"\ud83c\udfe5 Health-Checks API","text":"<p>Umfassende Gesundheitspr\u00fcfungen f\u00fcr System-Monitoring und Service-Verf\u00fcgbarkeit.</p>"},{"location":"api/health-checks/#health-check-architektur","title":"\ud83c\udfd7\ufe0f Health-Check-Architektur","text":"<pre><code>graph TB\n    subgraph \"Health Check Types\"\n        BASIC[Basic Health]\n        DETAILED[Detailed Health]\n        READINESS[Readiness Check]\n        LIVENESS[Liveness Check]\n    end\n\n    subgraph \"Component Checks\"\n        DB[Database]\n        REDIS[Redis Cache]\n        MCP[MCP Servers]\n        AZURE[Azure Services]\n    end\n\n    subgraph \"Aggregation\"\n        COLLECTOR[Health Collector]\n        AGGREGATOR[Status Aggregator]\n    end\n\n    BASIC --&gt; COLLECTOR\n    DETAILED --&gt; COLLECTOR\n    READINESS --&gt; AGGREGATOR\n    LIVENESS --&gt; AGGREGATOR\n\n    DB --&gt; COLLECTOR\n    REDIS --&gt; COLLECTOR\n    MCP --&gt; COLLECTOR\n    AZURE --&gt; COLLECTOR</code></pre>"},{"location":"api/health-checks/#health-check-endpunkte","title":"\ud83d\udd0d Health-Check-Endpunkte","text":""},{"location":"api/health-checks/#basis-health-check","title":"Basis-Health-Check","text":"<pre><code>from fastapi import APIRouter, HTTPException\nfrom typing import Dict, Any, List\nfrom enum import Enum\nimport asyncio\nimport time\n\nclass HealthStatus(Enum):\n    HEALTHY = \"healthy\"\n    DEGRADED = \"degraded\"\n    UNHEALTHY = \"unhealthy\"\n\nrouter = APIRouter(prefix=\"/health\", tags=[\"Health Checks\"])\n\n@router.get(\"/\")\nasync def basic_health_check():\n    \"\"\"Basis-Gesundheitspr\u00fcfung.\"\"\"\n    return {\n        \"status\": HealthStatus.HEALTHY.value,\n        \"timestamp\": time.time(),\n        \"version\": \"2.0.0\",\n        \"uptime\": get_uptime_seconds()\n    }\n\n@router.get(\"/detailed\")\nasync def detailed_health_check():\n    \"\"\"Detaillierte Gesundheitspr\u00fcfung aller Komponenten.\"\"\"\n\n    health_checks = [\n        check_database_health(),\n        check_redis_health(),\n        check_mcp_servers_health(),\n        check_azure_services_health(),\n        check_disk_space(),\n        check_memory_usage()\n    ]\n\n    results = await asyncio.gather(*health_checks, return_exceptions=True)\n\n    overall_status = HealthStatus.HEALTHY\n    component_statuses = {}\n\n    for i, result in enumerate(results):\n        component_name = [\n            \"database\", \"redis\", \"mcp_servers\",\n            \"azure_services\", \"disk\", \"memory\"\n        ][i]\n\n        if isinstance(result, Exception):\n            component_statuses[component_name] = {\n                \"status\": HealthStatus.UNHEALTHY.value,\n                \"error\": str(result)\n            }\n            overall_status = HealthStatus.UNHEALTHY\n        else:\n            component_statuses[component_name] = result\n            if result[\"status\"] != HealthStatus.HEALTHY.value:\n                if overall_status == HealthStatus.HEALTHY:\n                    overall_status = HealthStatus.DEGRADED\n\n    return {\n        \"status\": overall_status.value,\n        \"timestamp\": time.time(),\n        \"components\": component_statuses,\n        \"version\": \"2.0.0\"\n    }\n\n@router.get(\"/readiness\")\nasync def readiness_check():\n    \"\"\"Kubernetes Readiness-Check.\"\"\"\n\n    # Kritische Services pr\u00fcfen\n    critical_checks = [\n        check_database_health(),\n        check_redis_health()\n    ]\n\n    results = await asyncio.gather(*critical_checks, return_exceptions=True)\n\n    for result in results:\n        if isinstance(result, Exception) or result.get(\"status\") != HealthStatus.HEALTHY.value:\n            raise HTTPException(status_code=503, detail=\"Service not ready\")\n\n    return {\"status\": \"ready\"}\n\n@router.get(\"/liveness\")\nasync def liveness_check():\n    \"\"\"Kubernetes Liveness-Check.\"\"\"\n\n    # Basis-Funktionalit\u00e4t pr\u00fcfen\n    try:\n        # Einfacher Memory-Check\n        import psutil\n        memory_percent = psutil.virtual_memory().percent\n\n        if memory_percent &gt; 95:  # 95% Memory-Nutzung\n            raise HTTPException(status_code=503, detail=\"High memory usage\")\n\n        return {\"status\": \"alive\", \"memory_usage\": f\"{memory_percent}%\"}\n\n    except Exception as e:\n        raise HTTPException(status_code=503, detail=f\"Liveness check failed: {e}\")\n</code></pre>"},{"location":"api/health-checks/#component-health-checks","title":"\ud83d\udd27 Component-Health-Checks","text":""},{"location":"api/health-checks/#database-health-check","title":"Database-Health-Check","text":"<pre><code>import asyncpg\nfrom sqlalchemy.ext.asyncio import create_async_engine\n\nasync def check_database_health() -&gt; Dict[str, Any]:\n    \"\"\"Pr\u00fcft Database-Gesundheit.\"\"\"\n\n    try:\n        # Connection-Test\n        engine = create_async_engine(\"postgresql://...\")\n\n        async with engine.begin() as conn:\n            result = await conn.execute(\"SELECT 1\")\n\n        # Performance-Test\n        start_time = time.time()\n        async with engine.begin() as conn:\n            await conn.execute(\"SELECT COUNT(*) FROM pg_stat_activity\")\n        query_time = time.time() - start_time\n\n        status = HealthStatus.HEALTHY\n        if query_time &gt; 1.0:  # &gt; 1 Sekunde\n            status = HealthStatus.DEGRADED\n\n        return {\n            \"status\": status.value,\n            \"response_time\": query_time,\n            \"connections\": await get_db_connection_count(),\n            \"last_check\": time.time()\n        }\n\n    except Exception as e:\n        return {\n            \"status\": HealthStatus.UNHEALTHY.value,\n            \"error\": str(e),\n            \"last_check\": time.time()\n        }\n\nasync def check_redis_health() -&gt; Dict[str, Any]:\n    \"\"\"Pr\u00fcft Redis-Gesundheit.\"\"\"\n\n    try:\n        import redis.asyncio as redis\n\n        client = redis.Redis(host=\"localhost\", port=6379)\n\n        # Ping-Test\n        start_time = time.time()\n        await client.ping()\n        ping_time = time.time() - start_time\n\n        # Memory-Info\n        info = await client.info(\"memory\")\n        memory_usage = info.get(\"used_memory\", 0)\n\n        status = HealthStatus.HEALTHY\n        if ping_time &gt; 0.1:  # &gt; 100ms\n            status = HealthStatus.DEGRADED\n\n        return {\n            \"status\": status.value,\n            \"ping_time\": ping_time,\n            \"memory_usage\": memory_usage,\n            \"last_check\": time.time()\n        }\n\n    except Exception as e:\n        return {\n            \"status\": HealthStatus.UNHEALTHY.value,\n            \"error\": str(e),\n            \"last_check\": time.time()\n        }\n\nasync def check_mcp_servers_health() -&gt; Dict[str, Any]:\n    \"\"\"Pr\u00fcft MCP-Server-Gesundheit.\"\"\"\n\n    try:\n        # Registrierte MCP-Server abrufen\n        mcp_servers = await get_registered_mcp_servers()\n\n        server_statuses = {}\n        overall_healthy = True\n\n        for server in mcp_servers:\n            try:\n                # Health-Check f\u00fcr jeden Server\n                async with aiohttp.ClientSession() as session:\n                    async with session.get(\n                        f\"{server['base_url']}/health\",\n                        timeout=aiohttp.ClientTimeout(total=5)\n                    ) as response:\n                        if response.status == 200:\n                            server_statuses[server['name']] = {\n                                \"status\": HealthStatus.HEALTHY.value,\n                                \"response_time\": response.headers.get(\"X-Response-Time\")\n                            }\n                        else:\n                            server_statuses[server['name']] = {\n                                \"status\": HealthStatus.UNHEALTHY.value,\n                                \"http_status\": response.status\n                            }\n                            overall_healthy = False\n\n            except Exception as e:\n                server_statuses[server['name']] = {\n                    \"status\": HealthStatus.UNHEALTHY.value,\n                    \"error\": str(e)\n                }\n                overall_healthy = False\n\n        return {\n            \"status\": HealthStatus.HEALTHY.value if overall_healthy else HealthStatus.DEGRADED.value,\n            \"servers\": server_statuses,\n            \"total_servers\": len(mcp_servers),\n            \"healthy_servers\": sum(1 for s in server_statuses.values()\n                                 if s[\"status\"] == HealthStatus.HEALTHY.value),\n            \"last_check\": time.time()\n        }\n\n    except Exception as e:\n        return {\n            \"status\": HealthStatus.UNHEALTHY.value,\n            \"error\": str(e),\n            \"last_check\": time.time()\n        }\n</code></pre>"},{"location":"api/health-checks/#system-resource-checks","title":"\ud83d\udcca System-Resource-Checks","text":""},{"location":"api/health-checks/#resource-monitoring","title":"Resource-Monitoring","text":"<pre><code>import psutil\nimport shutil\n\nasync def check_disk_space() -&gt; Dict[str, Any]:\n    \"\"\"Pr\u00fcft verf\u00fcgbaren Festplattenspeicher.\"\"\"\n\n    try:\n        # Root-Partition pr\u00fcfen\n        disk_usage = shutil.disk_usage(\"/\")\n\n        total_gb = disk_usage.total / (1024**3)\n        free_gb = disk_usage.free / (1024**3)\n        used_percent = ((disk_usage.total - disk_usage.free) / disk_usage.total) * 100\n\n        status = HealthStatus.HEALTHY\n        if used_percent &gt; 90:\n            status = HealthStatus.UNHEALTHY\n        elif used_percent &gt; 80:\n            status = HealthStatus.DEGRADED\n\n        return {\n            \"status\": status.value,\n            \"total_gb\": round(total_gb, 2),\n            \"free_gb\": round(free_gb, 2),\n            \"used_percent\": round(used_percent, 2),\n            \"last_check\": time.time()\n        }\n\n    except Exception as e:\n        return {\n            \"status\": HealthStatus.UNHEALTHY.value,\n            \"error\": str(e),\n            \"last_check\": time.time()\n        }\n\nasync def check_memory_usage() -&gt; Dict[str, Any]:\n    \"\"\"Pr\u00fcft Speicherverbrauch.\"\"\"\n\n    try:\n        memory = psutil.virtual_memory()\n\n        status = HealthStatus.HEALTHY\n        if memory.percent &gt; 90:\n            status = HealthStatus.UNHEALTHY\n        elif memory.percent &gt; 80:\n            status = HealthStatus.DEGRADED\n\n        return {\n            \"status\": status.value,\n            \"total_gb\": round(memory.total / (1024**3), 2),\n            \"available_gb\": round(memory.available / (1024**3), 2),\n            \"used_percent\": memory.percent,\n            \"last_check\": time.time()\n        }\n\n    except Exception as e:\n        return {\n            \"status\": HealthStatus.UNHEALTHY.value,\n            \"error\": str(e),\n            \"last_check\": time.time()\n        }\n\nasync def check_azure_services_health() -&gt; Dict[str, Any]:\n    \"\"\"Pr\u00fcft Azure-Services-Gesundheit.\"\"\"\n\n    try:\n        from azure.identity import DefaultAzureCredential\n        from azure.mgmt.resource import ResourceManagementClient\n\n        credential = DefaultAzureCredential()\n\n        # Azure-Service-Status pr\u00fcfen\n        # Hier w\u00fcrden Sie spezifische Azure-Services pr\u00fcfen\n\n        return {\n            \"status\": HealthStatus.HEALTHY.value,\n            \"services\": {\n                \"ai_foundry\": {\"status\": \"healthy\"},\n                \"storage\": {\"status\": \"healthy\"},\n                \"key_vault\": {\"status\": \"healthy\"}\n            },\n            \"last_check\": time.time()\n        }\n\n    except Exception as e:\n        return {\n            \"status\": HealthStatus.UNHEALTHY.value,\n            \"error\": str(e),\n            \"last_check\": time.time()\n        }\n</code></pre>"},{"location":"api/health-checks/#health-check-monitoring","title":"\ud83d\udea8 Health-Check-Monitoring","text":""},{"location":"api/health-checks/#health-metriken","title":"Health-Metriken","text":"<pre><code>from prometheus_client import Gauge, Counter, Histogram\n\n# Health-Check-Metriken\nHEALTH_CHECK_STATUS = Gauge(\n    'keiko_health_check_status',\n    'Health-Check-Status (1=healthy, 0.5=degraded, 0=unhealthy)',\n    ['component']\n)\n\nHEALTH_CHECK_DURATION = Histogram(\n    'keiko_health_check_duration_seconds',\n    'Dauer der Health-Checks',\n    ['component'],\n    buckets=[0.1, 0.25, 0.5, 1.0, 2.5, 5.0]\n)\n\nHEALTH_CHECK_FAILURES = Counter(\n    'keiko_health_check_failures_total',\n    'Anzahl fehlgeschlagener Health-Checks',\n    ['component', 'error_type']\n)\n\ndef monitor_health_check(component_name: str):\n    \"\"\"Decorator f\u00fcr Health-Check-Monitoring.\"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            start_time = time.time()\n\n            try:\n                result = await func(*args, **kwargs)\n\n                # Status-Metrik setzen\n                status_value = {\n                    HealthStatus.HEALTHY.value: 1.0,\n                    HealthStatus.DEGRADED.value: 0.5,\n                    HealthStatus.UNHEALTHY.value: 0.0\n                }.get(result.get(\"status\"), 0.0)\n\n                HEALTH_CHECK_STATUS.labels(component=component_name).set(status_value)\n\n                return result\n\n            except Exception as e:\n                HEALTH_CHECK_FAILURES.labels(\n                    component=component_name,\n                    error_type=type(e).__name__\n                ).inc()\n\n                HEALTH_CHECK_STATUS.labels(component=component_name).set(0.0)\n                raise\n\n            finally:\n                duration = time.time() - start_time\n                HEALTH_CHECK_DURATION.labels(component=component_name).observe(duration)\n\n        return wrapper\n    return decorator\n\n# Anwendung der Monitoring-Decorator\n@monitor_health_check(\"database\")\nasync def monitored_database_check():\n    return await check_database_health()\n</code></pre>"},{"location":"api/health-checks/#health-check-konfiguration","title":"\ud83d\udccb Health-Check-Konfiguration","text":""},{"location":"api/health-checks/#konfigurierbare-health-checks","title":"Konfigurierbare Health-Checks","text":"<pre><code>from pydantic import BaseModel\nfrom typing import Optional\n\nclass HealthCheckConfig(BaseModel):\n    \"\"\"Konfiguration f\u00fcr Health-Checks.\"\"\"\n\n    enabled: bool = True\n    timeout_seconds: float = 5.0\n    retry_count: int = 3\n    retry_delay: float = 1.0\n    warning_threshold: Optional[float] = None\n    critical_threshold: Optional[float] = None\n\nclass HealthCheckManager:\n    \"\"\"Manager f\u00fcr konfigurierbare Health-Checks.\"\"\"\n\n    def __init__(self):\n        self.configs = {\n            \"database\": HealthCheckConfig(\n                timeout_seconds=10.0,\n                warning_threshold=1.0,\n                critical_threshold=5.0\n            ),\n            \"redis\": HealthCheckConfig(\n                timeout_seconds=5.0,\n                warning_threshold=0.1,\n                critical_threshold=1.0\n            ),\n            \"mcp_servers\": HealthCheckConfig(\n                timeout_seconds=15.0,\n                retry_count=2\n            )\n        }\n\n    async def run_health_check(self, component: str) -&gt; Dict[str, Any]:\n        \"\"\"F\u00fchrt konfigurierbaren Health-Check aus.\"\"\"\n\n        config = self.configs.get(component)\n        if not config or not config.enabled:\n            return {\"status\": \"disabled\"}\n\n        check_func = {\n            \"database\": check_database_health,\n            \"redis\": check_redis_health,\n            \"mcp_servers\": check_mcp_servers_health\n        }.get(component)\n\n        if not check_func:\n            return {\"status\": \"unknown\", \"error\": \"No check function\"}\n\n        # Health-Check mit Retry-Logic ausf\u00fchren\n        for attempt in range(config.retry_count):\n            try:\n                result = await asyncio.wait_for(\n                    check_func(),\n                    timeout=config.timeout_seconds\n                )\n                return result\n\n            except asyncio.TimeoutError:\n                if attempt &lt; config.retry_count - 1:\n                    await asyncio.sleep(config.retry_delay)\n                    continue\n                return {\n                    \"status\": HealthStatus.UNHEALTHY.value,\n                    \"error\": \"Timeout\"\n                }\n            except Exception as e:\n                if attempt &lt; config.retry_count - 1:\n                    await asyncio.sleep(config.retry_delay)\n                    continue\n                return {\n                    \"status\": HealthStatus.UNHEALTHY.value,\n                    \"error\": str(e)\n                }\n\n        return {\"status\": HealthStatus.UNHEALTHY.value, \"error\": \"Max retries exceeded\"}\n</code></pre> <p>Kubernetes Integration</p> <p>Die <code>/health/readiness</code> und <code>/health/liveness</code> Endpunkte sind f\u00fcr Kubernetes Probes optimiert.</p> <p>Monitoring-Integration</p> <p>Nutzen Sie die Prometheus-Metriken f\u00fcr umfassendes Health-Check-Monitoring in Grafana-Dashboards.</p>"},{"location":"api/protocol-clients/","title":"\ud83d\udd0c Protocol-Clients","text":"<p>Keiko Personal Assistant unterst\u00fctzt verschiedene Protokoll-Clients f\u00fcr die Kommunikation mit externen Services und MCP-Servern.</p>"},{"location":"api/protocol-clients/#client-architektur","title":"\ud83c\udfd7\ufe0f Client-Architektur","text":""},{"location":"api/protocol-clients/#protocol-client-ubersicht","title":"Protocol-Client-\u00dcbersicht","text":"<pre><code>graph TB\n    subgraph \"Client Layer\"\n        UC[Unified Client]\n        PS[Protocol Selector]\n    end\n\n    subgraph \"Protocol Implementations\"\n        HTTP[HTTP Client]\n        WS[WebSocket Client]\n        GRPC[gRPC Client]\n        MCP[MCP Client]\n    end\n\n    subgraph \"Transport Layer\"\n        TLS[TLS/SSL]\n        MTLS[Mutual TLS]\n        AUTH[Authentication]\n    end\n\n    subgraph \"External Services\"\n        REST[REST APIs]\n        MCPS[MCP Servers]\n        AZURE[Azure Services]\n        CUSTOM[Custom Services]\n    end\n\n    UC --&gt; PS\n    PS --&gt; HTTP\n    PS --&gt; WS\n    PS --&gt; GRPC\n    PS --&gt; MCP\n\n    HTTP --&gt; TLS\n    WS --&gt; TLS\n    GRPC --&gt; MTLS\n    MCP --&gt; AUTH\n\n    HTTP --&gt; REST\n    WS --&gt; MCPS\n    GRPC --&gt; AZURE\n    MCP --&gt; CUSTOM</code></pre>"},{"location":"api/protocol-clients/#http-client","title":"\ud83c\udf10 HTTP-Client","text":""},{"location":"api/protocol-clients/#basis-http-client","title":"Basis-HTTP-Client","text":"<pre><code>import aiohttp\nimport asyncio\nfrom typing import Dict, Any, Optional, Union\nfrom dataclasses import dataclass\nimport json\n\n@dataclass\nclass HTTPClientConfig:\n    \"\"\"Konfiguration f\u00fcr HTTP-Client.\"\"\"\n    base_url: str\n    timeout: float = 30.0\n    max_retries: int = 3\n    retry_delay: float = 1.0\n    headers: Optional[Dict[str, str]] = None\n    auth_token: Optional[str] = None\n    verify_ssl: bool = True\n\nclass HTTPProtocolClient:\n    \"\"\"HTTP-Protocol-Client f\u00fcr REST-API-Kommunikation.\"\"\"\n\n    def __init__(self, config: HTTPClientConfig):\n        self.config = config\n        self.session: Optional[aiohttp.ClientSession] = None\n\n    async def __aenter__(self):\n        \"\"\"Async Context Manager Entry.\"\"\"\n        await self.connect()\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async Context Manager Exit.\"\"\"\n        await self.disconnect()\n\n    async def connect(self):\n        \"\"\"Stellt Verbindung her.\"\"\"\n        headers = self.config.headers or {}\n\n        if self.config.auth_token:\n            headers['Authorization'] = f'Bearer {self.config.auth_token}'\n\n        connector = aiohttp.TCPConnector(\n            verify_ssl=self.config.verify_ssl,\n            limit=100,\n            limit_per_host=30\n        )\n\n        timeout = aiohttp.ClientTimeout(total=self.config.timeout)\n\n        self.session = aiohttp.ClientSession(\n            base_url=self.config.base_url,\n            headers=headers,\n            connector=connector,\n            timeout=timeout\n        )\n\n    async def disconnect(self):\n        \"\"\"Schlie\u00dft Verbindung.\"\"\"\n        if self.session:\n            await self.session.close()\n            self.session = None\n\n    async def request(\n        self,\n        method: str,\n        path: str,\n        data: Optional[Union[Dict, str]] = None,\n        params: Optional[Dict[str, str]] = None,\n        headers: Optional[Dict[str, str]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"F\u00fchrt HTTP-Request aus mit Retry-Logic.\"\"\"\n\n        if not self.session:\n            await self.connect()\n\n        for attempt in range(self.config.max_retries + 1):\n            try:\n                # Request-Daten vorbereiten\n                request_kwargs = {\n                    'params': params,\n                    'headers': headers\n                }\n\n                if data:\n                    if isinstance(data, dict):\n                        request_kwargs['json'] = data\n                    else:\n                        request_kwargs['data'] = data\n\n                # Request ausf\u00fchren\n                async with self.session.request(method, path, **request_kwargs) as response:\n                    response_data = await response.text()\n\n                    # JSON-Response versuchen zu parsen\n                    try:\n                        response_json = json.loads(response_data)\n                    except json.JSONDecodeError:\n                        response_json = {'raw_response': response_data}\n\n                    # Erfolgreiche Response\n                    if response.status &lt; 400:\n                        return {\n                            'status': response.status,\n                            'headers': dict(response.headers),\n                            'data': response_json\n                        }\n\n                    # Client-Fehler (4xx) - nicht wiederholen\n                    if 400 &lt;= response.status &lt; 500:\n                        raise aiohttp.ClientResponseError(\n                            request_info=response.request_info,\n                            history=response.history,\n                            status=response.status,\n                            message=response_data\n                        )\n\n                    # Server-Fehler (5xx) - wiederholen\n                    if attempt &lt; self.config.max_retries:\n                        await asyncio.sleep(self.config.retry_delay * (2 ** attempt))\n                        continue\n\n                    raise aiohttp.ClientResponseError(\n                        request_info=response.request_info,\n                        history=response.history,\n                        status=response.status,\n                        message=response_data\n                    )\n\n            except aiohttp.ClientError as e:\n                if attempt &lt; self.config.max_retries:\n                    await asyncio.sleep(self.config.retry_delay * (2 ** attempt))\n                    continue\n                raise\n\n        raise Exception(\"Max retries exceeded\")\n\n    async def get(self, path: str, params: Optional[Dict[str, str]] = None) -&gt; Dict[str, Any]:\n        \"\"\"GET-Request.\"\"\"\n        return await self.request('GET', path, params=params)\n\n    async def post(self, path: str, data: Optional[Union[Dict, str]] = None) -&gt; Dict[str, Any]:\n        \"\"\"POST-Request.\"\"\"\n        return await self.request('POST', path, data=data)\n\n    async def put(self, path: str, data: Optional[Union[Dict, str]] = None) -&gt; Dict[str, Any]:\n        \"\"\"PUT-Request.\"\"\"\n        return await self.request('PUT', path, data=data)\n\n    async def delete(self, path: str) -&gt; Dict[str, Any]:\n        \"\"\"DELETE-Request.\"\"\"\n        return await self.request('DELETE', path)\n</code></pre>"},{"location":"api/protocol-clients/#websocket-client","title":"\ud83d\udd0c WebSocket-Client","text":""},{"location":"api/protocol-clients/#websocket-protocol-client","title":"WebSocket-Protocol-Client","text":"<pre><code>import websockets\nimport json\nimport asyncio\nfrom typing import Dict, Any, Callable, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass WebSocketClientConfig:\n    \"\"\"Konfiguration f\u00fcr WebSocket-Client.\"\"\"\n    url: str\n    auth_token: Optional[str] = None\n    ping_interval: float = 30.0\n    ping_timeout: float = 10.0\n    close_timeout: float = 10.0\n    max_size: int = 1024 * 1024  # 1MB\n    compression: Optional[str] = 'deflate'\n\nclass WebSocketProtocolClient:\n    \"\"\"WebSocket-Protocol-Client f\u00fcr Echtzeit-Kommunikation.\"\"\"\n\n    def __init__(self, config: WebSocketClientConfig):\n        self.config = config\n        self.websocket: Optional[websockets.WebSocketServerProtocol] = None\n        self.message_handlers: Dict[str, Callable] = {}\n        self.is_connected = False\n\n    async def connect(self):\n        \"\"\"Stellt WebSocket-Verbindung her.\"\"\"\n        headers = {}\n        if self.config.auth_token:\n            headers['Authorization'] = f'Bearer {self.config.auth_token}'\n\n        try:\n            self.websocket = await websockets.connect(\n                self.config.url,\n                extra_headers=headers,\n                ping_interval=self.config.ping_interval,\n                ping_timeout=self.config.ping_timeout,\n                close_timeout=self.config.close_timeout,\n                max_size=self.config.max_size,\n                compression=self.config.compression\n            )\n            self.is_connected = True\n\n            # Message-Handler-Task starten\n            asyncio.create_task(self._message_handler_loop())\n\n        except Exception as e:\n            raise ConnectionError(f\"WebSocket-Verbindung fehlgeschlagen: {e}\")\n\n    async def disconnect(self):\n        \"\"\"Schlie\u00dft WebSocket-Verbindung.\"\"\"\n        if self.websocket:\n            await self.websocket.close()\n            self.websocket = None\n            self.is_connected = False\n\n    async def send_message(self, message_type: str, data: Dict[str, Any]) -&gt; None:\n        \"\"\"Sendet Nachricht \u00fcber WebSocket.\"\"\"\n        if not self.is_connected or not self.websocket:\n            raise ConnectionError(\"WebSocket nicht verbunden\")\n\n        message = {\n            'type': message_type,\n            'timestamp': asyncio.get_event_loop().time(),\n            'data': data\n        }\n\n        try:\n            await self.websocket.send(json.dumps(message))\n        except websockets.exceptions.ConnectionClosed:\n            self.is_connected = False\n            raise ConnectionError(\"WebSocket-Verbindung unterbrochen\")\n\n    async def _message_handler_loop(self):\n        \"\"\"Message-Handler-Loop f\u00fcr eingehende Nachrichten.\"\"\"\n        try:\n            async for message in self.websocket:\n                try:\n                    data = json.loads(message)\n                    message_type = data.get('type')\n\n                    if message_type in self.message_handlers:\n                        handler = self.message_handlers[message_type]\n                        asyncio.create_task(handler(data))\n\n                except json.JSONDecodeError:\n                    print(f\"Ung\u00fcltige JSON-Nachricht erhalten: {message}\")\n                except Exception as e:\n                    print(f\"Fehler beim Verarbeiten der Nachricht: {e}\")\n\n        except websockets.exceptions.ConnectionClosed:\n            self.is_connected = False\n        except Exception as e:\n            print(f\"Fehler in Message-Handler-Loop: {e}\")\n            self.is_connected = False\n\n    def register_handler(self, message_type: str, handler: Callable):\n        \"\"\"Registriert Handler f\u00fcr Nachrichtentyp.\"\"\"\n        self.message_handlers[message_type] = handler\n\n    def unregister_handler(self, message_type: str):\n        \"\"\"Entfernt Handler f\u00fcr Nachrichtentyp.\"\"\"\n        if message_type in self.message_handlers:\n            del self.message_handlers[message_type]\n</code></pre>"},{"location":"api/protocol-clients/#mcp-client","title":"\ud83e\udd16 MCP-Client","text":""},{"location":"api/protocol-clients/#model-context-protocol-client","title":"Model Context Protocol Client","text":"<pre><code>from typing import Dict, Any, List, Optional\nimport aiohttp\nimport json\n\nclass MCPProtocolClient:\n    \"\"\"MCP (Model Context Protocol) Client.\"\"\"\n\n    def __init__(self, server_url: str, auth_config: Optional[Dict[str, str]] = None):\n        self.server_url = server_url.rstrip('/')\n        self.auth_config = auth_config or {}\n        self.session: Optional[aiohttp.ClientSession] = None\n\n    async def __aenter__(self):\n        await self.connect()\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await self.disconnect()\n\n    async def connect(self):\n        \"\"\"Stellt Verbindung zum MCP-Server her.\"\"\"\n        headers = {'Content-Type': 'application/json'}\n\n        # Authentifizierung konfigurieren\n        if self.auth_config.get('type') == 'api_key':\n            headers['X-API-Key'] = self.auth_config['api_key']\n        elif self.auth_config.get('type') == 'bearer_token':\n            headers['Authorization'] = f\"Bearer {self.auth_config['token']}\"\n\n        self.session = aiohttp.ClientSession(headers=headers)\n\n        # Server-Verf\u00fcgbarkeit pr\u00fcfen\n        try:\n            async with self.session.get(f\"{self.server_url}/health\") as response:\n                if response.status != 200:\n                    raise ConnectionError(f\"MCP-Server nicht verf\u00fcgbar: {response.status}\")\n        except aiohttp.ClientError as e:\n            raise ConnectionError(f\"Verbindung zum MCP-Server fehlgeschlagen: {e}\")\n\n    async def disconnect(self):\n        \"\"\"Schlie\u00dft Verbindung zum MCP-Server.\"\"\"\n        if self.session:\n            await self.session.close()\n            self.session = None\n\n    async def list_tools(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Listet verf\u00fcgbare Tools auf.\"\"\"\n        async with self.session.get(f\"{self.server_url}/tools\") as response:\n            if response.status == 200:\n                data = await response.json()\n                return data.get('tools', [])\n            else:\n                raise Exception(f\"Fehler beim Abrufen der Tools: {response.status}\")\n\n    async def get_tool_schema(self, tool_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Ruft Schema f\u00fcr spezifisches Tool ab.\"\"\"\n        async with self.session.get(f\"{self.server_url}/tools/{tool_name}/schema\") as response:\n            if response.status == 200:\n                return await response.json()\n            else:\n                raise Exception(f\"Tool-Schema nicht gefunden: {tool_name}\")\n\n    async def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"F\u00fchrt Tool mit gegebenen Argumenten aus.\"\"\"\n        payload = {\n            'tool_name': tool_name,\n            'arguments': arguments\n        }\n\n        async with self.session.post(\n            f\"{self.server_url}/tools/{tool_name}/execute\",\n            json=payload\n        ) as response:\n            result = await response.json()\n\n            if response.status == 200:\n                return result\n            else:\n                error_msg = result.get('error', 'Unbekannter Fehler')\n                raise Exception(f\"Tool-Ausf\u00fchrung fehlgeschlagen: {error_msg}\")\n\n    async def get_server_info(self) -&gt; Dict[str, Any]:\n        \"\"\"Ruft Server-Informationen ab.\"\"\"\n        async with self.session.get(f\"{self.server_url}/info\") as response:\n            if response.status == 200:\n                return await response.json()\n            else:\n                raise Exception(f\"Server-Info nicht verf\u00fcgbar: {response.status}\")\n</code></pre>"},{"location":"api/protocol-clients/#client-factory","title":"\ud83d\udd27 Client-Factory","text":""},{"location":"api/protocol-clients/#protocol-client-factory","title":"Protocol-Client-Factory","text":"<pre><code>from enum import Enum\nfrom typing import Union, Dict, Any\n\nclass ProtocolType(Enum):\n    HTTP = \"http\"\n    WEBSOCKET = \"websocket\"\n    MCP = \"mcp\"\n\nclass ProtocolClientFactory:\n    \"\"\"Factory f\u00fcr Protocol-Clients.\"\"\"\n\n    @staticmethod\n    def create_client(\n        protocol_type: ProtocolType,\n        config: Union[HTTPClientConfig, WebSocketClientConfig, Dict[str, Any]]\n    ):\n        \"\"\"Erstellt Protocol-Client basierend auf Typ.\"\"\"\n\n        if protocol_type == ProtocolType.HTTP:\n            if not isinstance(config, HTTPClientConfig):\n                config = HTTPClientConfig(**config)\n            return HTTPProtocolClient(config)\n\n        elif protocol_type == ProtocolType.WEBSOCKET:\n            if not isinstance(config, WebSocketClientConfig):\n                config = WebSocketClientConfig(**config)\n            return WebSocketProtocolClient(config)\n\n        elif protocol_type == ProtocolType.MCP:\n            return MCPProtocolClient(\n                server_url=config.get('server_url'),\n                auth_config=config.get('auth_config')\n            )\n\n        else:\n            raise ValueError(f\"Unbekannter Protocol-Typ: {protocol_type}\")\n\n# Verwendungsbeispiel\nasync def example_usage():\n    \"\"\"Beispiel f\u00fcr Client-Verwendung.\"\"\"\n\n    # HTTP-Client\n    http_config = HTTPClientConfig(\n        base_url=\"https://api.example.com\",\n        auth_token=\"your-token\"\n    )\n\n    async with ProtocolClientFactory.create_client(ProtocolType.HTTP, http_config) as client:\n        response = await client.get(\"/users\")\n        print(f\"HTTP Response: {response}\")\n\n    # WebSocket-Client\n    ws_config = WebSocketClientConfig(\n        url=\"wss://api.example.com/ws\",\n        auth_token=\"your-token\"\n    )\n\n    ws_client = ProtocolClientFactory.create_client(ProtocolType.WEBSOCKET, ws_config)\n\n    # Message-Handler registrieren\n    async def handle_message(data):\n        print(f\"Received: {data}\")\n\n    ws_client.register_handler(\"notification\", handle_message)\n\n    await ws_client.connect()\n    await ws_client.send_message(\"subscribe\", {\"events\": [\"user_updates\"]})\n\n    # MCP-Client\n    mcp_config = {\n        'server_url': 'http://localhost:8080',\n        'auth_config': {'type': 'api_key', 'api_key': 'your-key'}\n    }\n\n    async with ProtocolClientFactory.create_client(ProtocolType.MCP, mcp_config) as client:\n        tools = await client.list_tools()\n        print(f\"Available tools: {tools}\")\n\n        if tools:\n            result = await client.execute_tool(\n                tools[0]['name'],\n                {'param1': 'value1'}\n            )\n            print(f\"Tool result: {result}\")\n</code></pre> <p>Client-Auswahl</p> <p>Verwenden Sie den HTTP-Client f\u00fcr REST-APIs, den WebSocket-Client f\u00fcr Echtzeit-Kommunikation und den MCP-Client f\u00fcr Model Context Protocol-Server.</p> <p>Performance-Optimierung</p> <p>Nutzen Sie Connection-Pooling und Keep-Alive-Verbindungen f\u00fcr bessere Performance bei h\u00e4ufigen Requests.</p>"},{"location":"api/protocol-selector/","title":"\ud83c\udfaf Protocol-Selector","text":"<p>Der Protocol-Selector automatisiert die Auswahl des optimalen Kommunikationsprotokolls basierend auf Service-Eigenschaften und Anforderungen.</p>"},{"location":"api/protocol-selector/#selector-architektur","title":"\ud83c\udfd7\ufe0f Selector-Architektur","text":""},{"location":"api/protocol-selector/#protocol-selection-pipeline","title":"Protocol-Selection-Pipeline","text":"<pre><code>graph TB\n    subgraph \"Input Analysis\"\n        REQ[Request Analysis]\n        SVC[Service Discovery]\n        CAPS[Capability Detection]\n    end\n\n    subgraph \"Selection Logic\"\n        RULES[Selection Rules]\n        WEIGHTS[Protocol Weights]\n        FALLBACK[Fallback Strategy]\n    end\n\n    subgraph \"Protocol Options\"\n        HTTP[HTTP/REST]\n        WS[WebSocket]\n        GRPC[gRPC]\n        MCP[MCP]\n    end\n\n    subgraph \"Quality Metrics\"\n        LATENCY[Latency Requirements]\n        THROUGHPUT[Throughput Needs]\n        RELIABILITY[Reliability Level]\n    end\n\n    REQ --&gt; RULES\n    SVC --&gt; WEIGHTS\n    CAPS --&gt; FALLBACK\n\n    RULES --&gt; HTTP\n    WEIGHTS --&gt; WS\n    FALLBACK --&gt; GRPC\n\n    LATENCY --&gt; RULES\n    THROUGHPUT --&gt; WEIGHTS\n    RELIABILITY --&gt; FALLBACK\n\n    HTTP --&gt; MCP</code></pre>"},{"location":"api/protocol-selector/#protocol-selector-implementation","title":"\ud83c\udf9b\ufe0f Protocol-Selector-Implementation","text":""},{"location":"api/protocol-selector/#basis-selector","title":"Basis-Selector","text":"<pre><code>from enum import Enum\nfrom typing import Dict, Any, Optional, List, Tuple\nfrom dataclasses import dataclass\nimport asyncio\n\nclass ProtocolType(Enum):\n    \"\"\"Verf\u00fcgbare Protokoll-Typen.\"\"\"\n    HTTP = \"http\"\n    WEBSOCKET = \"websocket\"\n    GRPC = \"grpc\"\n    MCP = \"mcp\"\n\n@dataclass\nclass ServiceCapabilities:\n    \"\"\"Service-F\u00e4higkeiten f\u00fcr Protocol-Selection.\"\"\"\n    supports_http: bool = True\n    supports_websocket: bool = False\n    supports_grpc: bool = False\n    supports_mcp: bool = False\n    real_time_required: bool = False\n    high_throughput: bool = False\n    low_latency: bool = False\n    streaming: bool = False\n    bidirectional: bool = False\n\n@dataclass\nclass RequestRequirements:\n    \"\"\"Anforderungen f\u00fcr Protocol-Selection.\"\"\"\n    operation_type: str  # \"query\", \"command\", \"stream\", \"subscribe\"\n    data_size: int = 0  # Bytes\n    expected_response_time: float = 5.0  # Sekunden\n    reliability_level: str = \"normal\"  # \"low\", \"normal\", \"high\", \"critical\"\n    security_level: str = \"standard\"  # \"basic\", \"standard\", \"high\", \"enterprise\"\n    concurrent_requests: int = 1\n\n@dataclass\nclass ProtocolScore:\n    \"\"\"Bewertung eines Protokolls f\u00fcr eine Anfrage.\"\"\"\n    protocol: ProtocolType\n    score: float\n    reasons: List[str]\n    warnings: List[str] = None\n\nclass ProtocolSelector:\n    \"\"\"Intelligenter Protocol-Selector.\"\"\"\n\n    def __init__(self):\n        self.protocol_weights = {\n            ProtocolType.HTTP: {\n                \"simplicity\": 0.9,\n                \"compatibility\": 0.95,\n                \"caching\": 0.8,\n                \"real_time\": 0.1,\n                \"throughput\": 0.6,\n                \"latency\": 0.5\n            },\n            ProtocolType.WEBSOCKET: {\n                \"simplicity\": 0.6,\n                \"compatibility\": 0.7,\n                \"caching\": 0.2,\n                \"real_time\": 0.95,\n                \"throughput\": 0.8,\n                \"latency\": 0.9\n            },\n            ProtocolType.GRPC: {\n                \"simplicity\": 0.4,\n                \"compatibility\": 0.6,\n                \"caching\": 0.3,\n                \"real_time\": 0.7,\n                \"throughput\": 0.95,\n                \"latency\": 0.95\n            },\n            ProtocolType.MCP: {\n                \"simplicity\": 0.8,\n                \"compatibility\": 0.5,\n                \"caching\": 0.4,\n                \"real_time\": 0.6,\n                \"throughput\": 0.7,\n                \"latency\": 0.7\n            }\n        }\n\n    def select_protocol(\n        self,\n        service_capabilities: ServiceCapabilities,\n        request_requirements: RequestRequirements,\n        available_protocols: Optional[List[ProtocolType]] = None\n    ) -&gt; ProtocolScore:\n        \"\"\"W\u00e4hlt optimales Protokoll basierend auf Anforderungen.\"\"\"\n\n        if available_protocols is None:\n            available_protocols = list(ProtocolType)\n\n        # Verf\u00fcgbare Protokolle basierend auf Service-Capabilities filtern\n        supported_protocols = self._filter_supported_protocols(\n            service_capabilities, available_protocols\n        )\n\n        if not supported_protocols:\n            raise ValueError(\"Keine unterst\u00fctzten Protokolle verf\u00fcgbar\")\n\n        # Protokolle bewerten\n        scores = []\n        for protocol in supported_protocols:\n            score = self._calculate_protocol_score(\n                protocol, service_capabilities, request_requirements\n            )\n            scores.append(score)\n\n        # Bestes Protokoll ausw\u00e4hlen\n        best_score = max(scores, key=lambda x: x.score)\n        return best_score\n\n    def _filter_supported_protocols(\n        self,\n        capabilities: ServiceCapabilities,\n        available_protocols: List[ProtocolType]\n    ) -&gt; List[ProtocolType]:\n        \"\"\"Filtert unterst\u00fctzte Protokolle basierend auf Service-Capabilities.\"\"\"\n\n        supported = []\n\n        for protocol in available_protocols:\n            if protocol == ProtocolType.HTTP and capabilities.supports_http:\n                supported.append(protocol)\n            elif protocol == ProtocolType.WEBSOCKET and capabilities.supports_websocket:\n                supported.append(protocol)\n            elif protocol == ProtocolType.GRPC and capabilities.supports_grpc:\n                supported.append(protocol)\n            elif protocol == ProtocolType.MCP and capabilities.supports_mcp:\n                supported.append(protocol)\n\n        return supported\n\n    def _calculate_protocol_score(\n        self,\n        protocol: ProtocolType,\n        capabilities: ServiceCapabilities,\n        requirements: RequestRequirements\n    ) -&gt; ProtocolScore:\n        \"\"\"Berechnet Bewertung f\u00fcr ein Protokoll.\"\"\"\n\n        weights = self.protocol_weights[protocol]\n        score = 0.0\n        reasons = []\n        warnings = []\n\n        # Real-Time-Anforderungen\n        if capabilities.real_time_required or requirements.operation_type == \"subscribe\":\n            real_time_score = weights[\"real_time\"]\n            score += real_time_score * 0.3\n            if real_time_score &gt; 0.8:\n                reasons.append(\"Exzellente Real-Time-Unterst\u00fctzung\")\n            elif real_time_score &lt; 0.3:\n                warnings.append(\"Begrenzte Real-Time-F\u00e4higkeiten\")\n\n        # Throughput-Anforderungen\n        if capabilities.high_throughput or requirements.data_size &gt; 1024 * 1024:  # &gt; 1MB\n            throughput_score = weights[\"throughput\"]\n            score += throughput_score * 0.25\n            if throughput_score &gt; 0.8:\n                reasons.append(\"Hoher Durchsatz unterst\u00fctzt\")\n            elif throughput_score &lt; 0.5:\n                warnings.append(\"Begrenzter Durchsatz\")\n\n        # Latency-Anforderungen\n        if capabilities.low_latency or requirements.expected_response_time &lt; 1.0:\n            latency_score = weights[\"latency\"]\n            score += latency_score * 0.25\n            if latency_score &gt; 0.8:\n                reasons.append(\"Niedrige Latenz\")\n            elif latency_score &lt; 0.5:\n                warnings.append(\"H\u00f6here Latenz m\u00f6glich\")\n\n        # Kompatibilit\u00e4t und Einfachheit\n        compatibility_score = weights[\"compatibility\"]\n        simplicity_score = weights[\"simplicity\"]\n        score += (compatibility_score + simplicity_score) * 0.1\n\n        # Sicherheitsanforderungen\n        if requirements.security_level in [\"high\", \"enterprise\"]:\n            if protocol in [ProtocolType.GRPC, ProtocolType.WEBSOCKET]:\n                score += 0.1\n                reasons.append(\"Erweiterte Sicherheitsfeatures\")\n\n        # Operation-Type-spezifische Bewertung\n        if requirements.operation_type == \"query\":\n            if protocol == ProtocolType.HTTP:\n                score += 0.15\n                reasons.append(\"Optimal f\u00fcr Query-Operationen\")\n        elif requirements.operation_type == \"stream\":\n            if protocol in [ProtocolType.WEBSOCKET, ProtocolType.GRPC]:\n                score += 0.2\n                reasons.append(\"Streaming-Unterst\u00fctzung\")\n        elif requirements.operation_type == \"command\":\n            if protocol in [ProtocolType.HTTP, ProtocolType.MCP]:\n                score += 0.1\n                reasons.append(\"Geeignet f\u00fcr Command-Operationen\")\n\n        # Concurrent-Request-Handling\n        if requirements.concurrent_requests &gt; 100:\n            if protocol == ProtocolType.GRPC:\n                score += 0.1\n                reasons.append(\"Exzellente Concurrent-Request-Behandlung\")\n            elif protocol == ProtocolType.HTTP:\n                warnings.append(\"M\u00f6gliche Concurrent-Request-Limits\")\n\n        return ProtocolScore(\n            protocol=protocol,\n            score=min(score, 1.0),  # Score auf 1.0 begrenzen\n            reasons=reasons,\n            warnings=warnings or None\n        )\n\n# Advanced Protocol Selector mit Machine Learning\nclass MLProtocolSelector(ProtocolSelector):\n    \"\"\"ML-basierter Protocol-Selector mit Lernf\u00e4higkeiten.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.performance_history: Dict[str, List[float]] = {}\n        self.selection_history: List[Dict[str, Any]] = []\n\n    def record_performance(\n        self,\n        protocol: ProtocolType,\n        request_id: str,\n        latency: float,\n        success: bool,\n        throughput: Optional[float] = None\n    ):\n        \"\"\"Zeichnet Performance-Daten f\u00fcr ML-Training auf.\"\"\"\n\n        key = f\"{protocol.value}_{request_id}\"\n        if key not in self.performance_history:\n            self.performance_history[key] = []\n\n        # Performance-Score berechnen\n        performance_score = 1.0 if success else 0.0\n        if success and latency &gt; 0:\n            performance_score *= min(1.0, 5.0 / latency)  # Latency-Penalty\n\n        if throughput:\n            performance_score *= min(1.0, throughput / 1000.0)  # Throughput-Bonus\n\n        self.performance_history[key].append(performance_score)\n\n    def get_adaptive_weights(self, protocol: ProtocolType) -&gt; Dict[str, float]:\n        \"\"\"Berechnet adaptive Gewichte basierend auf Performance-Historie.\"\"\"\n\n        base_weights = self.protocol_weights[protocol].copy()\n\n        # Performance-Historie analysieren\n        protocol_scores = []\n        for key, scores in self.performance_history.items():\n            if key.startswith(protocol.value):\n                protocol_scores.extend(scores)\n\n        if protocol_scores:\n            avg_performance = sum(protocol_scores) / len(protocol_scores)\n\n            # Gewichte basierend auf Performance anpassen\n            adjustment_factor = avg_performance * 0.2  # Max 20% Anpassung\n\n            for key in base_weights:\n                base_weights[key] *= (1.0 + adjustment_factor)\n                base_weights[key] = min(1.0, base_weights[key])  # Auf 1.0 begrenzen\n\n        return base_weights\n\n    def select_protocol_with_learning(\n        self,\n        service_capabilities: ServiceCapabilities,\n        request_requirements: RequestRequirements,\n        available_protocols: Optional[List[ProtocolType]] = None\n    ) -&gt; ProtocolScore:\n        \"\"\"Protocol-Selection mit ML-basierten Anpassungen.\"\"\"\n\n        # Tempor\u00e4r adaptive Gewichte verwenden\n        original_weights = self.protocol_weights.copy()\n\n        try:\n            # Adaptive Gewichte f\u00fcr alle Protokolle berechnen\n            for protocol in ProtocolType:\n                self.protocol_weights[protocol] = self.get_adaptive_weights(protocol)\n\n            # Standard-Selection mit angepassten Gewichten\n            result = self.select_protocol(\n                service_capabilities, request_requirements, available_protocols\n            )\n\n            # Selection-Historie aufzeichnen\n            self.selection_history.append({\n                'protocol': result.protocol.value,\n                'score': result.score,\n                'requirements': request_requirements,\n                'capabilities': service_capabilities,\n                'timestamp': asyncio.get_event_loop().time()\n            })\n\n            return result\n\n        finally:\n            # Original-Gewichte wiederherstellen\n            self.protocol_weights = original_weights\n\n# Verwendungsbeispiele\nasync def example_protocol_selection():\n    \"\"\"Beispiele f\u00fcr Protocol-Selection.\"\"\"\n\n    selector = ProtocolSelector()\n\n    # Beispiel 1: Real-Time-Chat-Anwendung\n    chat_capabilities = ServiceCapabilities(\n        supports_http=True,\n        supports_websocket=True,\n        real_time_required=True,\n        bidirectional=True\n    )\n\n    chat_requirements = RequestRequirements(\n        operation_type=\"subscribe\",\n        expected_response_time=0.1,\n        reliability_level=\"high\"\n    )\n\n    chat_protocol = selector.select_protocol(chat_capabilities, chat_requirements)\n    print(f\"Chat-Protokoll: {chat_protocol.protocol.value}\")\n    print(f\"Score: {chat_protocol.score:.2f}\")\n    print(f\"Gr\u00fcnde: {chat_protocol.reasons}\")\n\n    # Beispiel 2: Bulk-Datenverarbeitung\n    bulk_capabilities = ServiceCapabilities(\n        supports_http=True,\n        supports_grpc=True,\n        high_throughput=True\n    )\n\n    bulk_requirements = RequestRequirements(\n        operation_type=\"command\",\n        data_size=10 * 1024 * 1024,  # 10MB\n        concurrent_requests=200,\n        reliability_level=\"critical\"\n    )\n\n    bulk_protocol = selector.select_protocol(bulk_capabilities, bulk_requirements)\n    print(f\"\\nBulk-Protokoll: {bulk_protocol.protocol.value}\")\n    print(f\"Score: {bulk_protocol.score:.2f}\")\n    print(f\"Gr\u00fcnde: {bulk_protocol.reasons}\")\n\n    # Beispiel 3: MCP-Tool-Ausf\u00fchrung\n    mcp_capabilities = ServiceCapabilities(\n        supports_http=True,\n        supports_mcp=True\n    )\n\n    mcp_requirements = RequestRequirements(\n        operation_type=\"command\",\n        expected_response_time=2.0,\n        reliability_level=\"normal\"\n    )\n\n    mcp_protocol = selector.select_protocol(mcp_capabilities, mcp_requirements)\n    print(f\"\\nMCP-Protokoll: {mcp_protocol.protocol.value}\")\n    print(f\"Score: {mcp_protocol.score:.2f}\")\n    print(f\"Gr\u00fcnde: {mcp_protocol.reasons}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(example_protocol_selection())\n</code></pre>"},{"location":"api/protocol-selector/#selection-metriken","title":"\ud83d\udcca Selection-Metriken","text":""},{"location":"api/protocol-selector/#protocol-selection-monitoring","title":"Protocol-Selection-Monitoring","text":"<pre><code>from prometheus_client import Counter, Histogram, Gauge\n\n# Metriken f\u00fcr Protocol-Selection\nPROTOCOL_SELECTIONS = Counter(\n    'keiko_protocol_selections_total',\n    'Gesamtanzahl der Protocol-Selections',\n    ['protocol', 'operation_type', 'reason']\n)\n\nPROTOCOL_SELECTION_TIME = Histogram(\n    'keiko_protocol_selection_duration_seconds',\n    'Zeit f\u00fcr Protocol-Selection',\n    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1]\n)\n\nPROTOCOL_PERFORMANCE = Gauge(\n    'keiko_protocol_performance_score',\n    'Performance-Score f\u00fcr Protokolle',\n    ['protocol', 'metric_type']\n)\n\ndef monitor_protocol_selection(func):\n    \"\"\"Decorator f\u00fcr Protocol-Selection-Monitoring.\"\"\"\n\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        start_time = time.time()\n\n        try:\n            result = await func(*args, **kwargs)\n\n            # Metriken aufzeichnen\n            PROTOCOL_SELECTIONS.labels(\n                protocol=result.protocol.value,\n                operation_type=kwargs.get('request_requirements', {}).get('operation_type', 'unknown'),\n                reason='success'\n            ).inc()\n\n            return result\n\n        except Exception as e:\n            PROTOCOL_SELECTIONS.labels(\n                protocol='unknown',\n                operation_type='unknown',\n                reason='error'\n            ).inc()\n            raise\n\n        finally:\n            duration = time.time() - start_time\n            PROTOCOL_SELECTION_TIME.observe(duration)\n\n    return wrapper\n</code></pre> <p>Optimale Protocol-Selection</p> <ul> <li>Verwenden Sie HTTP f\u00fcr einfache Request/Response-Patterns</li> <li>W\u00e4hlen Sie WebSocket f\u00fcr Real-Time-Kommunikation</li> <li>Nutzen Sie gRPC f\u00fcr High-Performance-Anwendungen</li> <li>Setzen Sie MCP f\u00fcr Model Context Protocol-spezifische Operationen ein</li> </ul> <p>Machine Learning</p> <p>Der ML-basierte Selector lernt aus Performance-Daten und passt die Protocol-Selection automatisch an ver\u00e4nderte Bedingungen an.</p>"},{"location":"api/protocol-types/","title":"Protocol Types","text":"<p>Diese API-Dokumentation wird noch entwickelt.</p>"},{"location":"api/protocol-types/#ubersicht","title":"\u00dcbersicht","text":"<p>Typen und Konfigurationen f\u00fcr die verschiedenen Protokolle.</p>"},{"location":"api/protocol-types/#agentclientconfig","title":"AgentClientConfig","text":"<p>Basis-Konfiguration f\u00fcr den KEI-Agent Client.</p> <pre><code>@dataclass\nclass AgentClientConfig:\n    base_url: str\n    api_token: str\n    agent_id: str\n    timeout: int = 30\n</code></pre>"},{"location":"api/protocol-types/#protocolconfig","title":"ProtocolConfig","text":"<p>Konfiguration f\u00fcr Protokoll-spezifische Einstellungen.</p> <pre><code>@dataclass\nclass ProtocolConfig:\n    rpc_enabled: bool = True\n    stream_enabled: bool = True\n    bus_enabled: bool = True\n    mcp_enabled: bool = True\n</code></pre>"},{"location":"api/protocol-types/#securityconfig","title":"SecurityConfig","text":"<p>Sicherheitskonfiguration f\u00fcr Authentifizierung und Autorisierung.</p> <pre><code>@dataclass\nclass SecurityConfig:\n    auth_type: AuthType\n    rbac_enabled: bool = False\n    audit_enabled: bool = False\n</code></pre>"},{"location":"api/protocol-types/#weitere-informationen","title":"Weitere Informationen","text":"<ul> <li>Unified Client</li> <li>Security Manager</li> </ul>"},{"location":"api/security-manager/","title":"Security Manager","text":"<p>Diese API-Dokumentation wird noch entwickelt.</p>"},{"location":"api/security-manager/#ubersicht","title":"\u00dcbersicht","text":"<p>Der SecurityManager verwaltet Authentifizierung, Autorisierung und Sicherheitsrichtlinien.</p>"},{"location":"api/security-manager/#klasse-securitymanager","title":"Klasse: SecurityManager","text":"<pre><code>class SecurityManager:\n    def __init__(self, config: SecurityConfig):\n        \"\"\"Initialisiert den Security Manager.\"\"\"\n\n    async def authenticate(self) -&gt; bool:\n        \"\"\"F\u00fchrt Authentifizierung durch.\"\"\"\n\n    async def refresh_token(self) -&gt; str:\n        \"\"\"Erneuert das Authentifizierungs-Token.\"\"\"\n\n    def validate_permissions(self, operation: str) -&gt; bool:\n        \"\"\"Validiert Berechtigungen f\u00fcr eine Operation.\"\"\"\n</code></pre>"},{"location":"api/security-manager/#authentifizierungstypen","title":"Authentifizierungstypen","text":"<ul> <li>Bearer Token: Einfache Token-basierte Authentifizierung</li> <li>OIDC: OpenID Connect Integration</li> <li>mTLS: Mutual TLS f\u00fcr h\u00f6chste Sicherheit</li> </ul>"},{"location":"api/security-manager/#weitere-informationen","title":"Weitere Informationen","text":"<ul> <li>Protocol Types</li> <li>Unified Client</li> </ul>"},{"location":"api/unified-client/","title":"UnifiedKeiAgentClient","text":"<p>Die <code>UnifiedKeiAgentClient</code> Klasse ist die Haupt-API-Schnittstelle des KEI-Agent SDK. Sie bietet eine einheitliche, typisierte API f\u00fcr alle Agent-Operationen mit automatischer Protokoll-Auswahl und Enterprise-Features.</p>"},{"location":"api/unified-client/#ubersicht","title":"\ud83d\ude80 \u00dcbersicht","text":"<p>Der <code>UnifiedKeiAgentClient</code> abstrahiert die Komplexit\u00e4t der Multi-Protocol-Architektur und bietet eine einfache, aber m\u00e4chtige API f\u00fcr:</p> <ul> <li>Agent-Operationen: Plan, Act, Observe, Explain</li> <li>Multi-Protocol Support: Automatische Auswahl zwischen RPC, Stream, Bus und MCP</li> <li>Enterprise Features: Logging, Health Checks, Security</li> <li>Resilience: Automatische Fallback-Mechanismen und Retry-Logik</li> </ul>"},{"location":"api/unified-client/#konstruktor","title":"\ud83d\udccb Konstruktor","text":"<pre><code>def __init__(\n    self,\n    config: AgentClientConfig,\n    protocol_config: Optional[ProtocolConfig] = None,\n    security_config: Optional[SecurityConfig] = None\n) -&gt; None\n</code></pre>"},{"location":"api/unified-client/#parameter","title":"Parameter","text":"Parameter Typ Standard Beschreibung <code>config</code> <code>AgentClientConfig</code> Erforderlich Basis-Client-Konfiguration <code>protocol_config</code> <code>ProtocolConfig</code> <code>None</code> Protokoll-spezifische Konfiguration <code>security_config</code> <code>SecurityConfig</code> <code>None</code> Sicherheitskonfiguration"},{"location":"api/unified-client/#beispiel","title":"Beispiel","text":"<pre><code>from kei_agent import (\n    UnifiedKeiAgentClient,\n    AgentClientConfig,\n    ProtocolConfig,\n    SecurityConfig,\n    AuthType\n)\n\n# Basis-Konfiguration\nconfig = AgentClientConfig(\n    base_url=\"https://api.kei-framework.com\",\n    api_token=\"your-api-token\",\n    agent_id=\"my-agent\"\n)\n\n# Erweiterte Konfiguration\nprotocol_config = ProtocolConfig(\n    auto_protocol_selection=True,\n    protocol_fallback_enabled=True\n)\n\nsecurity_config = SecurityConfig(\n    auth_type=AuthType.BEARER,\n    rbac_enabled=True,\n    audit_enabled=True\n)\n\n# Client erstellen\nclient = UnifiedKeiAgentClient(\n    config=config,\n    protocol_config=protocol_config,\n    security_config=security_config\n)\n</code></pre>"},{"location":"api/unified-client/#lifecycle-management","title":"\ud83d\udd04 Lifecycle-Management","text":""},{"location":"api/unified-client/#async-context-manager-empfohlen","title":"Async Context Manager (Empfohlen)","text":"<pre><code>async with UnifiedKeiAgentClient(config=config) as client:\n    # Client ist automatisch initialisiert\n    result = await client.plan_task(\"Create report\")\n    # Automatisches Cleanup beim Verlassen\n</code></pre>"},{"location":"api/unified-client/#manuelle-verwaltung","title":"Manuelle Verwaltung","text":"<pre><code>client = UnifiedKeiAgentClient(config=config)\ntry:\n    await client.initialize()\n    result = await client.plan_task(\"Create report\")\nfinally:\n    await client.close()\n</code></pre>"},{"location":"api/unified-client/#high-level-api-methoden","title":"\ud83c\udfaf High-Level API-Methoden","text":""},{"location":"api/unified-client/#agent-operationen","title":"Agent-Operationen","text":""},{"location":"api/unified-client/#plan_task","title":"plan_task()","text":"<pre><code>async def plan_task(\n    self,\n    objective: str,\n    context: Optional[Dict[str, Any]] = None,\n    protocol: Optional[ProtocolType] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>Erstellt einen Plan f\u00fcr ein gegebenes Ziel.</p> <p>Parameter: - <code>objective</code>: Ziel-Beschreibung f\u00fcr die Planung - <code>context</code>: Zus\u00e4tzlicher Kontext f\u00fcr die Planung - <code>protocol</code>: Bevorzugtes Protokoll (optional)</p> <p>Beispiel: <pre><code>plan = await client.plan_task(\n    objective=\"Erstelle einen Quartalsbericht\",\n    context={\n        \"format\": \"pdf\",\n        \"quarter\": \"Q4-2024\",\n        \"sections\": [\"summary\", \"financials\", \"outlook\"]\n    }\n)\nprint(f\"Plan ID: {plan['plan_id']}\")\n</code></pre></p>"},{"location":"api/unified-client/#execute_action","title":"execute_action()","text":"<pre><code>async def execute_action(\n    self,\n    action: str,\n    parameters: Optional[Dict[str, Any]] = None,\n    protocol: Optional[ProtocolType] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>F\u00fchrt eine spezifische Aktion aus.</p> <p>Parameter: - <code>action</code>: Name der auszuf\u00fchrenden Aktion - <code>parameters</code>: Parameter f\u00fcr die Aktion - <code>protocol</code>: Bevorzugtes Protokoll (optional)</p> <p>Beispiel: <pre><code>result = await client.execute_action(\n    action=\"generate_report\",\n    parameters={\n        \"template\": \"quarterly_template\",\n        \"data_source\": \"financial_db\",\n        \"output_format\": \"pdf\"\n    }\n)\nprint(f\"Action ID: {result['action_id']}\")\n</code></pre></p>"},{"location":"api/unified-client/#observe_environment","title":"observe_environment()","text":"<pre><code>async def observe_environment(\n    self,\n    observation_type: str,\n    data: Optional[Dict[str, Any]] = None,\n    protocol: Optional[ProtocolType] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>F\u00fchrt Umgebungsbeobachtung durch.</p> <p>Parameter: - <code>observation_type</code>: Typ der Beobachtung - <code>data</code>: Beobachtungsdaten - <code>protocol</code>: Bevorzugtes Protokoll (optional)</p> <p>Beispiel: <pre><code>observation = await client.observe_environment(\n    observation_type=\"system_metrics\",\n    data={\n        \"interval\": 60,\n        \"metrics\": [\"cpu\", \"memory\", \"disk\"]\n    }\n)\nprint(f\"Observation ID: {observation['observation_id']}\")\n</code></pre></p>"},{"location":"api/unified-client/#explain_reasoning","title":"explain_reasoning()","text":"<pre><code>async def explain_reasoning(\n    self,\n    query: str,\n    context: Optional[Dict[str, Any]] = None,\n    protocol: Optional[ProtocolType] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>Erkl\u00e4rt das Reasoning f\u00fcr eine gegebene Anfrage.</p> <p>Parameter: - <code>query</code>: Erkl\u00e4rungsanfrage - <code>context</code>: Kontext f\u00fcr die Erkl\u00e4rung - <code>protocol</code>: Bevorzugtes Protokoll (optional)</p> <p>Beispiel: <pre><code>explanation = await client.explain_reasoning(\n    query=\"Warum wurde diese Vorlage gew\u00e4hlt?\",\n    context={\"action_id\": \"action-123\"}\n)\nprint(f\"Erkl\u00e4rung: {explanation['explanation']}\")\n</code></pre></p>"},{"location":"api/unified-client/#kommunikations-methoden","title":"Kommunikations-Methoden","text":""},{"location":"api/unified-client/#send_agent_message","title":"send_agent_message()","text":"<pre><code>async def send_agent_message(\n    self,\n    target_agent: str,\n    message_type: str,\n    payload: Dict[str, Any]\n) -&gt; Dict[str, Any]\n</code></pre> <p>Sendet Nachricht an anderen Agent (A2A-Kommunikation).</p> <p>Beispiel: <pre><code>response = await client.send_agent_message(\n    target_agent=\"data-processor-agent\",\n    message_type=\"task_request\",\n    payload={\n        \"task\": \"analyze_sales_data\",\n        \"dataset\": \"q4_2024_sales\",\n        \"priority\": \"high\"\n    }\n)\nprint(f\"Message ID: {response['message_id']}\")\n</code></pre></p>"},{"location":"api/unified-client/#start_streaming_session","title":"start_streaming_session()","text":"<pre><code>async def start_streaming_session(\n    self,\n    callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None\n) -&gt; None\n</code></pre> <p>Startet Streaming-Session f\u00fcr Echtzeit-Kommunikation.</p> <p>Beispiel: <pre><code>async def message_handler(message: Dict[str, Any]):\n    print(f\"Received: {message}\")\n\nawait client.start_streaming_session(callback=message_handler)\n</code></pre></p>"},{"location":"api/unified-client/#tool-integration","title":"Tool-Integration","text":""},{"location":"api/unified-client/#discover_available_tools","title":"discover_available_tools()","text":"<pre><code>async def discover_available_tools(\n    self,\n    category: Optional[str] = None\n) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Entdeckt verf\u00fcgbare MCP-Tools.</p> <p>Beispiel: <pre><code>tools = await client.discover_available_tools(\"math\")\nfor tool in tools:\n    print(f\"Tool: {tool['name']} - {tool['description']}\")\n</code></pre></p>"},{"location":"api/unified-client/#use_tool","title":"use_tool()","text":"<pre><code>async def use_tool(\n    self,\n    tool_name: str,\n    **parameters: Any\n) -&gt; Dict[str, Any]\n</code></pre> <p>F\u00fchrt MCP-Tool aus.</p> <p>Beispiel: <pre><code>result = await client.use_tool(\n    \"calculator\",\n    expression=\"(100 * 1.08) - 50\"\n)\nprint(f\"Ergebnis: {result['result']}\")\n</code></pre></p>"},{"location":"api/unified-client/#system-methoden","title":"\ud83d\udd27 System-Methoden","text":""},{"location":"api/unified-client/#health_check","title":"health_check()","text":"<pre><code>async def health_check(self) -&gt; Dict[str, Any]\n</code></pre> <p>F\u00fchrt System-Health-Check durch.</p> <p>Beispiel: <pre><code>health = await client.health_check()\nprint(f\"Status: {health['status']}\")\nprint(f\"Uptime: {health.get('uptime', 'unknown')}\")\n</code></pre></p>"},{"location":"api/unified-client/#register_agent","title":"register_agent()","text":"<pre><code>async def register_agent(\n    self,\n    name: str,\n    version: str,\n    description: str = \"\",\n    capabilities: Optional[List[str]] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>Registriert Agent im KEI-Framework.</p> <p>Beispiel: <pre><code>registration = await client.register_agent(\n    name=\"Report Generator\",\n    version=\"1.0.0\",\n    description=\"Automated report generation agent\",\n    capabilities=[\"pdf_generation\", \"data_analysis\", \"chart_creation\"]\n)\nprint(f\"Registered: {registration['agent_id']}\")\n</code></pre></p>"},{"location":"api/unified-client/#informations-methoden","title":"\ud83d\udd0d Informations-Methoden","text":""},{"location":"api/unified-client/#get_client_info","title":"get_client_info()","text":"<pre><code>def get_client_info(self) -&gt; Dict[str, Any]\n</code></pre> <p>Gibt Client-Informationen zur\u00fcck.</p> <p>Beispiel: <pre><code>info = client.get_client_info()\nprint(f\"Agent ID: {info['agent_id']}\")\nprint(f\"Initialized: {info['initialized']}\")\nprint(f\"Available Protocols: {info['available_protocols']}\")\nprint(f\"Features: {info['features']}\")\n</code></pre></p>"},{"location":"api/unified-client/#get_available_protocols","title":"get_available_protocols()","text":"<pre><code>def get_available_protocols(self) -&gt; List[ProtocolType]\n</code></pre> <p>Gibt Liste verf\u00fcgbarer Protokolle zur\u00fcck.</p> <p>Beispiel: <pre><code>protocols = client.get_available_protocols()\nprint(f\"Verf\u00fcgbare Protokolle: {protocols}\")\n</code></pre></p>"},{"location":"api/unified-client/#is_protocol_available","title":"is_protocol_available()","text":"<pre><code>def is_protocol_available(self, protocol: ProtocolType) -&gt; bool\n</code></pre> <p>Pr\u00fcft ob spezifisches Protokoll verf\u00fcgbar ist.</p> <p>Beispiel: <pre><code>if client.is_protocol_available(ProtocolType.STREAM):\n    print(\"Stream-Protokoll verf\u00fcgbar\")\n</code></pre></p>"},{"location":"api/unified-client/#low-level-api","title":"\u26a1 Low-Level API","text":""},{"location":"api/unified-client/#execute_agent_operation","title":"execute_agent_operation()","text":"<pre><code>async def execute_agent_operation(\n    self,\n    operation: str,\n    data: Dict[str, Any],\n    protocol: Optional[ProtocolType] = None\n) -&gt; Dict[str, Any]\n</code></pre> <p>F\u00fchrt Agent-Operation mit automatischer Protokoll-Auswahl aus.</p> <p>Beispiel: <pre><code># Automatische Protokoll-Auswahl\nresult = await client.execute_agent_operation(\n    \"custom_operation\",\n    {\"param1\": \"value1\", \"param2\": \"value2\"}\n)\n\n# Explizite Protokoll-Auswahl\nresult = await client.execute_agent_operation(\n    \"stream_operation\",\n    {\"data\": \"real-time\"},\n    protocol=ProtocolType.STREAM\n)\n</code></pre></p>"},{"location":"api/unified-client/#exception-handling","title":"\ud83d\udea8 Exception Handling","text":"<p>Der Client kann verschiedene Exceptions werfen:</p> <pre><code>from kei_agent.exceptions import KeiSDKError, ProtocolError, SecurityError\n\ntry:\n    async with UnifiedKeiAgentClient(config=config) as client:\n        result = await client.plan_task(\"objective\")\n\nexcept SecurityError as e:\n    # Authentifizierungs-/Autorisierungsfehler\n    print(f\"Security error: {e}\")\n\nexcept ProtocolError as e:\n    # Protokoll-spezifische Fehler\n    print(f\"Protocol error: {e}\")\n\nexcept KeiSDKError as e:\n    # Allgemeine SDK-Fehler\n    print(f\"SDK error: {e}\")\n\nexcept Exception as e:\n    # Unerwartete Fehler\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"api/unified-client/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"api/unified-client/#1-verwenden-sie-async-context-manager","title":"1. Verwenden Sie Async Context Manager","text":"<pre><code># \u2705 Empfohlen\nasync with UnifiedKeiAgentClient(config=config) as client:\n    result = await client.plan_task(\"objective\")\n\n# \u274c Vermeiden\nclient = UnifiedKeiAgentClient(config=config)\nawait client.initialize()\n# ... vergessen close() aufzurufen\n</code></pre>"},{"location":"api/unified-client/#2-nutzen-sie-high-level-apis","title":"2. Nutzen Sie High-Level APIs","text":"<pre><code># \u2705 Empfohlen - High-Level API\nplan = await client.plan_task(\"Create report\")\n\n# \u274c Vermeiden - Low-Level API ohne Grund\nplan = await client.execute_agent_operation(\"plan\", {\"objective\": \"Create report\"})\n</code></pre>"},{"location":"api/unified-client/#3-konfigurieren-sie-enterprise-features","title":"3. Konfigurieren Sie Enterprise Features","text":"<pre><code># \u2705 Production-ready Konfiguration\nprotocol_config = ProtocolConfig(\n    auto_protocol_selection=True,\n    protocol_fallback_enabled=True\n)\n\nsecurity_config = SecurityConfig(\n    rbac_enabled=True,\n    audit_enabled=True\n)\n</code></pre>"},{"location":"api/unified-client/#4-implementieren-sie-error-handling","title":"4. Implementieren Sie Error Handling","text":"<pre><code># \u2705 Robuste Fehlerbehandlung\ntry:\n    result = await client.plan_task(\"objective\")\nexcept ProtocolError as e:\n    # Fallback-Strategie\n    result = await client.execute_agent_operation(\n        \"plan\",\n        {\"objective\": \"objective\"},\n        protocol=ProtocolType.RPC\n    )\n</code></pre> <p>Siehe auch: - ProtocolTypes \u2192 - Konfigurationsklassen - Enterprise Logging \u2192 - Logging-Integration - Examples \u2192 - Praktische Beispiele</p>"},{"location":"architecture/","title":"Architektur","text":"<p>Das KEI-Agent Python SDK wurde mit einer modernen, modularen Architektur entwickelt, die Enterprise-Anforderungen erf\u00fcllt und gleichzeitig eine einfache Developer Experience bietet.</p>"},{"location":"architecture/#architektur-ubersicht","title":"\ud83c\udfd7\ufe0f Architektur-\u00dcbersicht","text":""},{"location":"architecture/#design-prinzipien","title":"Design-Prinzipien","text":"<p>Das SDK folgt bew\u00e4hrten Software-Engineering-Prinzipien:</p> <ul> <li>Clean Code: Alle Module \u2264200 Zeilen, Funktionen \u226420 Zeilen</li> <li>Single Responsibility: Jedes Modul hat eine klar definierte Verantwortlichkeit</li> <li>Dependency Inversion: Abstrakte Interfaces statt konkrete Implementierungen</li> <li>Open/Closed Principle: Erweiterbar ohne Modifikation bestehender Code</li> <li>Type Safety: 100% Type Hints f\u00fcr alle \u00f6ffentlichen APIs</li> </ul>"},{"location":"architecture/#architektur-diagramm","title":"Architektur-Diagramm","text":"<pre><code>graph TB\n    subgraph \"\ud83c\udfaf KEI-Agent SDK Architecture\"\n        subgraph \"\ud83c\udf10 Client Layer\"\n            UC[UnifiedKeiAgentClient&lt;br/&gt;\ud83d\udcf1 Main API]\n        end\n\n        subgraph \"\ud83d\udd27 Core Components\"\n            PT[ProtocolTypes&lt;br/&gt;\ud83d\udccb Configurations]\n            SM[SecurityManager&lt;br/&gt;\ud83d\udd10 Auth &amp; Tokens]\n            PS[ProtocolSelector&lt;br/&gt;\ud83c\udfaf Smart Selection]\n        end\n\n        subgraph \"\ud83c\udf10 Protocol Layer\"\n            RPC[KEIRPCClient&lt;br/&gt;\u26a1 Sync Operations]\n            STREAM[KEIStreamClient&lt;br/&gt;\ud83c\udf0a Real-time]\n            BUS[KEIBusClient&lt;br/&gt;\ud83d\udce8 Async Messages]\n            MCP[KEIMCPClient&lt;br/&gt;\ud83d\udee0\ufe0f Tool Integration]\n        end\n\n        subgraph \"\ud83d\ude80 Enterprise Layer\"\n            LOG[EnterpriseLogging&lt;br/&gt;\ud83d\udcca Structured JSON]\n            HEALTH[HealthChecks&lt;br/&gt;\ud83d\udc9a Monitoring]\n            VALID[InputValidation&lt;br/&gt;\ud83d\udee1\ufe0f Security]\n        end\n\n        subgraph \"\ud83d\udd0c Transport Layer\"\n            HTTP[HTTP/HTTPS&lt;br/&gt;\ud83c\udf10 REST APIs]\n            WS[WebSockets&lt;br/&gt;\u26a1 Real-time]\n            MSG[Message Bus&lt;br/&gt;\ud83d\udce8 Async]\n        end\n    end\n\n    UC --&gt; PT\n    UC --&gt; SM\n    UC --&gt; PS\n    PS --&gt; RPC\n    PS --&gt; STREAM\n    PS --&gt; BUS\n    PS --&gt; MCP\n    UC --&gt; LOG\n    UC --&gt; HEALTH\n    UC --&gt; VALID\n    RPC --&gt; HTTP\n    STREAM --&gt; WS\n    BUS --&gt; MSG\n    MCP --&gt; HTTP\n\n    style UC fill:#e1f5fe\n    style LOG fill:#f3e5f5\n    style HEALTH fill:#e8f5e8\n    style VALID fill:#fff3e0\n    style RPC fill:#e3f2fd\n    style STREAM fill:#e0f2f1\n    style BUS fill:#fff8e1\n    style MCP fill:#fce4ec</code></pre>"},{"location":"architecture/#modul-struktur","title":"\ud83d\udce6 Modul-Struktur","text":""},{"location":"architecture/#core-module","title":"Core-Module","text":"Modul Verantwortlichkeit Zeilen Abh\u00e4ngigkeiten <code>unified_client_refactored.py</code> Haupt-API-Interface 180 Core Components <code>protocol_types.py</code> Typ-Definitionen und Konfigurationen 150 Pydantic, Enum <code>security_manager.py</code> Authentifizierung und Token-Management 190 httpx, asyncio <code>protocol_selector.py</code> Intelligente Protokoll-Auswahl 170 Core Types"},{"location":"architecture/#protocol-module","title":"Protocol-Module","text":"Modul Verantwortlichkeit Zeilen Protokoll <code>protocol_clients.py</code> Alle Protokoll-Client-Implementierungen 200 KEI-RPC, Stream, Bus, MCP"},{"location":"architecture/#enterprise-module","title":"Enterprise-Module","text":"Modul Verantwortlichkeit Zeilen Features <code>enterprise_logging.py</code> Strukturiertes JSON-Logging 180 Correlation-IDs, Performance <code>health_checks.py</code> System-Monitoring 190 Database, API, Memory Checks <code>input_validation.py</code> Input-Validierung und Sanitization 200 Security, XSS/SQL Prevention"},{"location":"architecture/#datenfluss","title":"\ud83d\udd04 Datenfluss","text":""},{"location":"architecture/#request-response-zyklus","title":"Request-Response-Zyklus","text":"<pre><code>sequenceDiagram\n    participant App as Application\n    participant UC as UnifiedClient\n    participant PS as ProtocolSelector\n    participant PC as ProtocolClient\n    participant API as KEI-API\n\n    App-&gt;&gt;UC: plan_task(\"objective\")\n    UC-&gt;&gt;PS: select_protocol(\"plan\", context)\n    PS-&gt;&gt;UC: ProtocolType.RPC\n    UC-&gt;&gt;PC: KEIRPCClient.plan(objective)\n    PC-&gt;&gt;API: POST /api/v1/rpc/plan\n    API-&gt;&gt;PC: {\"plan_id\": \"123\", \"steps\": [...]}\n    PC-&gt;&gt;UC: Plan Response\n    UC-&gt;&gt;App: Plan Result</code></pre>"},{"location":"architecture/#fallback-mechanismus","title":"Fallback-Mechanismus","text":"<pre><code>sequenceDiagram\n    participant UC as UnifiedClient\n    participant PS as ProtocolSelector\n    participant RPC as RPC Client\n    participant BUS as Bus Client\n\n    UC-&gt;&gt;PS: select_protocol(\"operation\")\n    PS-&gt;&gt;UC: ProtocolType.RPC (primary)\n    UC-&gt;&gt;RPC: execute_operation()\n    RPC--&gt;&gt;UC: ProtocolError\n    UC-&gt;&gt;PS: get_fallback_chain(RPC)\n    PS-&gt;&gt;UC: [RPC, BUS, MCP]\n    UC-&gt;&gt;BUS: execute_operation() (fallback)\n    BUS-&gt;&gt;UC: Success Response</code></pre>"},{"location":"architecture/#design-patterns","title":"\ud83c\udfaf Design Patterns","text":""},{"location":"architecture/#1-factory-pattern","title":"1. Factory Pattern","text":"<pre><code># Protocol Client Factory\ndef create_protocol_client(protocol: ProtocolType, base_url: str, security: SecurityManager):\n    if protocol == ProtocolType.RPC:\n        return KEIRPCClient(base_url, security)\n    elif protocol == ProtocolType.STREAM:\n        return KEIStreamClient(base_url, security)\n    # ...\n</code></pre>"},{"location":"architecture/#2-strategy-pattern","title":"2. Strategy Pattern","text":"<pre><code># Protocol Selection Strategy\nclass ProtocolSelector:\n    def select_protocol(self, operation: str, context: Dict[str, Any]) -&gt; ProtocolType:\n        # Intelligente Auswahl basierend auf Operation und Kontext\n        if \"stream\" in operation.lower():\n            return ProtocolType.STREAM\n        elif \"async\" in operation.lower():\n            return ProtocolType.BUS\n        # ...\n</code></pre>"},{"location":"architecture/#3-decorator-pattern","title":"3. Decorator Pattern","text":"<pre><code># Logging Decorator\ndef log_operation(func):\n    async def wrapper(*args, **kwargs):\n        operation_id = logger.log_operation_start(func.__name__)\n        try:\n            result = await func(*args, **kwargs)\n            logger.log_operation_end(func.__name__, operation_id, success=True)\n            return result\n        except Exception as e:\n            logger.log_operation_end(func.__name__, operation_id, success=False)\n            raise\n    return wrapper\n</code></pre>"},{"location":"architecture/#4-observer-pattern","title":"4. Observer Pattern","text":"<pre><code># Health Check Observer\nclass HealthCheckManager:\n    def __init__(self):\n        self.observers = []\n\n    def register_observer(self, observer):\n        self.observers.append(observer)\n\n    def notify_health_change(self, status):\n        for observer in self.observers:\n            observer.on_health_change(status)\n</code></pre>"},{"location":"architecture/#security-architektur","title":"\ud83d\udd10 Security-Architektur","text":""},{"location":"architecture/#authentifizierung-flow","title":"Authentifizierung-Flow","text":"<pre><code>graph LR\n    subgraph \"\ud83d\udd10 Security Architecture\"\n        APP[Application] --&gt; SM[SecurityManager]\n        SM --&gt; |Bearer| BEARER[Bearer Token Auth]\n        SM --&gt; |OIDC| OIDC[OIDC Flow]\n        SM --&gt; |mTLS| MTLS[Mutual TLS]\n\n        BEARER --&gt; CACHE[Token Cache]\n        OIDC --&gt; CACHE\n        CACHE --&gt; REFRESH[Auto Refresh]\n\n        SM --&gt; RBAC[RBAC Check]\n        SM --&gt; AUDIT[Audit Log]\n    end\n\n    style SM fill:#ffebee\n    style RBAC fill:#e8f5e8\n    style AUDIT fill:#fff3e0</code></pre>"},{"location":"architecture/#security-layers","title":"Security-Layers","text":"<ol> <li>Transport Security: HTTPS/TLS f\u00fcr alle Verbindungen</li> <li>Authentication: Bearer Token, OIDC oder mTLS</li> <li>Authorization: Role-Based Access Control (RBAC)</li> <li>Input Validation: Umfassende Sanitization und Validierung</li> <li>Audit Logging: Vollst\u00e4ndige Nachverfolgbarkeit</li> </ol>"},{"location":"architecture/#performance-architektur","title":"\ud83d\udcca Performance-Architektur","text":""},{"location":"architecture/#async-first-design","title":"Async-First Design","text":"<pre><code># Alle I/O-Operationen sind asynchron\nasync def plan_task(self, objective: str) -&gt; Dict[str, Any]:\n    async with self._get_protocol_client(ProtocolType.RPC) as client:\n        return await client.plan(objective)\n</code></pre>"},{"location":"architecture/#connection-pooling","title":"Connection Pooling","text":"<pre><code># HTTP-Client mit Connection Pooling\nself._client = httpx.AsyncClient(\n    limits=httpx.Limits(max_keepalive_connections=20, max_connections=100),\n    timeout=httpx.Timeout(30.0)\n)\n</code></pre>"},{"location":"architecture/#caching-strategien","title":"Caching-Strategien","text":"<ul> <li>Token Caching: Authentifizierungs-Token werden gecacht</li> <li>Protocol Selection: Intelligente Auswahl wird gecacht</li> <li>Health Check Results: Tempor\u00e4res Caching f\u00fcr Performance</li> </ul>"},{"location":"architecture/#erweiterbarkeit","title":"\ud83d\udd04 Erweiterbarkeit","text":""},{"location":"architecture/#plugin-architektur","title":"Plugin-Architektur","text":"<pre><code># Custom Protocol Client\nclass CustomProtocolClient(BaseProtocolClient):\n    async def custom_operation(self, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        # Custom implementation\n        pass\n\n# Registration\nprotocol_selector.register_protocol(\"custom\", CustomProtocolClient)\n</code></pre>"},{"location":"architecture/#custom-health-checks","title":"Custom Health Checks","text":"<pre><code># Custom Health Check\nclass DatabaseHealthCheck(BaseHealthCheck):\n    async def check(self) -&gt; HealthCheckResult:\n        # Custom health check logic\n        pass\n\n# Registration\nhealth_manager.register_check(DatabaseHealthCheck(\"database\"))\n</code></pre>"},{"location":"architecture/#custom-validators","title":"Custom Validators","text":"<pre><code># Custom Input Validator\nclass EmailValidator(BaseValidator):\n    def validate(self, value: Any) -&gt; ValidationResult:\n        # Custom validation logic\n        pass\n\n# Registration\ninput_validator.register_validator(\"email\", EmailValidator(\"email\"))\n</code></pre>"},{"location":"architecture/#testing-architektur","title":"\ud83e\uddea Testing-Architektur","text":""},{"location":"architecture/#test-pyramide","title":"Test-Pyramide","text":"<pre><code>graph TB\n    subgraph \"\ud83e\uddea Testing Architecture\"\n        E2E[End-to-End Tests&lt;br/&gt;\ud83d\udd17 Full Integration]\n        INT[Integration Tests&lt;br/&gt;\ud83d\udd0c Protocol Tests]\n        UNIT[Unit Tests&lt;br/&gt;\u26a1 Component Tests]\n\n        E2E --&gt; INT\n        INT --&gt; UNIT\n    end\n\n    style UNIT fill:#e8f5e8\n    style INT fill:#fff3e0\n    style E2E fill:#ffebee</code></pre>"},{"location":"architecture/#test-kategorien","title":"Test-Kategorien","text":"<ul> <li>Unit Tests: Isolierte Komponenten-Tests (85%+ Coverage)</li> <li>Integration Tests: Protokoll-Integration-Tests</li> <li>Security Tests: Sicherheits-spezifische Tests</li> <li>Performance Tests: Load- und Stress-Tests</li> </ul>"},{"location":"architecture/#monitoring-architektur","title":"\ud83d\udcc8 Monitoring-Architektur","text":""},{"location":"architecture/#observability-stack","title":"Observability-Stack","text":"<pre><code>graph TB\n    subgraph \"\ud83d\udcca Observability\"\n        LOGS[Structured Logs&lt;br/&gt;\ud83d\udcdd JSON Format]\n        METRICS[Performance Metrics&lt;br/&gt;\ud83d\udcca Timing &amp; Resources]\n        TRACES[Distributed Tracing&lt;br/&gt;\ud83d\udd0d Request Flow]\n        HEALTH[Health Checks&lt;br/&gt;\ud83d\udc9a System Status]\n\n        LOGS --&gt; COLLECT[Log Collector]\n        METRICS --&gt; COLLECT\n        TRACES --&gt; COLLECT\n        HEALTH --&gt; COLLECT\n\n        COLLECT --&gt; MONITOR[Monitoring System]\n    end\n\n    style LOGS fill:#e3f2fd\n    style METRICS fill:#e8f5e8\n    style TRACES fill:#fff3e0\n    style HEALTH fill:#f3e5f5</code></pre>"},{"location":"architecture/#monitoring-features","title":"Monitoring-Features","text":"<ul> <li>Structured Logging: JSON-Format mit Correlation-IDs</li> <li>Performance Metrics: Request-Timing und Resource-Usage</li> <li>Health Checks: Proaktive System-\u00dcberwachung</li> <li>Distributed Tracing: End-to-End Request-Verfolgung</li> </ul> <p>Weitere Architektur-Details: - \u00dcberblick \u2192 - Detaillierte Architektur-\u00dcbersicht - Design Patterns \u2192 - Verwendete Design Patterns - Modulstruktur \u2192 - Detaillierte Modul-Beschreibungen - Protocol Integration \u2192 - Multi-Protocol-Architektur</p>"},{"location":"architecture/design-patterns/","title":"\ud83c\udfa8 Design-Patterns","text":"<p>Keiko Personal Assistant nutzt bew\u00e4hrte Design-Patterns f\u00fcr saubere, wartbare und erweiterbare Architektur.</p>"},{"location":"architecture/design-patterns/#architektur-patterns","title":"\ud83c\udfd7\ufe0f Architektur-Patterns","text":""},{"location":"architecture/design-patterns/#clean-architecture","title":"Clean Architecture","text":"<pre><code>graph TB\n    subgraph \"External Layer\"\n        WEB[Web Interface]\n        DB[Database]\n        API[External APIs]\n    end\n\n    subgraph \"Interface Adapters\"\n        CTRL[Controllers]\n        REPO[Repositories]\n        PRESENT[Presenters]\n    end\n\n    subgraph \"Use Cases\"\n        AGENT[Agent Use Cases]\n        TASK[Task Use Cases]\n        USER[User Use Cases]\n    end\n\n    subgraph \"Entities\"\n        DOMAIN[Domain Models]\n        BUSINESS[Business Rules]\n    end\n\n    WEB --&gt; CTRL\n    DB --&gt; REPO\n    API --&gt; PRESENT\n\n    CTRL --&gt; AGENT\n    REPO --&gt; TASK\n    PRESENT --&gt; USER\n\n    AGENT --&gt; DOMAIN\n    TASK --&gt; BUSINESS\n    USER --&gt; DOMAIN</code></pre>"},{"location":"architecture/design-patterns/#implementation","title":"Implementation","text":"<pre><code># Domain Layer - Entities\nclass Agent:\n    \"\"\"Domain-Entity f\u00fcr Agenten.\"\"\"\n\n    def __init__(self, agent_id: str, name: str, agent_type: str):\n        self.id = agent_id\n        self.name = name\n        self.type = agent_type\n        self._status = AgentStatus.INACTIVE\n\n    def activate(self) -&gt; None:\n        \"\"\"Business Rule: Agent aktivieren.\"\"\"\n        if self.type == \"system\" and not self._has_required_permissions():\n            raise DomainException(\"System-Agent ben\u00f6tigt spezielle Berechtigungen\")\n        self._status = AgentStatus.ACTIVE\n\n    def can_execute_task(self, task_type: str) -&gt; bool:\n        \"\"\"Business Rule: Task-Ausf\u00fchrung pr\u00fcfen.\"\"\"\n        return (\n            self._status == AgentStatus.ACTIVE and\n            task_type in self._supported_task_types()\n        )\n\n# Use Case Layer\nclass ExecuteAgentTaskUseCase:\n    \"\"\"Use Case f\u00fcr Agent-Task-Ausf\u00fchrung.\"\"\"\n\n    def __init__(self, agent_repo: AgentRepository, task_repo: TaskRepository):\n        self.agent_repo = agent_repo\n        self.task_repo = task_repo\n\n    async def execute(self, request: ExecuteTaskRequest) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Agent-Task aus.\"\"\"\n        # 1. Agent laden\n        agent = await self.agent_repo.get_by_id(request.agent_id)\n        if not agent:\n            raise AgentNotFoundException(request.agent_id)\n\n        # 2. Business Rules pr\u00fcfen\n        if not agent.can_execute_task(request.task_type):\n            raise TaskExecutionNotAllowedException(agent.id, request.task_type)\n\n        # 3. Task erstellen und ausf\u00fchren\n        task = Task.create(request.task_type, request.parameters)\n        result = await agent.execute_task(task)\n\n        # 4. Ergebnis speichern\n        await self.task_repo.save_result(task.id, result)\n\n        return result\n\n# Interface Adapter Layer\nclass AgentController:\n    \"\"\"Controller f\u00fcr Agent-API.\"\"\"\n\n    def __init__(self, execute_task_use_case: ExecuteAgentTaskUseCase):\n        self.execute_task_use_case = execute_task_use_case\n\n    async def execute_task(self, request: HTTPRequest) -&gt; HTTPResponse:\n        \"\"\"HTTP-Endpunkt f\u00fcr Task-Ausf\u00fchrung.\"\"\"\n        try:\n            # Request validieren und konvertieren\n            task_request = ExecuteTaskRequest.from_http(request)\n\n            # Use Case ausf\u00fchren\n            result = await self.execute_task_use_case.execute(task_request)\n\n            # Response erstellen\n            return HTTPResponse.success(result.to_dict())\n\n        except DomainException as e:\n            return HTTPResponse.bad_request(str(e))\n        except Exception as e:\n            return HTTPResponse.internal_error(\"Task execution failed\")\n</code></pre>"},{"location":"architecture/design-patterns/#repository-pattern","title":"Repository Pattern","text":"<pre><code>from abc import ABC, abstractmethod\nfrom typing import List, Optional\n\n# Abstract Repository\nclass AgentRepository(ABC):\n    \"\"\"Abstract Repository f\u00fcr Agenten.\"\"\"\n\n    @abstractmethod\n    async def get_by_id(self, agent_id: str) -&gt; Optional[Agent]:\n        \"\"\"L\u00e4dt Agent nach ID.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_by_type(self, agent_type: str) -&gt; List[Agent]:\n        \"\"\"L\u00e4dt Agenten nach Typ.\"\"\"\n        pass\n\n    @abstractmethod\n    async def save(self, agent: Agent) -&gt; None:\n        \"\"\"Speichert Agent.\"\"\"\n        pass\n\n    @abstractmethod\n    async def delete(self, agent_id: str) -&gt; None:\n        \"\"\"L\u00f6scht Agent.\"\"\"\n        pass\n\n# Concrete Repository\nclass PostgreSQLAgentRepository(AgentRepository):\n    \"\"\"PostgreSQL-Implementation des Agent-Repository.\"\"\"\n\n    def __init__(self, db_session: AsyncSession):\n        self.db_session = db_session\n\n    async def get_by_id(self, agent_id: str) -&gt; Optional[Agent]:\n        \"\"\"L\u00e4dt Agent aus PostgreSQL.\"\"\"\n        query = select(AgentModel).where(AgentModel.id == agent_id)\n        result = await self.db_session.execute(query)\n        agent_model = result.scalar_one_or_none()\n\n        if agent_model:\n            return Agent.from_model(agent_model)\n        return None\n\n    async def save(self, agent: Agent) -&gt; None:\n        \"\"\"Speichert Agent in PostgreSQL.\"\"\"\n        agent_model = AgentModel.from_domain(agent)\n        self.db_session.add(agent_model)\n        await self.db_session.commit()\n\n# In-Memory Repository f\u00fcr Tests\nclass InMemoryAgentRepository(AgentRepository):\n    \"\"\"In-Memory-Implementation f\u00fcr Tests.\"\"\"\n\n    def __init__(self):\n        self._agents: Dict[str, Agent] = {}\n\n    async def get_by_id(self, agent_id: str) -&gt; Optional[Agent]:\n        return self._agents.get(agent_id)\n\n    async def save(self, agent: Agent) -&gt; None:\n        self._agents[agent.id] = agent\n</code></pre>"},{"location":"architecture/design-patterns/#creational-patterns","title":"\ud83d\udd27 Creational Patterns","text":""},{"location":"architecture/design-patterns/#factory-pattern","title":"Factory Pattern","text":"<pre><code>from enum import Enum\nfrom typing import Dict, Type\n\nclass AgentType(Enum):\n    ORCHESTRATOR = \"orchestrator\"\n    SPECIALIST = \"specialist\"\n    WORKFLOW = \"workflow\"\n    EXAMPLE = \"example\"\n\nclass AgentFactory:\n    \"\"\"Factory f\u00fcr Agent-Erstellung.\"\"\"\n\n    _agent_classes: Dict[AgentType, Type[Agent]] = {\n        AgentType.ORCHESTRATOR: OrchestratorAgent,\n        AgentType.SPECIALIST: SpecialistAgent,\n        AgentType.WORKFLOW: WorkflowAgent,\n        AgentType.EXAMPLE: ExampleAgent\n    }\n\n    @classmethod\n    def create_agent(\n        cls,\n        agent_type: AgentType,\n        config: AgentConfig\n    ) -&gt; Agent:\n        \"\"\"Erstellt Agent basierend auf Typ.\"\"\"\n\n        agent_class = cls._agent_classes.get(agent_type)\n        if not agent_class:\n            raise ValueError(f\"Unbekannter Agent-Typ: {agent_type}\")\n\n        return agent_class(config)\n\n    @classmethod\n    def register_agent_type(\n        cls,\n        agent_type: AgentType,\n        agent_class: Type[Agent]\n    ) -&gt; None:\n        \"\"\"Registriert neuen Agent-Typ.\"\"\"\n        cls._agent_classes[agent_type] = agent_class\n\n# Abstract Factory f\u00fcr Protocol-Clients\nclass ProtocolClientFactory:\n    \"\"\"Abstract Factory f\u00fcr Protocol-Clients.\"\"\"\n\n    @staticmethod\n    def create_http_client(config: HTTPConfig) -&gt; HTTPClient:\n        \"\"\"Erstellt HTTP-Client.\"\"\"\n        return HTTPClient(config)\n\n    @staticmethod\n    def create_websocket_client(config: WebSocketConfig) -&gt; WebSocketClient:\n        \"\"\"Erstellt WebSocket-Client.\"\"\"\n        return WebSocketClient(config)\n\n    @staticmethod\n    def create_mcp_client(config: MCPConfig) -&gt; MCPClient:\n        \"\"\"Erstellt MCP-Client.\"\"\"\n        return MCPClient(config)\n</code></pre>"},{"location":"architecture/design-patterns/#builder-pattern","title":"Builder Pattern","text":"<pre><code>class AgentConfigBuilder:\n    \"\"\"Builder f\u00fcr Agent-Konfiguration.\"\"\"\n\n    def __init__(self):\n        self._config = AgentConfig()\n\n    def with_name(self, name: str) -&gt; 'AgentConfigBuilder':\n        \"\"\"Setzt Agent-Name.\"\"\"\n        self._config.name = name\n        return self\n\n    def with_type(self, agent_type: AgentType) -&gt; 'AgentConfigBuilder':\n        \"\"\"Setzt Agent-Typ.\"\"\"\n        self._config.type = agent_type\n        return self\n\n    def with_capability(self, capability: str) -&gt; 'AgentConfigBuilder':\n        \"\"\"F\u00fcgt Capability hinzu.\"\"\"\n        self._config.capabilities.append(capability)\n        return self\n\n    def with_timeout(self, timeout_seconds: int) -&gt; 'AgentConfigBuilder':\n        \"\"\"Setzt Timeout.\"\"\"\n        self._config.timeout_seconds = timeout_seconds\n        return self\n\n    def with_retry_policy(self, max_retries: int, delay: float) -&gt; 'AgentConfigBuilder':\n        \"\"\"Konfiguriert Retry-Policy.\"\"\"\n        self._config.retry_policy = RetryPolicy(max_retries, delay)\n        return self\n\n    def build(self) -&gt; AgentConfig:\n        \"\"\"Erstellt finale Konfiguration.\"\"\"\n        if not self._config.name:\n            raise ValueError(\"Agent-Name ist erforderlich\")\n        if not self._config.type:\n            raise ValueError(\"Agent-Typ ist erforderlich\")\n\n        return self._config\n\n# Verwendung\nconfig = (AgentConfigBuilder()\n    .with_name(\"Image Generator\")\n    .with_type(AgentType.SPECIALIST)\n    .with_capability(\"image_generation\")\n    .with_capability(\"image_editing\")\n    .with_timeout(300)\n    .with_retry_policy(max_retries=3, delay=1.0)\n    .build())\n</code></pre>"},{"location":"architecture/design-patterns/#behavioral-patterns","title":"\ud83d\udd04 Behavioral Patterns","text":""},{"location":"architecture/design-patterns/#strategy-pattern","title":"Strategy Pattern","text":"<pre><code>from abc import ABC, abstractmethod\n\n# Strategy Interface\nclass TaskExecutionStrategy(ABC):\n    \"\"\"Strategy f\u00fcr Task-Ausf\u00fchrung.\"\"\"\n\n    @abstractmethod\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task aus.\"\"\"\n        pass\n\n# Concrete Strategies\nclass SynchronousExecutionStrategy(TaskExecutionStrategy):\n    \"\"\"Synchrone Task-Ausf\u00fchrung.\"\"\"\n\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task synchron aus.\"\"\"\n        start_time = time.time()\n\n        try:\n            result = await self._execute_task_logic(task)\n            return TaskResult.success(result, time.time() - start_time)\n        except Exception as e:\n            return TaskResult.failure(str(e), time.time() - start_time)\n\nclass AsynchronousExecutionStrategy(TaskExecutionStrategy):\n    \"\"\"Asynchrone Task-Ausf\u00fchrung.\"\"\"\n\n    def __init__(self, task_queue: TaskQueue):\n        self.task_queue = task_queue\n\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task asynchron aus.\"\"\"\n        # Task in Queue einreihen\n        await self.task_queue.enqueue(task)\n\n        # Sofortiges Result mit Task-ID\n        return TaskResult.pending(task.id)\n\nclass BatchExecutionStrategy(TaskExecutionStrategy):\n    \"\"\"Batch-Task-Ausf\u00fchrung.\"\"\"\n\n    def __init__(self, batch_size: int = 10):\n        self.batch_size = batch_size\n        self.batch: List[Task] = []\n\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"Sammelt Tasks f\u00fcr Batch-Ausf\u00fchrung.\"\"\"\n        self.batch.append(task)\n\n        if len(self.batch) &gt;= self.batch_size:\n            return await self._execute_batch()\n\n        return TaskResult.batched(task.id)\n\n# Context\nclass TaskExecutor:\n    \"\"\"Context f\u00fcr Task-Ausf\u00fchrung.\"\"\"\n\n    def __init__(self, strategy: TaskExecutionStrategy):\n        self._strategy = strategy\n\n    def set_strategy(self, strategy: TaskExecutionStrategy) -&gt; None:\n        \"\"\"\u00c4ndert Ausf\u00fchrungsstrategie.\"\"\"\n        self._strategy = strategy\n\n    async def execute_task(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task mit aktueller Strategie aus.\"\"\"\n        return await self._strategy.execute(task)\n</code></pre>"},{"location":"architecture/design-patterns/#observer-pattern","title":"Observer Pattern","text":"<pre><code>from typing import List, Callable\nfrom abc import ABC, abstractmethod\n\n# Observer Interface\nclass TaskObserver(ABC):\n    \"\"\"Observer f\u00fcr Task-Events.\"\"\"\n\n    @abstractmethod\n    async def on_task_created(self, task: Task) -&gt; None:\n        \"\"\"Wird aufgerufen, wenn Task erstellt wird.\"\"\"\n        pass\n\n    @abstractmethod\n    async def on_task_started(self, task: Task) -&gt; None:\n        \"\"\"Wird aufgerufen, wenn Task startet.\"\"\"\n        pass\n\n    @abstractmethod\n    async def on_task_completed(self, task: Task, result: TaskResult) -&gt; None:\n        \"\"\"Wird aufgerufen, wenn Task abgeschlossen wird.\"\"\"\n        pass\n\n    @abstractmethod\n    async def on_task_failed(self, task: Task, error: Exception) -&gt; None:\n        \"\"\"Wird aufgerufen, wenn Task fehlschl\u00e4gt.\"\"\"\n        pass\n\n# Concrete Observers\nclass MetricsObserver(TaskObserver):\n    \"\"\"Observer f\u00fcr Metriken-Sammlung.\"\"\"\n\n    async def on_task_created(self, task: Task) -&gt; None:\n        TASK_CREATED_COUNTER.labels(task_type=task.type).inc()\n\n    async def on_task_completed(self, task: Task, result: TaskResult) -&gt; None:\n        TASK_DURATION_HISTOGRAM.labels(task_type=task.type).observe(result.duration)\n        TASK_COMPLETED_COUNTER.labels(task_type=task.type, status=\"success\").inc()\n\n    async def on_task_failed(self, task: Task, error: Exception) -&gt; None:\n        TASK_COMPLETED_COUNTER.labels(task_type=task.type, status=\"failed\").inc()\n\nclass NotificationObserver(TaskObserver):\n    \"\"\"Observer f\u00fcr Benachrichtigungen.\"\"\"\n\n    def __init__(self, notification_service: NotificationService):\n        self.notification_service = notification_service\n\n    async def on_task_completed(self, task: Task, result: TaskResult) -&gt; None:\n        if task.notify_on_completion:\n            await self.notification_service.send_completion_notification(\n                task.user_id, task.id, result\n            )\n\nclass AuditObserver(TaskObserver):\n    \"\"\"Observer f\u00fcr Audit-Logging.\"\"\"\n\n    def __init__(self, audit_logger: AuditLogger):\n        self.audit_logger = audit_logger\n\n    async def on_task_created(self, task: Task) -&gt; None:\n        await self.audit_logger.log_task_created(task)\n\n    async def on_task_completed(self, task: Task, result: TaskResult) -&gt; None:\n        await self.audit_logger.log_task_completed(task, result)\n\n# Subject\nclass TaskSubject:\n    \"\"\"Subject f\u00fcr Task-Events.\"\"\"\n\n    def __init__(self):\n        self._observers: List[TaskObserver] = []\n\n    def attach(self, observer: TaskObserver) -&gt; None:\n        \"\"\"F\u00fcgt Observer hinzu.\"\"\"\n        self._observers.append(observer)\n\n    def detach(self, observer: TaskObserver) -&gt; None:\n        \"\"\"Entfernt Observer.\"\"\"\n        self._observers.remove(observer)\n\n    async def notify_task_created(self, task: Task) -&gt; None:\n        \"\"\"Benachrichtigt Observer \u00fcber Task-Erstellung.\"\"\"\n        for observer in self._observers:\n            await observer.on_task_created(task)\n\n    async def notify_task_completed(self, task: Task, result: TaskResult) -&gt; None:\n        \"\"\"Benachrichtigt Observer \u00fcber Task-Abschluss.\"\"\"\n        for observer in self._observers:\n            await observer.on_task_completed(task, result)\n</code></pre>"},{"location":"architecture/design-patterns/#command-pattern","title":"Command Pattern","text":"<pre><code>from abc import ABC, abstractmethod\nfrom typing import Any, Optional\n\n# Command Interface\nclass Command(ABC):\n    \"\"\"Command Interface.\"\"\"\n\n    @abstractmethod\n    async def execute(self) -&gt; Any:\n        \"\"\"F\u00fchrt Command aus.\"\"\"\n        pass\n\n    @abstractmethod\n    async def undo(self) -&gt; Any:\n        \"\"\"Macht Command r\u00fcckg\u00e4ngig.\"\"\"\n        pass\n\n# Concrete Commands\nclass CreateAgentCommand(Command):\n    \"\"\"Command f\u00fcr Agent-Erstellung.\"\"\"\n\n    def __init__(self, agent_service: AgentService, config: AgentConfig):\n        self.agent_service = agent_service\n        self.config = config\n        self.created_agent_id: Optional[str] = None\n\n    async def execute(self) -&gt; str:\n        \"\"\"Erstellt Agent.\"\"\"\n        agent = await self.agent_service.create_agent(self.config)\n        self.created_agent_id = agent.id\n        return agent.id\n\n    async def undo(self) -&gt; None:\n        \"\"\"L\u00f6scht erstellten Agent.\"\"\"\n        if self.created_agent_id:\n            await self.agent_service.delete_agent(self.created_agent_id)\n\nclass ExecuteTaskCommand(Command):\n    \"\"\"Command f\u00fcr Task-Ausf\u00fchrung.\"\"\"\n\n    def __init__(self, task_service: TaskService, task_request: TaskRequest):\n        self.task_service = task_service\n        self.task_request = task_request\n        self.task_id: Optional[str] = None\n\n    async def execute(self) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task aus.\"\"\"\n        task = await self.task_service.create_task(self.task_request)\n        self.task_id = task.id\n        return await self.task_service.execute_task(task.id)\n\n    async def undo(self) -&gt; None:\n        \"\"\"Bricht Task ab.\"\"\"\n        if self.task_id:\n            await self.task_service.cancel_task(self.task_id)\n\n# Command Invoker\nclass CommandInvoker:\n    \"\"\"Invoker f\u00fcr Commands.\"\"\"\n\n    def __init__(self):\n        self._command_history: List[Command] = []\n\n    async def execute_command(self, command: Command) -&gt; Any:\n        \"\"\"F\u00fchrt Command aus und speichert in Historie.\"\"\"\n        result = await command.execute()\n        self._command_history.append(command)\n        return result\n\n    async def undo_last_command(self) -&gt; None:\n        \"\"\"Macht letztes Command r\u00fcckg\u00e4ngig.\"\"\"\n        if self._command_history:\n            last_command = self._command_history.pop()\n            await last_command.undo()\n\n    async def undo_all_commands(self) -&gt; None:\n        \"\"\"Macht alle Commands r\u00fcckg\u00e4ngig.\"\"\"\n        while self._command_history:\n            await self.undo_last_command()\n</code></pre>"},{"location":"architecture/design-patterns/#structural-patterns","title":"\ud83d\udd17 Structural Patterns","text":""},{"location":"architecture/design-patterns/#adapter-pattern","title":"Adapter Pattern","text":"<pre><code># Target Interface\nclass MCPToolInterface(ABC):\n    \"\"\"Standard-Interface f\u00fcr MCP-Tools.\"\"\"\n\n    @abstractmethod\n    async def execute(self, arguments: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"F\u00fchrt Tool aus.\"\"\"\n        pass\n\n# Adaptee (Legacy System)\nclass LegacyWeatherAPI:\n    \"\"\"Legacy Weather API.\"\"\"\n\n    def get_weather_data(self, city: str, country: str) -&gt; dict:\n        \"\"\"Legacy-Methode f\u00fcr Wetterdaten.\"\"\"\n        # Legacy-Implementation\n        return {\"temperature\": 20, \"humidity\": 60}\n\n# Adapter\nclass WeatherAPIAdapter(MCPToolInterface):\n    \"\"\"Adapter f\u00fcr Legacy Weather API.\"\"\"\n\n    def __init__(self, legacy_api: LegacyWeatherAPI):\n        self.legacy_api = legacy_api\n\n    async def execute(self, arguments: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Adaptiert Legacy-API f\u00fcr MCP-Interface.\"\"\"\n        city = arguments.get(\"city\")\n        country = arguments.get(\"country\", \"\")\n\n        # Legacy-API aufrufen\n        weather_data = self.legacy_api.get_weather_data(city, country)\n\n        # Format f\u00fcr MCP anpassen\n        return {\n            \"location\": f\"{city}, {country}\",\n            \"temperature_celsius\": weather_data[\"temperature\"],\n            \"humidity_percent\": weather_data[\"humidity\"],\n            \"timestamp\": time.time()\n        }\n</code></pre>"},{"location":"architecture/design-patterns/#decorator-pattern","title":"Decorator Pattern","text":"<pre><code># Component Interface\nclass TaskExecutor(ABC):\n    \"\"\"Interface f\u00fcr Task-Ausf\u00fchrung.\"\"\"\n\n    @abstractmethod\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task aus.\"\"\"\n        pass\n\n# Concrete Component\nclass BasicTaskExecutor(TaskExecutor):\n    \"\"\"Basis-Task-Executor.\"\"\"\n\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task aus.\"\"\"\n        # Basis-Implementation\n        return await self._execute_task_logic(task)\n\n# Decorators\nclass LoggingTaskExecutor(TaskExecutor):\n    \"\"\"Decorator f\u00fcr Logging.\"\"\"\n\n    def __init__(self, executor: TaskExecutor):\n        self._executor = executor\n\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task mit Logging aus.\"\"\"\n        logger.info(f\"Starting task execution: {task.id}\")\n\n        try:\n            result = await self._executor.execute(task)\n            logger.info(f\"Task completed successfully: {task.id}\")\n            return result\n        except Exception as e:\n            logger.error(f\"Task failed: {task.id}, error: {e}\")\n            raise\n\nclass MetricsTaskExecutor(TaskExecutor):\n    \"\"\"Decorator f\u00fcr Metriken.\"\"\"\n\n    def __init__(self, executor: TaskExecutor):\n        self._executor = executor\n\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task mit Metriken aus.\"\"\"\n        start_time = time.time()\n\n        try:\n            result = await self._executor.execute(task)\n            TASK_DURATION_HISTOGRAM.observe(time.time() - start_time)\n            TASK_SUCCESS_COUNTER.inc()\n            return result\n        except Exception as e:\n            TASK_FAILURE_COUNTER.inc()\n            raise\n\nclass RetryTaskExecutor(TaskExecutor):\n    \"\"\"Decorator f\u00fcr Retry-Logic.\"\"\"\n\n    def __init__(self, executor: TaskExecutor, max_retries: int = 3):\n        self._executor = executor\n        self.max_retries = max_retries\n\n    async def execute(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task mit Retry aus.\"\"\"\n        last_exception = None\n\n        for attempt in range(self.max_retries + 1):\n            try:\n                return await self._executor.execute(task)\n            except Exception as e:\n                last_exception = e\n                if attempt &lt; self.max_retries:\n                    await asyncio.sleep(2 ** attempt)  # Exponential backoff\n                    continue\n                raise last_exception\n\n# Verwendung mit mehreren Decorators\nexecutor = RetryTaskExecutor(\n    MetricsTaskExecutor(\n        LoggingTaskExecutor(\n            BasicTaskExecutor()\n        )\n    ),\n    max_retries=3\n)\n</code></pre> <p>Pattern-Auswahl</p> <p>Die Wahl des richtigen Design-Patterns h\u00e4ngt vom spezifischen Problem ab. Verwenden Sie Patterns nur wenn sie echten Mehrwert bieten, nicht um der Patterns willen.</p> <p>Kombinationen</p> <p>Viele Patterns k\u00f6nnen effektiv kombiniert werden. Beispielsweise kann ein Factory Pattern mit Strategy Pattern kombiniert werden, um verschiedene Strategien basierend auf Konfiguration zu erstellen.</p>"},{"location":"architecture/modules/","title":"\ud83d\udce6 Module-Architektur","text":"<p>Keiko Personal Assistant ist in modulare Komponenten unterteilt f\u00fcr bessere Wartbarkeit und Erweiterbarkeit.</p>"},{"location":"architecture/modules/#module-ubersicht","title":"\ud83c\udfd7\ufe0f Module-\u00dcbersicht","text":"<pre><code>graph TB\n    subgraph \"Core Modules\"\n        AGENT[Agent Module]\n        TASK[Task Module]\n        USER[User Module]\n        AUTH[Auth Module]\n    end\n\n    subgraph \"Integration Modules\"\n        MCP[MCP Module]\n        AZURE[Azure Module]\n        PROTOCOL[Protocol Module]\n    end\n\n    subgraph \"Infrastructure Modules\"\n        DB[Database Module]\n        CACHE[Cache Module]\n        LOGGING[Logging Module]\n        METRICS[Metrics Module]\n    end\n\n    subgraph \"Utility Modules\"\n        CONFIG[Config Module]\n        SECURITY[Security Module]\n        VALIDATION[Validation Module]\n    end\n\n    AGENT --&gt; TASK\n    TASK --&gt; USER\n    USER --&gt; AUTH\n\n    AGENT --&gt; MCP\n    MCP --&gt; AZURE\n    AZURE --&gt; PROTOCOL\n\n    AGENT --&gt; DB\n    TASK --&gt; CACHE\n    USER --&gt; LOGGING\n    AUTH --&gt; METRICS\n\n    DB --&gt; CONFIG\n    CACHE --&gt; SECURITY\n    LOGGING --&gt; VALIDATION</code></pre>"},{"location":"architecture/modules/#core-modules","title":"\ud83e\udd16 Core Modules","text":""},{"location":"architecture/modules/#agent-module","title":"Agent Module","text":"<pre><code># keiko/core/agent/__init__.py\n\"\"\"Agent-Modul f\u00fcr Agent-Management und -Ausf\u00fchrung.\"\"\"\n\nfrom .models import Agent, AgentConfig, AgentStatus\nfrom .services import AgentService, AgentOrchestrator\nfrom .repositories import AgentRepository\nfrom .factories import AgentFactory\nfrom .exceptions import AgentException, AgentNotFoundException\n\n__all__ = [\n    \"Agent\", \"AgentConfig\", \"AgentStatus\",\n    \"AgentService\", \"AgentOrchestrator\",\n    \"AgentRepository\", \"AgentFactory\",\n    \"AgentException\", \"AgentNotFoundException\"\n]\n\n# keiko/core/agent/models.py\nfrom dataclasses import dataclass\nfrom typing import Dict, Any, List\nfrom enum import Enum\n\nclass AgentStatus(Enum):\n    INACTIVE = \"inactive\"\n    ACTIVE = \"active\"\n    BUSY = \"busy\"\n    ERROR = \"error\"\n\n@dataclass\nclass AgentConfig:\n    \"\"\"Konfiguration f\u00fcr Agenten.\"\"\"\n    name: str\n    type: str\n    capabilities: List[str]\n    timeout_seconds: int = 300\n    max_concurrent_tasks: int = 1\n    retry_policy: Dict[str, Any] = None\n\nclass Agent:\n    \"\"\"Domain-Model f\u00fcr Agenten.\"\"\"\n\n    def __init__(self, config: AgentConfig):\n        self.id = generate_uuid()\n        self.config = config\n        self.status = AgentStatus.INACTIVE\n        self.current_tasks: List[str] = []\n\n    def can_accept_task(self) -&gt; bool:\n        \"\"\"Pr\u00fcft, ob Agent neue Tasks annehmen kann.\"\"\"\n        return (\n            self.status == AgentStatus.ACTIVE and\n            len(self.current_tasks) &lt; self.config.max_concurrent_tasks\n        )\n\n    async def execute_task(self, task: 'Task') -&gt; 'TaskResult':\n        \"\"\"F\u00fchrt Task aus.\"\"\"\n        if not self.can_accept_task():\n            raise AgentBusyException(self.id)\n\n        self.status = AgentStatus.BUSY\n        self.current_tasks.append(task.id)\n\n        try:\n            result = await self._execute_task_logic(task)\n            return result\n        finally:\n            self.current_tasks.remove(task.id)\n            self.status = AgentStatus.ACTIVE if self.current_tasks else AgentStatus.ACTIVE\n\n# keiko/core/agent/services.py\nclass AgentService:\n    \"\"\"Service f\u00fcr Agent-Management.\"\"\"\n\n    def __init__(self, agent_repo: AgentRepository, event_bus: EventBus):\n        self.agent_repo = agent_repo\n        self.event_bus = event_bus\n\n    async def create_agent(self, config: AgentConfig) -&gt; Agent:\n        \"\"\"Erstellt neuen Agent.\"\"\"\n        agent = Agent(config)\n        await self.agent_repo.save(agent)\n\n        await self.event_bus.publish(AgentCreatedEvent(\n            agent_id=agent.id,\n            agent_type=config.type\n        ))\n\n        return agent\n\n    async def activate_agent(self, agent_id: str) -&gt; None:\n        \"\"\"Aktiviert Agent.\"\"\"\n        agent = await self.agent_repo.get_by_id(agent_id)\n        if not agent:\n            raise AgentNotFoundException(agent_id)\n\n        agent.status = AgentStatus.ACTIVE\n        await self.agent_repo.save(agent)\n\n        await self.event_bus.publish(AgentActivatedEvent(agent_id=agent_id))\n</code></pre>"},{"location":"architecture/modules/#task-module","title":"Task Module","text":"<pre><code># keiko/core/task/__init__.py\n\"\"\"Task-Modul f\u00fcr Task-Management und -Ausf\u00fchrung.\"\"\"\n\nfrom .models import Task, TaskRequest, TaskResult, TaskStatus\nfrom .services import TaskService, TaskScheduler\nfrom .repositories import TaskRepository\nfrom .executors import TaskExecutor, AsyncTaskExecutor\n\n__all__ = [\n    \"Task\", \"TaskRequest\", \"TaskResult\", \"TaskStatus\",\n    \"TaskService\", \"TaskScheduler\",\n    \"TaskRepository\", \"TaskExecutor\", \"AsyncTaskExecutor\"\n]\n\n# keiko/core/task/models.py\nfrom dataclasses import dataclass\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\nfrom enum import Enum\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\nclass TaskPriority(Enum):\n    LOW = \"low\"\n    NORMAL = \"normal\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n@dataclass\nclass TaskRequest:\n    \"\"\"Request f\u00fcr Task-Erstellung.\"\"\"\n    task_type: str\n    parameters: Dict[str, Any]\n    priority: TaskPriority = TaskPriority.NORMAL\n    timeout_seconds: Optional[int] = None\n    user_id: Optional[str] = None\n\nclass Task:\n    \"\"\"Domain-Model f\u00fcr Tasks.\"\"\"\n\n    def __init__(self, request: TaskRequest):\n        self.id = generate_uuid()\n        self.type = request.task_type\n        self.parameters = request.parameters\n        self.priority = request.priority\n        self.timeout_seconds = request.timeout_seconds\n        self.user_id = request.user_id\n        self.status = TaskStatus.PENDING\n        self.created_at = datetime.utcnow()\n        self.started_at: Optional[datetime] = None\n        self.completed_at: Optional[datetime] = None\n        self.result: Optional['TaskResult'] = None\n\n    def start(self) -&gt; None:\n        \"\"\"Startet Task.\"\"\"\n        if self.status != TaskStatus.PENDING:\n            raise InvalidTaskStateException(self.id, self.status)\n\n        self.status = TaskStatus.RUNNING\n        self.started_at = datetime.utcnow()\n\n    def complete(self, result: 'TaskResult') -&gt; None:\n        \"\"\"Schlie\u00dft Task ab.\"\"\"\n        if self.status != TaskStatus.RUNNING:\n            raise InvalidTaskStateException(self.id, self.status)\n\n        self.status = TaskStatus.COMPLETED\n        self.completed_at = datetime.utcnow()\n        self.result = result\n\n@dataclass\nclass TaskResult:\n    \"\"\"Ergebnis einer Task-Ausf\u00fchrung.\"\"\"\n    success: bool\n    data: Optional[Dict[str, Any]] = None\n    error_message: Optional[str] = None\n    execution_time_seconds: Optional[float] = None\n    metadata: Optional[Dict[str, Any]] = None\n</code></pre>"},{"location":"architecture/modules/#user-module","title":"User Module","text":"<pre><code># keiko/core/user/__init__.py\n\"\"\"User-Modul f\u00fcr Benutzerverwaltung.\"\"\"\n\nfrom .models import User, UserRole, UserProfile\nfrom .services import UserService, UserAuthService\nfrom .repositories import UserRepository\n\n__all__ = [\n    \"User\", \"UserRole\", \"UserProfile\",\n    \"UserService\", \"UserAuthService\",\n    \"UserRepository\"\n]\n\n# keiko/core/user/models.py\nclass UserRole(Enum):\n    ADMIN = \"admin\"\n    OPERATOR = \"operator\"\n    USER = \"user\"\n    VIEWER = \"viewer\"\n\n@dataclass\nclass UserProfile:\n    \"\"\"Benutzerprofil.\"\"\"\n    full_name: Optional[str] = None\n    email: Optional[str] = None\n    preferences: Dict[str, Any] = None\n    timezone: str = \"UTC\"\n\nclass User:\n    \"\"\"Domain-Model f\u00fcr Benutzer.\"\"\"\n\n    def __init__(self, username: str, email: str, role: UserRole):\n        self.id = generate_uuid()\n        self.username = username\n        self.email = email\n        self.role = role\n        self.profile = UserProfile()\n        self.is_active = True\n        self.created_at = datetime.utcnow()\n        self.last_login: Optional[datetime] = None\n\n    def has_permission(self, permission: str) -&gt; bool:\n        \"\"\"Pr\u00fcft Berechtigung.\"\"\"\n        role_permissions = {\n            UserRole.ADMIN: [\"*\"],\n            UserRole.OPERATOR: [\"agents:*\", \"tasks:*\"],\n            UserRole.USER: [\"tasks:create\", \"tasks:read\"],\n            UserRole.VIEWER: [\"tasks:read\", \"agents:read\"]\n        }\n\n        permissions = role_permissions.get(self.role, [])\n        return \"*\" in permissions or permission in permissions\n</code></pre>"},{"location":"architecture/modules/#integration-modules","title":"\ud83d\udd0c Integration Modules","text":""},{"location":"architecture/modules/#mcp-module","title":"MCP Module","text":"<pre><code># keiko/integration/mcp/__init__.py\n\"\"\"MCP-Modul f\u00fcr Model Context Protocol Integration.\"\"\"\n\nfrom .client import MCPClient, MCPClientConfig\nfrom .server_registry import MCPServerRegistry\nfrom .tool_executor import ToolExecutor\nfrom .protocol_selector import ProtocolSelector\n\n__all__ = [\n    \"MCPClient\", \"MCPClientConfig\",\n    \"MCPServerRegistry\", \"ToolExecutor\",\n    \"ProtocolSelector\"\n]\n\n# keiko/integration/mcp/client.py\nclass MCPClient:\n    \"\"\"Client f\u00fcr MCP-Server-Kommunikation.\"\"\"\n\n    def __init__(self, config: MCPClientConfig):\n        self.config = config\n        self.session: Optional[aiohttp.ClientSession] = None\n\n    async def connect(self) -&gt; None:\n        \"\"\"Stellt Verbindung zum MCP-Server her.\"\"\"\n        headers = {\"Content-Type\": \"application/json\"}\n\n        if self.config.auth_config:\n            headers.update(self._build_auth_headers())\n\n        self.session = aiohttp.ClientSession(headers=headers)\n\n    async def list_tools(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Listet verf\u00fcgbare Tools auf.\"\"\"\n        async with self.session.get(f\"{self.config.base_url}/tools\") as response:\n            data = await response.json()\n            return data.get(\"tools\", [])\n\n    async def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"F\u00fchrt Tool aus.\"\"\"\n        payload = {\"tool_name\": tool_name, \"arguments\": arguments}\n\n        async with self.session.post(\n            f\"{self.config.base_url}/tools/{tool_name}/execute\",\n            json=payload\n        ) as response:\n            return await response.json()\n</code></pre>"},{"location":"architecture/modules/#azure-module","title":"Azure Module","text":"<pre><code># keiko/integration/azure/__init__.py\n\"\"\"Azure-Modul f\u00fcr Azure AI Foundry Integration.\"\"\"\n\nfrom .ai_client import AzureAIClient\nfrom .storage_client import AzureStorageClient\nfrom .key_vault_client import AzureKeyVaultClient\n\n__all__ = [\n    \"AzureAIClient\", \"AzureStorageClient\", \"AzureKeyVaultClient\"\n]\n\n# keiko/integration/azure/ai_client.py\nclass AzureAIClient:\n    \"\"\"Client f\u00fcr Azure AI Foundry.\"\"\"\n\n    def __init__(self, config: AzureAIConfig):\n        self.config = config\n        self.credential = DefaultAzureCredential()\n\n    async def generate_completion(self, prompt: str, model: str = \"gpt-4\") -&gt; str:\n        \"\"\"Generiert Text-Completion.\"\"\"\n        # Azure AI Foundry API-Aufruf\n        pass\n\n    async def generate_image(self, prompt: str, size: str = \"1024x1024\") -&gt; str:\n        \"\"\"Generiert Bild.\"\"\"\n        # Azure AI Foundry API-Aufruf\n        pass\n</code></pre>"},{"location":"architecture/modules/#infrastructure-modules","title":"\ud83c\udfd7\ufe0f Infrastructure Modules","text":""},{"location":"architecture/modules/#database-module","title":"Database Module","text":"<pre><code># keiko/infrastructure/database/__init__.py\n\"\"\"Database-Modul f\u00fcr Datenpersistierung.\"\"\"\n\nfrom .connection import DatabaseConnection, get_db_session\nfrom .models import BaseModel\nfrom .migrations import MigrationManager\n\n__all__ = [\n    \"DatabaseConnection\", \"get_db_session\",\n    \"BaseModel\", \"MigrationManager\"\n]\n\n# keiko/infrastructure/database/connection.py\nclass DatabaseConnection:\n    \"\"\"Database-Verbindungsmanagement.\"\"\"\n\n    def __init__(self, config: DatabaseConfig):\n        self.config = config\n        self.engine: Optional[AsyncEngine] = None\n        self.session_factory: Optional[async_sessionmaker] = None\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialisiert Database-Verbindung.\"\"\"\n        self.engine = create_async_engine(\n            self.config.connection_string,\n            pool_size=self.config.pool_size,\n            max_overflow=self.config.max_overflow\n        )\n\n        self.session_factory = async_sessionmaker(\n            self.engine,\n            expire_on_commit=False\n        )\n\n    async def get_session(self) -&gt; AsyncSession:\n        \"\"\"Erstellt neue Database-Session.\"\"\"\n        if not self.session_factory:\n            await self.initialize()\n\n        return self.session_factory()\n</code></pre>"},{"location":"architecture/modules/#cache-module","title":"Cache Module","text":"<pre><code># keiko/infrastructure/cache/__init__.py\n\"\"\"Cache-Modul f\u00fcr Redis-Integration.\"\"\"\n\nfrom .redis_client import RedisClient, RedisConfig\nfrom .cache_service import CacheService\nfrom .decorators import cached, cache_invalidate\n\n__all__ = [\n    \"RedisClient\", \"RedisConfig\",\n    \"CacheService\", \"cached\", \"cache_invalidate\"\n]\n\n# keiko/infrastructure/cache/decorators.py\ndef cached(key_pattern: str, ttl: int = 3600):\n    \"\"\"Decorator f\u00fcr Caching.\"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            cache_key = key_pattern.format(*args, **kwargs)\n\n            # Cache pr\u00fcfen\n            cached_result = await redis_client.get(cache_key)\n            if cached_result:\n                return json.loads(cached_result)\n\n            # Funktion ausf\u00fchren\n            result = await func(*args, **kwargs)\n\n            # Ergebnis cachen\n            await redis_client.setex(\n                cache_key,\n                ttl,\n                json.dumps(result, default=str)\n            )\n\n            return result\n\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"architecture/modules/#module-dependencies","title":"\ud83d\udccb Module-Dependencies","text":""},{"location":"architecture/modules/#dependency-graph","title":"Dependency-Graph","text":"<pre><code>graph TD\n    CONFIG[Config Module] --&gt; DB[Database Module]\n    CONFIG --&gt; CACHE[Cache Module]\n    CONFIG --&gt; SECURITY[Security Module]\n\n    SECURITY --&gt; AUTH[Auth Module]\n    SECURITY --&gt; VALIDATION[Validation Module]\n\n    DB --&gt; USER[User Module]\n    DB --&gt; AGENT[Agent Module]\n    DB --&gt; TASK[Task Module]\n\n    CACHE --&gt; USER\n    CACHE --&gt; AGENT\n    CACHE --&gt; TASK\n\n    AUTH --&gt; USER\n    VALIDATION --&gt; TASK\n\n    AGENT --&gt; MCP[MCP Module]\n    AGENT --&gt; AZURE[Azure Module]\n\n    MCP --&gt; PROTOCOL[Protocol Module]\n    AZURE --&gt; PROTOCOL\n\n    LOGGING[Logging Module] --&gt; METRICS[Metrics Module]\n    METRICS --&gt; AGENT\n    METRICS --&gt; TASK</code></pre>"},{"location":"architecture/modules/#module-konfiguration","title":"Module-Konfiguration","text":"<pre><code># keiko/config/modules.py\n\"\"\"Modul-Konfiguration und Dependency Injection.\"\"\"\n\nfrom dependency_injector import containers, providers\nfrom dependency_injector.wiring import Provide, inject\n\nclass ApplicationContainer(containers.DeclarativeContainer):\n    \"\"\"Dependency Injection Container.\"\"\"\n\n    # Configuration\n    config = providers.Configuration()\n\n    # Infrastructure\n    database = providers.Singleton(\n        DatabaseConnection,\n        config=config.database\n    )\n\n    cache = providers.Singleton(\n        RedisClient,\n        config=config.redis\n    )\n\n    # Repositories\n    user_repository = providers.Factory(\n        UserRepository,\n        db_session=database.provided.get_session\n    )\n\n    agent_repository = providers.Factory(\n        AgentRepository,\n        db_session=database.provided.get_session\n    )\n\n    # Services\n    user_service = providers.Factory(\n        UserService,\n        user_repo=user_repository,\n        cache=cache\n    )\n\n    agent_service = providers.Factory(\n        AgentService,\n        agent_repo=agent_repository,\n        cache=cache\n    )\n\n# Verwendung\n@inject\nasync def create_agent(\n    config: AgentConfig,\n    agent_service: AgentService = Provide[ApplicationContainer.agent_service]\n) -&gt; Agent:\n    \"\"\"Erstellt Agent mit Dependency Injection.\"\"\"\n    return await agent_service.create_agent(config)\n</code></pre> <p>Modul-Design</p> <p>Jedes Modul ist in sich geschlossen und definiert klare Interfaces f\u00fcr die Kommunikation mit anderen Modulen.</p> <p>Erweiterbarkeit</p> <p>Neue Module k\u00f6nnen einfach hinzugef\u00fcgt werden, indem sie die definierten Interfaces implementieren und in den Dependency Injection Container registriert werden.</p>"},{"location":"architecture/overview/","title":"\ud83c\udfd7\ufe0f Architektur-\u00dcbersicht","text":"<p>Keiko Personal Assistant basiert auf einer modernen, skalierbaren Microservices-Architektur mit Clean Code-Prinzipien.</p>"},{"location":"architecture/overview/#architektur-prinzipien","title":"\ud83c\udfaf Architektur-Prinzipien","text":""},{"location":"architecture/overview/#design-philosophie","title":"Design-Philosophie","text":"<ul> <li>Clean Architecture: Trennung von Business-Logic und Infrastructure</li> <li>Domain-Driven Design: Fachliche Dom\u00e4nen im Zentrum</li> <li>SOLID-Prinzipien: Wartbarer und erweiterbarer Code</li> <li>Async-First: Optimiert f\u00fcr High-Performance Concurrent Operations</li> <li>Event-Driven: Lose gekoppelte Komponenten durch Events</li> </ul>"},{"location":"architecture/overview/#system-architektur","title":"\ud83c\udfdb\ufe0f System-Architektur","text":""},{"location":"architecture/overview/#high-level-ubersicht","title":"High-Level-\u00dcbersicht","text":"<pre><code>graph TB\n    subgraph \"Client Layer\"\n        WEB[Web UI]\n        MOBILE[Mobile App]\n        SDK[TypeScript SDK]\n        CLI[CLI Tools]\n    end\n\n    subgraph \"API Gateway\"\n        GATEWAY[API Gateway]\n        LB[Load Balancer]\n        AUTH[Auth Service]\n    end\n\n    subgraph \"Core Services\"\n        AGENT[Agent Orchestrator]\n        MCP[MCP Manager]\n        TASK[Task Manager]\n        USER[User Service]\n    end\n\n    subgraph \"Integration Layer\"\n        AZURE[Azure AI Foundry]\n        EXTERNAL[External APIs]\n        TOOLS[MCP Tools]\n    end\n\n    subgraph \"Data Layer\"\n        POSTGRES[PostgreSQL]\n        REDIS[Redis Cache]\n        STORAGE[Object Storage]\n    end\n\n    subgraph \"Infrastructure\"\n        MONITOR[Monitoring]\n        LOGGING[Logging]\n        SECURITY[Security]\n    end\n\n    WEB --&gt; GATEWAY\n    MOBILE --&gt; GATEWAY\n    SDK --&gt; GATEWAY\n    CLI --&gt; GATEWAY\n\n    GATEWAY --&gt; LB\n    LB --&gt; AUTH\n    AUTH --&gt; AGENT\n    AUTH --&gt; MCP\n    AUTH --&gt; TASK\n    AUTH --&gt; USER\n\n    AGENT --&gt; AZURE\n    MCP --&gt; EXTERNAL\n    TASK --&gt; TOOLS\n\n    AGENT --&gt; POSTGRES\n    MCP --&gt; REDIS\n    TASK --&gt; STORAGE\n\n    AGENT --&gt; MONITOR\n    MCP --&gt; LOGGING\n    TASK --&gt; SECURITY</code></pre>"},{"location":"architecture/overview/#komponenten-architektur","title":"\ud83d\udd27 Komponenten-Architektur","text":""},{"location":"architecture/overview/#core-services","title":"Core-Services","text":""},{"location":"architecture/overview/#agent-orchestrator","title":"Agent Orchestrator","text":"<pre><code># Zentrale Agent-Verwaltung und -Orchestrierung\nclass AgentOrchestrator:\n    \"\"\"Koordiniert Agent-Ausf\u00fchrung und Workflow-Management.\"\"\"\n\n    def __init__(self):\n        self.agent_registry = AgentRegistry()\n        self.task_scheduler = TaskScheduler()\n        self.workflow_engine = WorkflowEngine()\n\n    async def execute_task(self, agent_id: str, task: AgentTask) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Agent-Task aus.\"\"\"\n        agent = await self.agent_registry.get_agent(agent_id)\n        return await agent.execute(task)\n\n    async def orchestrate_workflow(self, workflow: Workflow) -&gt; WorkflowResult:\n        \"\"\"Orchestriert Multi-Agent-Workflow.\"\"\"\n        return await self.workflow_engine.execute(workflow)\n</code></pre>"},{"location":"architecture/overview/#mcp-manager","title":"MCP Manager","text":"<pre><code># Model Context Protocol Management\nclass MCPManager:\n    \"\"\"Verwaltet MCP-Server und Tool-Ausf\u00fchrung.\"\"\"\n\n    def __init__(self):\n        self.server_registry = MCPServerRegistry()\n        self.tool_executor = ToolExecutor()\n        self.protocol_selector = ProtocolSelector()\n\n    async def register_server(self, config: MCPServerConfig) -&gt; str:\n        \"\"\"Registriert neuen MCP-Server.\"\"\"\n        return await self.server_registry.register(config)\n\n    async def execute_tool(self, server_name: str, tool_name: str, args: dict) -&gt; dict:\n        \"\"\"F\u00fchrt MCP-Tool aus.\"\"\"\n        return await self.tool_executor.execute(server_name, tool_name, args)\n</code></pre>"},{"location":"architecture/overview/#task-manager","title":"Task Manager","text":"<pre><code># Task-Lifecycle-Management\nclass TaskManager:\n    \"\"\"Verwaltet Task-Lifecycle und -Status.\"\"\"\n\n    def __init__(self):\n        self.task_store = TaskStore()\n        self.result_store = ResultStore()\n        self.notification_service = NotificationService()\n\n    async def create_task(self, task_request: TaskRequest) -&gt; Task:\n        \"\"\"Erstellt neue Task.\"\"\"\n        task = Task.from_request(task_request)\n        await self.task_store.save(task)\n        return task\n\n    async def update_task_status(self, task_id: str, status: TaskStatus) -&gt; None:\n        \"\"\"Aktualisiert Task-Status.\"\"\"\n        await self.task_store.update_status(task_id, status)\n        await self.notification_service.notify_status_change(task_id, status)\n</code></pre>"},{"location":"architecture/overview/#daten-architektur","title":"\ud83d\udcca Daten-Architektur","text":""},{"location":"architecture/overview/#datenmodell","title":"Datenmodell","text":"<pre><code>erDiagram\n    User ||--o{ Agent : owns\n    User ||--o{ Task : creates\n    Agent ||--o{ Task : executes\n    Task ||--o{ TaskResult : produces\n    MCPServer ||--o{ Tool : provides\n    Tool ||--o{ ToolExecution : used_in\n\n    User {\n        uuid id PK\n        string username\n        string email\n        string role\n        timestamp created_at\n        timestamp last_login\n    }\n\n    Agent {\n        uuid id PK\n        string name\n        string type\n        json configuration\n        string status\n        timestamp created_at\n    }\n\n    Task {\n        uuid id PK\n        uuid user_id FK\n        uuid agent_id FK\n        string task_type\n        json parameters\n        string status\n        timestamp created_at\n        timestamp completed_at\n    }\n\n    TaskResult {\n        uuid id PK\n        uuid task_id FK\n        json result_data\n        string status\n        timestamp created_at\n    }\n\n    MCPServer {\n        uuid id PK\n        string name\n        string base_url\n        json auth_config\n        string status\n        timestamp registered_at\n    }\n\n    Tool {\n        uuid id PK\n        uuid server_id FK\n        string name\n        json schema\n        string description\n    }</code></pre>"},{"location":"architecture/overview/#daten-persistierung","title":"Daten-Persistierung","text":""},{"location":"architecture/overview/#postgresql-primary-database","title":"PostgreSQL (Primary Database)","text":"<pre><code>-- Benutzer und Authentifizierung\nCREATE TABLE users (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    username VARCHAR(50) UNIQUE NOT NULL,\n    email VARCHAR(255) UNIQUE NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    role VARCHAR(20) DEFAULT 'user',\n    created_at TIMESTAMP DEFAULT NOW(),\n    last_login TIMESTAMP\n);\n\n-- Agent-Definitionen\nCREATE TABLE agents (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(100) NOT NULL,\n    type VARCHAR(50) NOT NULL,\n    configuration JSONB NOT NULL,\n    status VARCHAR(20) DEFAULT 'active',\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Task-Management\nCREATE TABLE tasks (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id UUID REFERENCES users(id),\n    agent_id UUID REFERENCES agents(id),\n    task_type VARCHAR(100) NOT NULL,\n    parameters JSONB NOT NULL,\n    status VARCHAR(20) DEFAULT 'pending',\n    priority VARCHAR(20) DEFAULT 'normal',\n    created_at TIMESTAMP DEFAULT NOW(),\n    started_at TIMESTAMP,\n    completed_at TIMESTAMP\n);\n</code></pre>"},{"location":"architecture/overview/#redis-caching-sessions","title":"Redis (Caching &amp; Sessions)","text":"<pre><code># Session-Management\nREDIS_KEYS = {\n    \"user_session\": \"session:{user_id}\",\n    \"agent_status\": \"agent:status:{agent_id}\",\n    \"task_cache\": \"task:cache:{task_id}\",\n    \"mcp_server_health\": \"mcp:health:{server_name}\",\n    \"rate_limit\": \"rate_limit:{client_ip}:{endpoint}\"\n}\n\n# Cache-Strategien\nCACHE_TTL = {\n    \"user_session\": 3600,      # 1 Stunde\n    \"agent_status\": 300,       # 5 Minuten\n    \"task_cache\": 1800,        # 30 Minuten\n    \"mcp_server_health\": 60,   # 1 Minute\n    \"rate_limit\": 60           # 1 Minute\n}\n</code></pre>"},{"location":"architecture/overview/#event-driven-architektur","title":"\ud83d\udd04 Event-Driven-Architektur","text":""},{"location":"architecture/overview/#event-system","title":"Event-System","text":"<pre><code>graph LR\n    subgraph \"Event Producers\"\n        AGENT[Agent Service]\n        TASK[Task Service]\n        USER[User Service]\n        MCP[MCP Service]\n    end\n\n    subgraph \"Event Bus\"\n        REDIS_STREAMS[Redis Streams]\n        PUBSUB[Redis Pub/Sub]\n    end\n\n    subgraph \"Event Consumers\"\n        NOTIFICATION[Notification Service]\n        AUDIT[Audit Service]\n        METRICS[Metrics Collector]\n        WEBHOOK[Webhook Service]\n    end\n\n    AGENT --&gt; REDIS_STREAMS\n    TASK --&gt; REDIS_STREAMS\n    USER --&gt; PUBSUB\n    MCP --&gt; PUBSUB\n\n    REDIS_STREAMS --&gt; NOTIFICATION\n    REDIS_STREAMS --&gt; AUDIT\n    PUBSUB --&gt; METRICS\n    PUBSUB --&gt; WEBHOOK</code></pre>"},{"location":"architecture/overview/#event-definitionen","title":"Event-Definitionen","text":"<pre><code>from dataclasses import dataclass\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\n\n@dataclass\nclass BaseEvent:\n    \"\"\"Basis-Event-Klasse.\"\"\"\n    event_type: str\n    event_id: str\n    timestamp: datetime\n    source_service: str\n    correlation_id: Optional[str] = None\n    metadata: Optional[Dict[str, Any]] = None\n\n@dataclass\nclass TaskCreatedEvent(BaseEvent):\n    \"\"\"Event f\u00fcr Task-Erstellung.\"\"\"\n    task_id: str\n    user_id: str\n    agent_id: str\n    task_type: str\n\n@dataclass\nclass TaskCompletedEvent(BaseEvent):\n    \"\"\"Event f\u00fcr Task-Abschluss.\"\"\"\n    task_id: str\n    status: str\n    duration_seconds: float\n    result_size_bytes: int\n\n@dataclass\nclass AgentStatusChangedEvent(BaseEvent):\n    \"\"\"Event f\u00fcr Agent-Status-\u00c4nderung.\"\"\"\n    agent_id: str\n    old_status: str\n    new_status: str\n    reason: Optional[str] = None\n\n@dataclass\nclass MCPToolExecutedEvent(BaseEvent):\n    \"\"\"Event f\u00fcr MCP-Tool-Ausf\u00fchrung.\"\"\"\n    server_name: str\n    tool_name: str\n    execution_time_ms: float\n    success: bool\n    error_message: Optional[str] = None\n</code></pre>"},{"location":"architecture/overview/#sicherheits-architektur","title":"\ud83d\udd10 Sicherheits-Architektur","text":""},{"location":"architecture/overview/#security-layers","title":"Security-Layers","text":"<pre><code>graph TB\n    subgraph \"Perimeter Security\"\n        WAF[Web Application Firewall]\n        DDOS[DDoS Protection]\n        RATE[Rate Limiting]\n    end\n\n    subgraph \"Application Security\"\n        AUTH[Authentication]\n        AUTHZ[Authorization]\n        INPUT[Input Validation]\n        OUTPUT[Output Encoding]\n    end\n\n    subgraph \"Data Security\"\n        ENCRYPT[Encryption at Rest]\n        TLS[TLS in Transit]\n        TOKENIZE[Data Tokenization]\n    end\n\n    subgraph \"Infrastructure Security\"\n        NETWORK[Network Segmentation]\n        SECRETS[Secret Management]\n        AUDIT[Audit Logging]\n    end\n\n    WAF --&gt; AUTH\n    DDOS --&gt; AUTHZ\n    RATE --&gt; INPUT\n\n    AUTH --&gt; ENCRYPT\n    AUTHZ --&gt; TLS\n    INPUT --&gt; TOKENIZE\n\n    ENCRYPT --&gt; NETWORK\n    TLS --&gt; SECRETS\n    TOKENIZE --&gt; AUDIT</code></pre>"},{"location":"architecture/overview/#security-implementation","title":"Security-Implementation","text":"<pre><code># Multi-Layer-Security\nclass SecurityManager:\n    \"\"\"Zentrale Sicherheitsverwaltung.\"\"\"\n\n    def __init__(self):\n        self.auth_service = AuthenticationService()\n        self.authz_service = AuthorizationService()\n        self.encryption_service = EncryptionService()\n        self.audit_logger = AuditLogger()\n\n    async def authenticate_request(self, request: Request) -&gt; User:\n        \"\"\"Authentifiziert Request.\"\"\"\n        token = self.extract_token(request)\n        user = await self.auth_service.validate_token(token)\n        await self.audit_logger.log_authentication(user.id, True)\n        return user\n\n    async def authorize_action(self, user: User, action: str, resource: str) -&gt; bool:\n        \"\"\"Autorisiert Benutzer-Aktion.\"\"\"\n        authorized = await self.authz_service.check_permission(\n            user.id, action, resource\n        )\n        await self.audit_logger.log_authorization(\n            user.id, action, resource, authorized\n        )\n        return authorized\n</code></pre>"},{"location":"architecture/overview/#skalierungs-architektur","title":"\ud83d\udcc8 Skalierungs-Architektur","text":""},{"location":"architecture/overview/#horizontal-scaling","title":"Horizontal Scaling","text":"<pre><code>graph TB\n    subgraph \"Load Balancer\"\n        LB[NGINX/HAProxy]\n    end\n\n    subgraph \"API Instances\"\n        API1[API Instance 1]\n        API2[API Instance 2]\n        API3[API Instance 3]\n    end\n\n    subgraph \"Worker Instances\"\n        WORKER1[Agent Worker 1]\n        WORKER2[Agent Worker 2]\n        WORKER3[Agent Worker 3]\n    end\n\n    subgraph \"Database Cluster\"\n        MASTER[PostgreSQL Master]\n        REPLICA1[Read Replica 1]\n        REPLICA2[Read Replica 2]\n    end\n\n    LB --&gt; API1\n    LB --&gt; API2\n    LB --&gt; API3\n\n    API1 --&gt; WORKER1\n    API2 --&gt; WORKER2\n    API3 --&gt; WORKER3\n\n    API1 --&gt; MASTER\n    API2 --&gt; REPLICA1\n    API3 --&gt; REPLICA2</code></pre>"},{"location":"architecture/overview/#performance-optimierungen","title":"Performance-Optimierungen","text":"<pre><code># Connection Pooling\nDATABASE_CONFIG = {\n    \"pool_size\": 20,\n    \"max_overflow\": 30,\n    \"pool_timeout\": 30,\n    \"pool_recycle\": 3600\n}\n\n# Async Processing\nclass AsyncTaskProcessor:\n    \"\"\"Asynchrone Task-Verarbeitung.\"\"\"\n\n    def __init__(self, max_workers: int = 10):\n        self.semaphore = asyncio.Semaphore(max_workers)\n        self.task_queue = asyncio.Queue()\n\n    async def process_task(self, task: Task) -&gt; TaskResult:\n        \"\"\"Verarbeitet Task asynchron.\"\"\"\n        async with self.semaphore:\n            return await self._execute_task(task)\n</code></pre>"},{"location":"architecture/overview/#architektur-qualitatsmerkmale","title":"\ud83d\udccb Architektur-Qualit\u00e4tsmerkmale","text":""},{"location":"architecture/overview/#quality-attributes","title":"Quality Attributes","text":"Merkmal Zielwert Implementierung Verf\u00fcgbarkeit 99.9% Load Balancing, Health Checks, Failover Performance &lt; 200ms Response Time Caching, Connection Pooling, Async Processing Skalierbarkeit 1000+ concurrent users Horizontal Scaling, Microservices Sicherheit Enterprise-grade Multi-layer Security, Encryption, Audit Wartbarkeit Clean Code SOLID Principles, DDD, Automated Testing Observability Full Monitoring Metrics, Logging, Tracing, Alerting"},{"location":"architecture/overview/#architektur-metriken","title":"Architektur-Metriken","text":"<pre><code># Architektur-Qualit\u00e4ts-Metriken\nARCHITECTURE_METRICS = {\n    \"coupling\": \"low\",           # Lose Kopplung zwischen Services\n    \"cohesion\": \"high\",          # Hohe Koh\u00e4sion innerhalb Services\n    \"complexity\": \"managed\",     # Kontrollierte Komplexit\u00e4t\n    \"testability\": \"high\",       # Hohe Testabdeckung m\u00f6glich\n    \"deployability\": \"automated\" # Automatisierte Deployments\n}\n</code></pre> <p>Architektur-Evolution</p> <p>Die Architektur ist darauf ausgelegt, sich mit wachsenden Anforderungen zu entwickeln. Neue Services k\u00f6nnen einfach hinzugef\u00fcgt und bestehende Services unabh\u00e4ngig skaliert werden.</p> <p>Best Practices</p> <ul> <li>Verwenden Sie Dependency Injection f\u00fcr bessere Testbarkeit</li> <li>Implementieren Sie Circuit Breaker f\u00fcr Resilience</li> <li>Nutzen Sie Event Sourcing f\u00fcr kritische Business-Events</li> <li>Setzen Sie auf Infrastructure as Code f\u00fcr reproduzierbare Deployments</li> </ul>"},{"location":"architecture/protocols/","title":"\ud83c\udf10 Protocol-Architektur","text":"<p>Keiko Personal Assistant unterst\u00fctzt verschiedene Kommunikationsprotokolle f\u00fcr flexible Integration und optimale Performance.</p>"},{"location":"architecture/protocols/#protocol-stack","title":"\ud83c\udfd7\ufe0f Protocol-Stack","text":"<pre><code>graph TB\n    subgraph \"Application Layer\"\n        API[REST API]\n        WS[WebSocket API]\n        GRAPHQL[GraphQL API]\n        MCP[MCP Protocol]\n    end\n\n    subgraph \"Transport Layer\"\n        HTTP[HTTP/HTTPS]\n        WSS[WebSocket Secure]\n        GRPC[gRPC]\n        TCP[TCP/TLS]\n    end\n\n    subgraph \"Security Layer\"\n        TLS[TLS 1.3]\n        MTLS[Mutual TLS]\n        JWT[JWT Tokens]\n        OAUTH[OAuth 2.0]\n    end\n\n    subgraph \"Network Layer\"\n        IPV4[IPv4]\n        IPV6[IPv6]\n        DNS[DNS Resolution]\n    end\n\n    API --&gt; HTTP\n    WS --&gt; WSS\n    GRAPHQL --&gt; HTTP\n    MCP --&gt; TCP\n\n    HTTP --&gt; TLS\n    WSS --&gt; TLS\n    GRPC --&gt; MTLS\n    TCP --&gt; JWT\n\n    TLS --&gt; IPV4\n    MTLS --&gt; IPV6\n    JWT --&gt; DNS</code></pre>"},{"location":"architecture/protocols/#protocol-implementations","title":"\ud83d\udd0c Protocol-Implementations","text":""},{"location":"architecture/protocols/#httprest-protocol","title":"HTTP/REST Protocol","text":"<pre><code># keiko/protocols/http/__init__.py\n\"\"\"HTTP/REST Protocol Implementation.\"\"\"\n\nfrom .client import HTTPClient, HTTPConfig\nfrom .server import HTTPServer\nfrom .middleware import HTTPMiddleware\nfrom .handlers import RequestHandler, ResponseHandler\n\n__all__ = [\n    \"HTTPClient\", \"HTTPConfig\", \"HTTPServer\",\n    \"HTTPMiddleware\", \"RequestHandler\", \"ResponseHandler\"\n]\n\n# keiko/protocols/http/client.py\nclass HTTPClient:\n    \"\"\"HTTP-Client f\u00fcr REST-API-Kommunikation.\"\"\"\n\n    def __init__(self, config: HTTPConfig):\n        self.config = config\n        self.session: Optional[aiohttp.ClientSession] = None\n        self.retry_policy = RetryPolicy(\n            max_retries=config.max_retries,\n            backoff_factor=config.backoff_factor\n        )\n\n    async def __aenter__(self):\n        await self.connect()\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await self.disconnect()\n\n    async def connect(self) -&gt; None:\n        \"\"\"Stellt HTTP-Verbindung her.\"\"\"\n        connector = aiohttp.TCPConnector(\n            limit=self.config.connection_pool_size,\n            limit_per_host=self.config.max_connections_per_host,\n            ttl_dns_cache=300,\n            use_dns_cache=True,\n            verify_ssl=self.config.verify_ssl\n        )\n\n        timeout = aiohttp.ClientTimeout(\n            total=self.config.total_timeout,\n            connect=self.config.connect_timeout,\n            sock_read=self.config.read_timeout\n        )\n\n        headers = {\n            \"User-Agent\": f\"Keiko-Client/{VERSION}\",\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        if self.config.auth_token:\n            headers[\"Authorization\"] = f\"Bearer {self.config.auth_token}\"\n\n        self.session = aiohttp.ClientSession(\n            connector=connector,\n            timeout=timeout,\n            headers=headers,\n            raise_for_status=False\n        )\n\n    async def request(\n        self,\n        method: str,\n        url: str,\n        data: Optional[Dict[str, Any]] = None,\n        params: Optional[Dict[str, str]] = None,\n        headers: Optional[Dict[str, str]] = None\n    ) -&gt; HTTPResponse:\n        \"\"\"F\u00fchrt HTTP-Request mit Retry-Logic aus.\"\"\"\n\n        return await self.retry_policy.execute(\n            self._make_request,\n            method, url, data, params, headers\n        )\n\n    async def _make_request(\n        self,\n        method: str,\n        url: str,\n        data: Optional[Dict[str, Any]] = None,\n        params: Optional[Dict[str, str]] = None,\n        headers: Optional[Dict[str, str]] = None\n    ) -&gt; HTTPResponse:\n        \"\"\"F\u00fchrt einzelnen HTTP-Request aus.\"\"\"\n\n        request_kwargs = {\n            \"params\": params,\n            \"headers\": headers\n        }\n\n        if data:\n            request_kwargs[\"json\"] = data\n\n        async with self.session.request(method, url, **request_kwargs) as response:\n            response_data = await response.text()\n\n            # JSON-Response versuchen zu parsen\n            try:\n                json_data = await response.json()\n            except (aiohttp.ContentTypeError, json.JSONDecodeError):\n                json_data = None\n\n            return HTTPResponse(\n                status_code=response.status,\n                headers=dict(response.headers),\n                text=response_data,\n                json=json_data,\n                url=str(response.url)\n            )\n\n@dataclass\nclass HTTPResponse:\n    \"\"\"HTTP-Response-Wrapper.\"\"\"\n    status_code: int\n    headers: Dict[str, str]\n    text: str\n    json: Optional[Dict[str, Any]]\n    url: str\n\n    @property\n    def is_success(self) -&gt; bool:\n        \"\"\"Pr\u00fcft, ob Response erfolgreich war.\"\"\"\n        return 200 &lt;= self.status_code &lt; 300\n\n    @property\n    def is_client_error(self) -&gt; bool:\n        \"\"\"Pr\u00fcft, ob Client-Fehler vorliegt.\"\"\"\n        return 400 &lt;= self.status_code &lt; 500\n\n    @property\n    def is_server_error(self) -&gt; bool:\n        \"\"\"Pr\u00fcft, ob Server-Fehler vorliegt.\"\"\"\n        return 500 &lt;= self.status_code &lt; 600\n</code></pre>"},{"location":"architecture/protocols/#websocket-protocol","title":"WebSocket Protocol","text":"<pre><code># keiko/protocols/websocket/__init__.py\n\"\"\"WebSocket Protocol Implementation.\"\"\"\n\nfrom .client import WebSocketClient, WebSocketConfig\nfrom .server import WebSocketServer\nfrom .handlers import MessageHandler, EventHandler\n\n__all__ = [\n    \"WebSocketClient\", \"WebSocketConfig\", \"WebSocketServer\",\n    \"MessageHandler\", \"EventHandler\"\n]\n\n# keiko/protocols/websocket/client.py\nclass WebSocketClient:\n    \"\"\"WebSocket-Client f\u00fcr Real-Time-Kommunikation.\"\"\"\n\n    def __init__(self, config: WebSocketConfig):\n        self.config = config\n        self.websocket: Optional[websockets.WebSocketServerProtocol] = None\n        self.message_handlers: Dict[str, Callable] = {}\n        self.is_connected = False\n        self._heartbeat_task: Optional[asyncio.Task] = None\n        self._message_handler_task: Optional[asyncio.Task] = None\n\n    async def connect(self) -&gt; None:\n        \"\"\"Stellt WebSocket-Verbindung her.\"\"\"\n        headers = {}\n        if self.config.auth_token:\n            headers[\"Authorization\"] = f\"Bearer {self.config.auth_token}\"\n\n        extra_headers = []\n        for key, value in headers.items():\n            extra_headers.append((key, value))\n\n        try:\n            self.websocket = await websockets.connect(\n                self.config.url,\n                extra_headers=extra_headers,\n                ping_interval=self.config.ping_interval,\n                ping_timeout=self.config.ping_timeout,\n                close_timeout=self.config.close_timeout,\n                max_size=self.config.max_message_size,\n                compression=self.config.compression\n            )\n\n            self.is_connected = True\n\n            # Background-Tasks starten\n            self._heartbeat_task = asyncio.create_task(self._heartbeat_loop())\n            self._message_handler_task = asyncio.create_task(self._message_handler_loop())\n\n        except Exception as e:\n            raise ConnectionError(f\"WebSocket-Verbindung fehlgeschlagen: {e}\")\n\n    async def disconnect(self) -&gt; None:\n        \"\"\"Schlie\u00dft WebSocket-Verbindung.\"\"\"\n        self.is_connected = False\n\n        # Background-Tasks beenden\n        if self._heartbeat_task:\n            self._heartbeat_task.cancel()\n        if self._message_handler_task:\n            self._message_handler_task.cancel()\n\n        if self.websocket:\n            await self.websocket.close()\n            self.websocket = None\n\n    async def send_message(\n        self,\n        message_type: str,\n        data: Dict[str, Any],\n        correlation_id: Optional[str] = None\n    ) -&gt; None:\n        \"\"\"Sendet Nachricht \u00fcber WebSocket.\"\"\"\n        if not self.is_connected or not self.websocket:\n            raise ConnectionError(\"WebSocket nicht verbunden\")\n\n        message = {\n            \"type\": message_type,\n            \"data\": data,\n            \"timestamp\": time.time(),\n            \"correlation_id\": correlation_id or str(uuid.uuid4())\n        }\n\n        try:\n            await self.websocket.send(json.dumps(message))\n        except websockets.exceptions.ConnectionClosed:\n            self.is_connected = False\n            raise ConnectionError(\"WebSocket-Verbindung unterbrochen\")\n\n    async def _heartbeat_loop(self) -&gt; None:\n        \"\"\"Heartbeat-Loop f\u00fcr Verbindungs\u00fcberwachung.\"\"\"\n        while self.is_connected:\n            try:\n                await self.send_message(\"heartbeat\", {\"timestamp\": time.time()})\n                await asyncio.sleep(self.config.heartbeat_interval)\n            except Exception:\n                self.is_connected = False\n                break\n\n    async def _message_handler_loop(self) -&gt; None:\n        \"\"\"Message-Handler-Loop f\u00fcr eingehende Nachrichten.\"\"\"\n        try:\n            async for message in self.websocket:\n                try:\n                    data = json.loads(message)\n                    message_type = data.get(\"type\")\n\n                    if message_type in self.message_handlers:\n                        handler = self.message_handlers[message_type]\n                        asyncio.create_task(handler(data))\n\n                except json.JSONDecodeError:\n                    logger.warning(f\"Ung\u00fcltige JSON-Nachricht: {message}\")\n                except Exception as e:\n                    logger.error(f\"Fehler beim Verarbeiten der Nachricht: {e}\")\n\n        except websockets.exceptions.ConnectionClosed:\n            self.is_connected = False\n        except Exception as e:\n            logger.error(f\"Fehler in Message-Handler-Loop: {e}\")\n            self.is_connected = False\n\n    def register_handler(self, message_type: str, handler: Callable) -&gt; None:\n        \"\"\"Registriert Handler f\u00fcr Nachrichtentyp.\"\"\"\n        self.message_handlers[message_type] = handler\n\n    def unregister_handler(self, message_type: str) -&gt; None:\n        \"\"\"Entfernt Handler f\u00fcr Nachrichtentyp.\"\"\"\n        self.message_handlers.pop(message_type, None)\n</code></pre>"},{"location":"architecture/protocols/#mcp-protocol","title":"MCP Protocol","text":"<pre><code># keiko/protocols/mcp/__init__.py\n\"\"\"Model Context Protocol Implementation.\"\"\"\n\nfrom .client import MCPClient, MCPConfig\nfrom .server import MCPServer\nfrom .messages import MCPMessage, MCPRequest, MCPResponse\nfrom .tools import MCPTool, ToolRegistry\n\n__all__ = [\n    \"MCPClient\", \"MCPConfig\", \"MCPServer\",\n    \"MCPMessage\", \"MCPRequest\", \"MCPResponse\",\n    \"MCPTool\", \"ToolRegistry\"\n]\n\n# keiko/protocols/mcp/messages.py\n@dataclass\nclass MCPMessage:\n    \"\"\"Basis-MCP-Nachricht.\"\"\"\n    version: str = \"1.0\"\n    message_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    timestamp: float = field(default_factory=time.time)\n\n@dataclass\nclass MCPRequest(MCPMessage):\n    \"\"\"MCP-Request-Nachricht.\"\"\"\n    method: str\n    params: Dict[str, Any] = field(default_factory=dict)\n\n@dataclass\nclass MCPResponse(MCPMessage):\n    \"\"\"MCP-Response-Nachricht.\"\"\"\n    request_id: str\n    success: bool\n    result: Optional[Dict[str, Any]] = None\n    error: Optional[str] = None\n\n# keiko/protocols/mcp/client.py\nclass MCPClient:\n    \"\"\"MCP-Client f\u00fcr Model Context Protocol.\"\"\"\n\n    def __init__(self, config: MCPConfig):\n        self.config = config\n        self.transport: Optional[MCPTransport] = None\n        self.pending_requests: Dict[str, asyncio.Future] = {}\n\n    async def connect(self) -&gt; None:\n        \"\"\"Stellt MCP-Verbindung her.\"\"\"\n        if self.config.transport_type == \"http\":\n            self.transport = HTTPMCPTransport(self.config)\n        elif self.config.transport_type == \"websocket\":\n            self.transport = WebSocketMCPTransport(self.config)\n        else:\n            raise ValueError(f\"Unbekannter Transport-Typ: {self.config.transport_type}\")\n\n        await self.transport.connect()\n\n        # Message-Handler registrieren\n        self.transport.register_handler(self._handle_response)\n\n    async def list_tools(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Listet verf\u00fcgbare Tools auf.\"\"\"\n        request = MCPRequest(\n            method=\"tools/list\",\n            params={}\n        )\n\n        response = await self._send_request(request)\n        return response.result.get(\"tools\", [])\n\n    async def get_tool_schema(self, tool_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Ruft Tool-Schema ab.\"\"\"\n        request = MCPRequest(\n            method=\"tools/schema\",\n            params={\"tool_name\": tool_name}\n        )\n\n        response = await self._send_request(request)\n        return response.result\n\n    async def execute_tool(\n        self,\n        tool_name: str,\n        arguments: Dict[str, Any]\n    ) -&gt; Dict[str, Any]:\n        \"\"\"F\u00fchrt Tool aus.\"\"\"\n        request = MCPRequest(\n            method=\"tools/execute\",\n            params={\n                \"tool_name\": tool_name,\n                \"arguments\": arguments\n            }\n        )\n\n        response = await self._send_request(request)\n\n        if not response.success:\n            raise MCPExecutionError(response.error)\n\n        return response.result\n\n    async def _send_request(self, request: MCPRequest) -&gt; MCPResponse:\n        \"\"\"Sendet MCP-Request und wartet auf Response.\"\"\"\n        future = asyncio.Future()\n        self.pending_requests[request.message_id] = future\n\n        try:\n            await self.transport.send_message(request)\n\n            # Auf Response warten (mit Timeout)\n            response = await asyncio.wait_for(\n                future,\n                timeout=self.config.request_timeout\n            )\n\n            return response\n\n        except asyncio.TimeoutError:\n            raise MCPTimeoutError(f\"Request timeout: {request.message_id}\")\n        finally:\n            self.pending_requests.pop(request.message_id, None)\n\n    async def _handle_response(self, message: Dict[str, Any]) -&gt; None:\n        \"\"\"Behandelt eingehende MCP-Responses.\"\"\"\n        try:\n            response = MCPResponse(**message)\n\n            if response.request_id in self.pending_requests:\n                future = self.pending_requests[response.request_id]\n                future.set_result(response)\n\n        except Exception as e:\n            logger.error(f\"Fehler beim Verarbeiten der MCP-Response: {e}\")\n</code></pre>"},{"location":"architecture/protocols/#grpc-protocol","title":"gRPC Protocol","text":"<pre><code># keiko/protocols/grpc/__init__.py\n\"\"\"gRPC Protocol Implementation.\"\"\"\n\nfrom .client import GRPCClient, GRPCConfig\nfrom .server import GRPCServer\nfrom .interceptors import AuthInterceptor, MetricsInterceptor\n\n__all__ = [\n    \"GRPCClient\", \"GRPCConfig\", \"GRPCServer\",\n    \"AuthInterceptor\", \"MetricsInterceptor\"\n]\n\n# keiko/protocols/grpc/client.py\nclass GRPCClient:\n    \"\"\"gRPC-Client f\u00fcr High-Performance-Kommunikation.\"\"\"\n\n    def __init__(self, config: GRPCConfig):\n        self.config = config\n        self.channel: Optional[grpc.aio.Channel] = None\n        self.stubs: Dict[str, Any] = {}\n\n    async def connect(self) -&gt; None:\n        \"\"\"Stellt gRPC-Verbindung her.\"\"\"\n        # Channel-Optionen konfigurieren\n        options = [\n            (\"grpc.keepalive_time_ms\", 30000),\n            (\"grpc.keepalive_timeout_ms\", 5000),\n            (\"grpc.keepalive_permit_without_calls\", True),\n            (\"grpc.http2.max_pings_without_data\", 0),\n            (\"grpc.http2.min_time_between_pings_ms\", 10000),\n            (\"grpc.http2.min_ping_interval_without_data_ms\", 300000)\n        ]\n\n        # TLS-Konfiguration\n        if self.config.use_tls:\n            credentials = grpc.ssl_channel_credentials()\n            self.channel = grpc.aio.secure_channel(\n                self.config.server_address,\n                credentials,\n                options=options\n            )\n        else:\n            self.channel = grpc.aio.insecure_channel(\n                self.config.server_address,\n                options=options\n            )\n\n        # Stubs erstellen\n        self._create_stubs()\n\n    async def disconnect(self) -&gt; None:\n        \"\"\"Schlie\u00dft gRPC-Verbindung.\"\"\"\n        if self.channel:\n            await self.channel.close()\n            self.channel = None\n\n    def _create_stubs(self) -&gt; None:\n        \"\"\"Erstellt gRPC-Stubs.\"\"\"\n        # Hier w\u00fcrden die generierten gRPC-Stubs erstellt\n        # self.stubs[\"agent\"] = agent_pb2_grpc.AgentServiceStub(self.channel)\n        # self.stubs[\"task\"] = task_pb2_grpc.TaskServiceStub(self.channel)\n        pass\n</code></pre>"},{"location":"architecture/protocols/#protocol-selection","title":"\ud83d\udd04 Protocol-Selection","text":""},{"location":"architecture/protocols/#automatische-protocol-auswahl","title":"Automatische Protocol-Auswahl","text":"<pre><code>class ProtocolSelector:\n    \"\"\"Automatische Protocol-Auswahl basierend auf Anforderungen.\"\"\"\n\n    def __init__(self):\n        self.protocol_capabilities = {\n            \"http\": {\n                \"real_time\": False,\n                \"bidirectional\": False,\n                \"streaming\": False,\n                \"performance\": \"medium\",\n                \"complexity\": \"low\"\n            },\n            \"websocket\": {\n                \"real_time\": True,\n                \"bidirectional\": True,\n                \"streaming\": True,\n                \"performance\": \"high\",\n                \"complexity\": \"medium\"\n            },\n            \"grpc\": {\n                \"real_time\": True,\n                \"bidirectional\": True,\n                \"streaming\": True,\n                \"performance\": \"very_high\",\n                \"complexity\": \"high\"\n            },\n            \"mcp\": {\n                \"real_time\": False,\n                \"bidirectional\": False,\n                \"streaming\": False,\n                \"performance\": \"medium\",\n                \"complexity\": \"medium\"\n            }\n        }\n\n    def select_protocol(self, requirements: ProtocolRequirements) -&gt; str:\n        \"\"\"W\u00e4hlt optimales Protokoll basierend auf Anforderungen.\"\"\"\n\n        scores = {}\n\n        for protocol, capabilities in self.protocol_capabilities.items():\n            score = 0\n\n            # Real-Time-Anforderung\n            if requirements.real_time_required and capabilities[\"real_time\"]:\n                score += 30\n            elif requirements.real_time_required and not capabilities[\"real_time\"]:\n                score -= 20\n\n            # Bidirektionale Kommunikation\n            if requirements.bidirectional and capabilities[\"bidirectional\"]:\n                score += 20\n\n            # Streaming-Anforderung\n            if requirements.streaming and capabilities[\"streaming\"]:\n                score += 25\n\n            # Performance-Anforderung\n            performance_scores = {\n                \"low\": 10, \"medium\": 20, \"high\": 30, \"very_high\": 40\n            }\n            if requirements.performance_level in performance_scores:\n                required_score = performance_scores[requirements.performance_level]\n                actual_score = performance_scores.get(capabilities[\"performance\"], 0)\n                score += min(actual_score, required_score)\n\n            # Komplexit\u00e4ts-Pr\u00e4ferenz (niedrigere Komplexit\u00e4t bevorzugt)\n            complexity_penalty = {\n                \"low\": 0, \"medium\": -5, \"high\": -10\n            }\n            score += complexity_penalty.get(capabilities[\"complexity\"], 0)\n\n            scores[protocol] = score\n\n        # Bestes Protokoll ausw\u00e4hlen\n        best_protocol = max(scores, key=scores.get)\n        return best_protocol\n\n@dataclass\nclass ProtocolRequirements:\n    \"\"\"Anforderungen f\u00fcr Protocol-Selection.\"\"\"\n    real_time_required: bool = False\n    bidirectional: bool = False\n    streaming: bool = False\n    performance_level: str = \"medium\"  # low, medium, high, very_high\n    security_level: str = \"standard\"   # basic, standard, high, enterprise\n</code></pre>"},{"location":"architecture/protocols/#protocol-monitoring","title":"\ud83d\udcca Protocol-Monitoring","text":""},{"location":"architecture/protocols/#protocol-metriken","title":"Protocol-Metriken","text":"<pre><code>from prometheus_client import Counter, Histogram, Gauge\n\n# Protocol-Metriken\nPROTOCOL_REQUESTS_TOTAL = Counter(\n    'keiko_protocol_requests_total',\n    'Gesamtanzahl der Protocol-Requests',\n    ['protocol', 'method', 'status']\n)\n\nPROTOCOL_REQUEST_DURATION = Histogram(\n    'keiko_protocol_request_duration_seconds',\n    'Dauer der Protocol-Requests',\n    ['protocol', 'method'],\n    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0]\n)\n\nPROTOCOL_CONNECTIONS_ACTIVE = Gauge(\n    'keiko_protocol_connections_active',\n    'Anzahl aktiver Protocol-Verbindungen',\n    ['protocol']\n)\n\nPROTOCOL_ERRORS_TOTAL = Counter(\n    'keiko_protocol_errors_total',\n    'Gesamtanzahl der Protocol-Fehler',\n    ['protocol', 'error_type']\n)\n\ndef monitor_protocol_request(protocol: str, method: str):\n    \"\"\"Decorator f\u00fcr Protocol-Request-Monitoring.\"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            start_time = time.time()\n\n            try:\n                result = await func(*args, **kwargs)\n\n                PROTOCOL_REQUESTS_TOTAL.labels(\n                    protocol=protocol,\n                    method=method,\n                    status=\"success\"\n                ).inc()\n\n                return result\n\n            except Exception as e:\n                PROTOCOL_REQUESTS_TOTAL.labels(\n                    protocol=protocol,\n                    method=method,\n                    status=\"error\"\n                ).inc()\n\n                PROTOCOL_ERRORS_TOTAL.labels(\n                    protocol=protocol,\n                    error_type=type(e).__name__\n                ).inc()\n\n                raise\n\n            finally:\n                duration = time.time() - start_time\n                PROTOCOL_REQUEST_DURATION.labels(\n                    protocol=protocol,\n                    method=method\n                ).observe(duration)\n\n        return wrapper\n    return decorator\n</code></pre> <p>Protocol-Wahl</p> <ul> <li>HTTP/REST: F\u00fcr einfache Request/Response-Patterns</li> <li>WebSocket: F\u00fcr Real-Time-Kommunikation und bidirektionale Streams</li> <li>gRPC: F\u00fcr High-Performance-Anwendungen mit starker Typisierung</li> <li>MCP: F\u00fcr Model Context Protocol-spezifische Operationen</li> </ul> <p>Performance-Optimierung</p> <p>Nutzen Sie Connection-Pooling, Keep-Alive-Verbindungen und Compression f\u00fcr bessere Protocol-Performance.</p>"},{"location":"enterprise/","title":"Enterprise Features","text":"<p>Das KEI-Agent Python SDK bietet umfassende Enterprise-Features f\u00fcr Production-Deployments, Monitoring und Security-Compliance.</p>"},{"location":"enterprise/#ubersicht","title":"\ud83d\ude80 \u00dcbersicht","text":""},{"location":"enterprise/#enterprise-ready-features","title":"Enterprise-Ready Features","text":"<ul> <li>Structured Logging - JSON-basiertes Logging mit Correlation-IDs</li> <li>Health Checks - Umfassende System-\u00dcberwachung</li> <li>Input Validation - Security-Hardening und Sanitization</li> <li>Security - Multi-Auth und RBAC-Integration</li> <li>Monitoring - Performance-Metriken und Alerting</li> </ul>"},{"location":"enterprise/#production-readiness","title":"Production-Readiness","text":"<p>Das SDK erf\u00fcllt Enterprise-Standards f\u00fcr:</p> <ul> <li>\u2705 Observability: Vollst\u00e4ndige Logging-, Metrics- und Tracing-Integration</li> <li>\u2705 Security: Multi-Factor-Authentication und Input-Validierung</li> <li>\u2705 Reliability: Health Checks und automatische Fallback-Mechanismen</li> <li>\u2705 Performance: Async-First Design mit Connection Pooling</li> <li>\u2705 Compliance: Audit-Logging und RBAC-Unterst\u00fctzung</li> </ul>"},{"location":"enterprise/#enterprise-architektur","title":"\ud83d\udcca Enterprise-Architektur","text":"<pre><code>graph TB\n    subgraph \"\ud83c\udfe2 Enterprise KEI-Agent SDK\"\n        subgraph \"\ud83d\udd10 Security Layer\"\n            AUTH[Multi-Auth&lt;br/&gt;Bearer/OIDC/mTLS]\n            RBAC[Role-Based&lt;br/&gt;Access Control]\n            VALID[Input Validation&lt;br/&gt;&amp; Sanitization]\n            AUDIT[Audit Logging&lt;br/&gt;&amp; Compliance]\n        end\n\n        subgraph \"\ud83d\udcca Observability Layer\"\n            LOGS[Structured Logging&lt;br/&gt;JSON + Correlation-IDs]\n            METRICS[Performance Metrics&lt;br/&gt;Timing &amp; Resources]\n            HEALTH[Health Checks&lt;br/&gt;Proactive Monitoring]\n            TRACE[Distributed Tracing&lt;br/&gt;Request Flow]\n        end\n\n        subgraph \"\u26a1 Performance Layer\"\n            ASYNC[Async-First&lt;br/&gt;Non-blocking I/O]\n            POOL[Connection Pooling&lt;br/&gt;Resource Management]\n            CACHE[Intelligent Caching&lt;br/&gt;Token &amp; Protocol]\n            RETRY[Retry Logic&lt;br/&gt;Circuit Breaker]\n        end\n\n        subgraph \"\ud83d\udd04 Resilience Layer\"\n            FALLBACK[Protocol Fallback&lt;br/&gt;Auto-Recovery]\n            CIRCUIT[Circuit Breaker&lt;br/&gt;Failure Isolation]\n            TIMEOUT[Timeout Handling&lt;br/&gt;Resource Protection]\n            GRACEFUL[Graceful Shutdown&lt;br/&gt;Clean Termination]\n        end\n    end\n\n    style AUTH fill:#ffebee\n    style LOGS fill:#e3f2fd\n    style ASYNC fill:#e8f5e8\n    style FALLBACK fill:#fff3e0</code></pre>"},{"location":"enterprise/#quick-setup","title":"\ud83d\udd27 Quick Setup","text":""},{"location":"enterprise/#basis-enterprise-konfiguration","title":"Basis-Enterprise-Konfiguration","text":"<pre><code>from kei_agent import (\n    UnifiedKeiAgentClient,\n    AgentClientConfig,\n    ProtocolConfig,\n    SecurityConfig,\n    AuthType,\n    configure_logging,\n    get_health_manager\n)\n\n# Enterprise Logging konfigurieren\nlogger = configure_logging(\n    level=\"INFO\",\n    enable_structured=True,\n    enable_file=True,\n    file_path=\"/var/log/kei-agent.log\",\n    extra_fields={\n        \"service\": \"kei-agent-production\",\n        \"environment\": \"production\",\n        \"version\": \"1.0.0\"\n    }\n)\n\n# Enterprise Security konfigurieren\nsecurity_config = SecurityConfig(\n    auth_type=AuthType.OIDC,\n    oidc_issuer=\"https://auth.company.com\",\n    oidc_client_id=\"kei-agent-prod\",\n    oidc_client_secret=\"secure-secret\",\n    rbac_enabled=True,\n    audit_enabled=True,\n    token_refresh_enabled=True\n)\n\n# Production Protocol konfigurieren\nprotocol_config = ProtocolConfig(\n    rpc_enabled=True,\n    stream_enabled=True,\n    bus_enabled=True,\n    mcp_enabled=True,\n    auto_protocol_selection=True,\n    protocol_fallback_enabled=True\n)\n\n# Agent konfigurieren\nagent_config = AgentClientConfig(\n    base_url=\"https://api.kei-framework.com\",\n    api_token=\"production-token\",\n    agent_id=\"enterprise-agent-001\",\n    timeout=30,\n    max_retries=5,\n    retry_delay=2.0\n)\n\n# Enterprise Client erstellen\nasync with UnifiedKeiAgentClient(\n    config=agent_config,\n    protocol_config=protocol_config,\n    security_config=security_config\n) as client:\n    # Production-ready Agent-Operationen\n    plan = await client.plan_task(\"Enterprise task\")\n</code></pre>"},{"location":"enterprise/#health-monitoring-setup","title":"Health Monitoring Setup","text":"<pre><code>from kei_agent import (\n    get_health_manager,\n    APIHealthCheck,\n    DatabaseHealthCheck,\n    MemoryHealthCheck\n)\n\n# Health Manager konfigurieren\nhealth_manager = get_health_manager()\n\n# Critical System Checks\nhealth_manager.register_check(APIHealthCheck(\n    name=\"kei_api\",\n    url=\"https://api.kei-framework.com/health\",\n    critical=True,\n    timeout_seconds=10\n))\n\nhealth_manager.register_check(DatabaseHealthCheck(\n    name=\"primary_database\",\n    connection_string=\"postgresql://...\",\n    critical=True\n))\n\nhealth_manager.register_check(MemoryHealthCheck(\n    name=\"system_memory\",\n    warning_threshold=0.8,\n    critical_threshold=0.95,\n    critical=False\n))\n\n# Kontinuierliches Monitoring\nasync def continuous_monitoring():\n    while True:\n        summary = await health_manager.run_all_checks()\n\n        if summary.overall_status != \"healthy\":\n            logger.error(\n                \"System health degraded\",\n                overall_status=summary.overall_status,\n                unhealthy_count=summary.unhealthy_count,\n                checks=[check.name for check in summary.checks if check.status != \"healthy\"]\n            )\n\n        await asyncio.sleep(60)  # Check every minute\n\n# Background monitoring starten\nasyncio.create_task(continuous_monitoring())\n</code></pre>"},{"location":"enterprise/#security-features","title":"\ud83d\udd10 Security Features","text":""},{"location":"enterprise/#multi-authentication-support","title":"Multi-Authentication Support","text":"<pre><code># Bearer Token (Einfach)\nbearer_config = SecurityConfig(\n    auth_type=AuthType.BEARER,\n    api_token=\"bearer-token-123\"\n)\n\n# OIDC (Enterprise)\noidc_config = SecurityConfig(\n    auth_type=AuthType.OIDC,\n    oidc_issuer=\"https://auth.company.com\",\n    oidc_client_id=\"kei-agent\",\n    oidc_client_secret=\"client-secret\",\n    oidc_scope=\"openid profile kei-agent\"\n)\n\n# mTLS (High Security)\nmtls_config = SecurityConfig(\n    auth_type=AuthType.MTLS,\n    mtls_cert_path=\"/etc/ssl/certs/client.crt\",\n    mtls_key_path=\"/etc/ssl/private/client.key\",\n    mtls_ca_path=\"/etc/ssl/certs/ca.crt\"\n)\n</code></pre>"},{"location":"enterprise/#input-validation-security","title":"Input Validation &amp; Security","text":"<pre><code>from kei_agent import get_input_validator\n\nvalidator = get_input_validator()\n\n# Enterprise-Grade Validierung\ndef validate_enterprise_input(data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Validiert Enterprise-Input mit Security-Hardening.\"\"\"\n\n    # Agent-Operation validieren\n    result = validator.validate_agent_operation(\"plan\", data)\n\n    if not result.valid:\n        # Security-Event loggen\n        logger.log_security_event(\n            event_type=\"input_validation_failed\",\n            severity=\"high\",\n            description=\"Invalid input detected\",\n            validation_errors=result.errors,\n            input_data=data\n        )\n        raise SecurityError(f\"Input validation failed: {result.errors}\")\n\n    return result.sanitized_value\n</code></pre>"},{"location":"enterprise/#monitoring-observability","title":"\ud83d\udcca Monitoring &amp; Observability","text":""},{"location":"enterprise/#structured-logging","title":"Structured Logging","text":"<pre><code>from kei_agent import get_logger, LogContext\n\n# Enterprise Logger\nlogger = get_logger(\"enterprise_agent\")\n\n# Request-Context setzen\ncorrelation_id = logger.create_correlation_id()\nlogger.set_context(LogContext(\n    correlation_id=correlation_id,\n    user_id=\"enterprise-user-123\",\n    agent_id=\"enterprise-agent-001\",\n    operation=\"quarterly_report_generation\",\n    environment=\"production\"\n))\n\n# Business-Logic mit Logging\nasync def generate_quarterly_report():\n    operation_id = logger.log_operation_start(\"quarterly_report\")\n\n    try:\n        # Performance-Tracking\n        start_time = time.time()\n\n        # Business-Logic\n        plan = await client.plan_task(\"Generate Q4 2024 report\")\n        logger.info(\"Report plan created\", plan_id=plan['plan_id'])\n\n        result = await client.execute_action(\"generate_report\", {\n            \"template\": \"quarterly_template\",\n            \"quarter\": \"Q4-2024\"\n        })\n\n        # Performance-Metriken\n        duration = (time.time() - start_time) * 1000\n        logger.log_performance(\n            operation=\"quarterly_report\",\n            duration_ms=duration,\n            memory_usage=get_memory_usage(),\n            report_size=result.get('file_size', 0)\n        )\n\n        logger.log_operation_end(\"quarterly_report\", operation_id, start_time, success=True)\n        return result\n\n    except Exception as e:\n        logger.log_operation_end(\"quarterly_report\", operation_id, start_time, success=False)\n        logger.error(\"Report generation failed\", error=str(e), exception_type=type(e).__name__)\n        raise\n</code></pre>"},{"location":"enterprise/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>import psutil\nimport time\n\nasync def monitor_performance():\n    \"\"\"Kontinuierliches Performance-Monitoring.\"\"\"\n\n    while True:\n        # System-Metriken sammeln\n        cpu_percent = psutil.cpu_percent(interval=1)\n        memory = psutil.virtual_memory()\n        disk = psutil.disk_usage('/')\n\n        # Performance-Metriken loggen\n        logger.log_performance(\n            operation=\"system_monitoring\",\n            duration_ms=1000,  # 1 second interval\n            cpu_usage=cpu_percent,\n            memory_usage=memory.percent,\n            disk_usage=disk.percent,\n            memory_available_mb=memory.available // (1024 * 1024)\n        )\n\n        # Alerts bei kritischen Werten\n        if cpu_percent &gt; 90:\n            logger.log_security_event(\n                event_type=\"high_cpu_usage\",\n                severity=\"critical\",\n                description=f\"CPU usage critical: {cpu_percent}%\"\n            )\n\n        if memory.percent &gt; 95:\n            logger.log_security_event(\n                event_type=\"high_memory_usage\",\n                severity=\"critical\",\n                description=f\"Memory usage critical: {memory.percent}%\"\n            )\n\n        await asyncio.sleep(60)  # Monitor every minute\n</code></pre>"},{"location":"enterprise/#production-deployment","title":"\ud83d\udd04 Production Deployment","text":""},{"location":"enterprise/#docker-integration","title":"Docker-Integration","text":"<pre><code>FROM python:3.11-slim\n\n# System-Dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# KEI-Agent SDK installieren\nRUN pip install \"kei-agent-sdk[security,docs]\"\n\n# Application Code\nCOPY . /app\nWORKDIR /app\n\n# Health Check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n    CMD python -c \"import asyncio; from health_check import check_health; asyncio.run(check_health())\"\n\n# Production Command\nCMD [\"python\", \"-m\", \"enterprise_agent\"]\n</code></pre>"},{"location":"enterprise/#kubernetes-integration","title":"Kubernetes-Integration","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kei-agent-enterprise\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kei-agent-enterprise\n  template:\n    metadata:\n      labels:\n        app: kei-agent-enterprise\n    spec:\n      containers:\n      - name: kei-agent\n        image: kei-agent-enterprise:latest\n        env:\n        - name: KEI_API_URL\n          value: \"https://api.kei-framework.com\"\n        - name: KEI_API_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: kei-agent-secrets\n              key: api-token\n        - name: KEI_AGENT_ID\n          value: \"k8s-enterprise-agent\"\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n</code></pre>"},{"location":"enterprise/#compliance-governance","title":"\ud83d\udcc8 Compliance &amp; Governance","text":""},{"location":"enterprise/#audit-logging","title":"Audit-Logging","text":"<pre><code># Automatisches Audit-Logging f\u00fcr alle Operationen\nasync def audit_logged_operation(operation: str, data: Dict[str, Any]):\n    \"\"\"F\u00fchrt Operation mit vollst\u00e4ndigem Audit-Logging aus.\"\"\"\n\n    # Pre-Operation Audit\n    logger.log_security_event(\n        event_type=\"operation_started\",\n        severity=\"info\",\n        description=f\"Operation '{operation}' started\",\n        operation=operation,\n        user_id=get_current_user_id(),\n        timestamp=datetime.utcnow().isoformat(),\n        input_data_hash=hash_sensitive_data(data)\n    )\n\n    try:\n        result = await client.execute_agent_operation(operation, data)\n\n        # Success Audit\n        logger.log_security_event(\n            event_type=\"operation_completed\",\n            severity=\"info\",\n            description=f\"Operation '{operation}' completed successfully\",\n            operation=operation,\n            result_hash=hash_sensitive_data(result)\n        )\n\n        return result\n\n    except Exception as e:\n        # Failure Audit\n        logger.log_security_event(\n            event_type=\"operation_failed\",\n            severity=\"error\",\n            description=f\"Operation '{operation}' failed\",\n            operation=operation,\n            error_type=type(e).__name__,\n            error_message=str(e)\n        )\n        raise\n</code></pre>"},{"location":"enterprise/#gdpr-compliance","title":"GDPR-Compliance","text":"<pre><code># Datenschutz-konforme Datenverarbeitung\ndef sanitize_for_logging(data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Entfernt PII-Daten f\u00fcr GDPR-Compliance.\"\"\"\n\n    sensitive_fields = ['email', 'phone', 'ssn', 'credit_card']\n    sanitized = data.copy()\n\n    for field in sensitive_fields:\n        if field in sanitized:\n            sanitized[field] = \"[REDACTED]\"\n\n    return sanitized\n</code></pre> <p>Enterprise-Feature Details: - Structured Logging \u2192 - Production-Logging-Setup - Health Checks \u2192 - System-Monitoring - Input Validation \u2192 - Security-Hardening - Security \u2192 - Authentication &amp; Authorization - Monitoring \u2192 - Performance &amp; Alerting</p>"},{"location":"enterprise/health-checks/","title":"Health Checks","text":"<p>Diese Seite wird noch entwickelt.</p>"},{"location":"enterprise/health-checks/#ubersicht","title":"\u00dcbersicht","text":"<p>Umfassende Health Check-Funktionalit\u00e4t f\u00fcr produktive Umgebungen.</p>"},{"location":"enterprise/health-checks/#features","title":"Features","text":"<ul> <li>System Health: CPU, Memory, Disk Usage</li> <li>Service Health: Abh\u00e4ngigkeiten und externe Services</li> <li>Custom Checks: Anwendungsspezifische Gesundheitspr\u00fcfungen</li> <li>Readiness/Liveness: Kubernetes-kompatible Endpoints</li> </ul>"},{"location":"enterprise/health-checks/#verwendung","title":"Verwendung","text":"<pre><code>from kei_agent import get_health_manager\n\nhealth = get_health_manager()\nstatus = await health.check_health()\n\nprint(f\"System Health: {status.overall}\")\nfor check in status.checks:\n    print(f\"  {check.name}: {check.status}\")\n</code></pre>"},{"location":"enterprise/health-checks/#health-check-endpoints","title":"Health Check Endpoints","text":"<ul> <li><code>/health</code> - Allgemeine Gesundheit</li> <li><code>/health/ready</code> - Readiness Check</li> <li><code>/health/live</code> - Liveness Check</li> </ul>"},{"location":"enterprise/health-checks/#weitere-informationen","title":"Weitere Informationen","text":"<ul> <li>Logging</li> <li>Monitoring</li> </ul>"},{"location":"enterprise/input-validation/","title":"\u2705 Input-Validation","text":"<p>Keiko Personal Assistant implementiert umfassende Input-Validation f\u00fcr Enterprise-Sicherheit und Datenintegrit\u00e4t.</p>"},{"location":"enterprise/input-validation/#validation-architektur","title":"\ud83d\udee1\ufe0f Validation-Architektur","text":""},{"location":"enterprise/input-validation/#mehrschichtige-validierung","title":"Mehrschichtige Validierung","text":"<pre><code>graph TB\n    subgraph \"Client-Side Validation\"\n        JS[JavaScript Validation]\n        TS[TypeScript Type Checking]\n    end\n\n    subgraph \"API Gateway Validation\"\n        SCHEMA[Schema Validation]\n        RATE[Rate Limiting]\n        SIZE[Size Limits]\n    end\n\n    subgraph \"Application Validation\"\n        PYDANTIC[Pydantic Models]\n        BUSINESS[Business Rules]\n        SANITIZE[Data Sanitization]\n    end\n\n    subgraph \"Database Validation\"\n        CONSTRAINTS[DB Constraints]\n        TRIGGERS[Validation Triggers]\n    end\n\n    JS --&gt; SCHEMA\n    TS --&gt; RATE\n    SCHEMA --&gt; PYDANTIC\n    RATE --&gt; BUSINESS\n    SIZE --&gt; SANITIZE\n    PYDANTIC --&gt; CONSTRAINTS\n    BUSINESS --&gt; TRIGGERS</code></pre>"},{"location":"enterprise/input-validation/#schema-validation","title":"\ud83d\udccb Schema-Validation","text":""},{"location":"enterprise/input-validation/#pydantic-modelle","title":"Pydantic-Modelle","text":""},{"location":"enterprise/input-validation/#agent-task-validation","title":"Agent-Task-Validation","text":"<pre><code>from pydantic import BaseModel, Field, validator\nfrom typing import Optional, Dict, Any, List\nfrom enum import Enum\n\nclass TaskPriority(str, Enum):\n    LOW = \"low\"\n    NORMAL = \"normal\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\nclass AgentTaskRequest(BaseModel):\n    \"\"\"Validierung f\u00fcr Agent-Task-Anfragen.\"\"\"\n\n    task_type: str = Field(\n        ...,\n        min_length=1,\n        max_length=100,\n        regex=r\"^[a-zA-Z0-9_-]+$\",\n        description=\"Task-Typ (alphanumerisch, Unterstriche, Bindestriche)\"\n    )\n\n    parameters: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Task-Parameter\"\n    )\n\n    priority: TaskPriority = Field(\n        default=TaskPriority.NORMAL,\n        description=\"Task-Priorit\u00e4t\"\n    )\n\n    timeout_seconds: Optional[int] = Field(\n        default=300,\n        ge=1,\n        le=3600,\n        description=\"Timeout in Sekunden (1-3600)\"\n    )\n\n    metadata: Optional[Dict[str, str]] = Field(\n        default_factory=dict,\n        description=\"Zus\u00e4tzliche Metadaten\"\n    )\n\n    @validator('parameters')\n    def validate_parameters(cls, v):\n        \"\"\"Validiert Task-Parameter.\"\"\"\n        if not isinstance(v, dict):\n            raise ValueError(\"Parameters m\u00fcssen ein Dictionary sein\")\n\n        # Maximale Verschachtelungstiefe pr\u00fcfen\n        if cls._get_dict_depth(v) &gt; 5:\n            raise ValueError(\"Parameter-Verschachtelung zu tief (max. 5 Ebenen)\")\n\n        # Gef\u00e4hrliche Schl\u00fcssel pr\u00fcfen\n        dangerous_keys = ['__class__', '__module__', 'eval', 'exec']\n        if any(key in str(v) for key in dangerous_keys):\n            raise ValueError(\"Gef\u00e4hrliche Parameter-Schl\u00fcssel erkannt\")\n\n        return v\n\n    @validator('metadata')\n    def validate_metadata(cls, v):\n        \"\"\"Validiert Metadaten.\"\"\"\n        if v is None:\n            return {}\n\n        # Maximale Anzahl Metadaten-Felder\n        if len(v) &gt; 20:\n            raise ValueError(\"Zu viele Metadaten-Felder (max. 20)\")\n\n        # Schl\u00fcssel- und Wert-L\u00e4ngen pr\u00fcfen\n        for key, value in v.items():\n            if len(key) &gt; 50:\n                raise ValueError(f\"Metadaten-Schl\u00fcssel zu lang: {key}\")\n            if len(str(value)) &gt; 500:\n                raise ValueError(f\"Metadaten-Wert zu lang f\u00fcr Schl\u00fcssel: {key}\")\n\n        return v\n\n    @staticmethod\n    def _get_dict_depth(d: Dict, depth: int = 0) -&gt; int:\n        \"\"\"Berechnet die Verschachtelungstiefe eines Dictionaries.\"\"\"\n        if not isinstance(d, dict) or not d:\n            return depth\n        return max(\n            AgentTaskRequest._get_dict_depth(v, depth + 1)\n            for v in d.values()\n            if isinstance(v, dict)\n        ) if any(isinstance(v, dict) for v in d.values()) else depth\n</code></pre>"},{"location":"enterprise/input-validation/#mcp-server-registration","title":"MCP-Server-Registration","text":"<pre><code>from pydantic import BaseModel, Field, validator, HttpUrl\nfrom typing import Optional, Dict\n\nclass MCPServerRegistration(BaseModel):\n    \"\"\"Validierung f\u00fcr MCP-Server-Registrierung.\"\"\"\n\n    server_name: str = Field(\n        ...,\n        min_length=3,\n        max_length=50,\n        regex=r\"^[a-zA-Z0-9][a-zA-Z0-9_-]*[a-zA-Z0-9]$\",\n        description=\"Server-Name (3-50 Zeichen, alphanumerisch)\"\n    )\n\n    base_url: HttpUrl = Field(\n        ...,\n        description=\"Basis-URL des MCP-Servers\"\n    )\n\n    timeout_seconds: float = Field(\n        default=30.0,\n        ge=1.0,\n        le=300.0,\n        description=\"Timeout in Sekunden (1-300)\"\n    )\n\n    description: Optional[str] = Field(\n        default=\"\",\n        max_length=500,\n        description=\"Server-Beschreibung (max. 500 Zeichen)\"\n    )\n\n    authentication: Optional[Dict[str, str]] = Field(\n        default_factory=dict,\n        description=\"Authentifizierungsinformationen\"\n    )\n\n    @validator('base_url')\n    def validate_base_url(cls, v):\n        \"\"\"Validiert die Basis-URL.\"\"\"\n        url_str = str(v)\n\n        # Nur HTTPS in Produktion\n        if not url_str.startswith(('http://', 'https://')):\n            raise ValueError(\"URL muss mit http:// oder https:// beginnen\")\n\n        # Localhost nur in Entwicklung\n        if 'localhost' in url_str or '127.0.0.1' in url_str:\n            import os\n            if os.getenv('ENVIRONMENT') == 'production':\n                raise ValueError(\"Localhost-URLs in Produktion nicht erlaubt\")\n\n        return v\n\n    @validator('authentication')\n    def validate_authentication(cls, v):\n        \"\"\"Validiert Authentifizierungsinformationen.\"\"\"\n        if not v:\n            return v\n\n        allowed_types = ['api_key', 'bearer_token', 'basic_auth']\n        auth_type = v.get('type')\n\n        if auth_type not in allowed_types:\n            raise ValueError(f\"Authentifizierungstyp muss einer von {allowed_types} sein\")\n\n        # Spezifische Validierung je nach Typ\n        if auth_type == 'api_key' and 'api_key' not in v:\n            raise ValueError(\"API-Key erforderlich f\u00fcr api_key Authentifizierung\")\n\n        if auth_type == 'bearer_token' and 'token' not in v:\n            raise ValueError(\"Token erforderlich f\u00fcr bearer_token Authentifizierung\")\n\n        if auth_type == 'basic_auth':\n            if 'username' not in v or 'password' not in v:\n                raise ValueError(\"Username und Password erforderlich f\u00fcr basic_auth\")\n\n        return v\n</code></pre>"},{"location":"enterprise/input-validation/#sicherheits-validation","title":"\ud83d\udd12 Sicherheits-Validation","text":""},{"location":"enterprise/input-validation/#sql-injection-schutz","title":"SQL-Injection-Schutz","text":"<pre><code>import re\nfrom typing import Any\n\nclass SecurityValidator:\n    \"\"\"Sicherheits-Validierungen f\u00fcr Eingaben.\"\"\"\n\n    # Gef\u00e4hrliche SQL-Patterns\n    SQL_INJECTION_PATTERNS = [\n        r\"(\\b(SELECT|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER|EXEC|UNION)\\b)\",\n        r\"(--|#|/\\*|\\*/)\",\n        r\"(\\b(OR|AND)\\s+\\d+\\s*=\\s*\\d+)\",\n        r\"(\\b(OR|AND)\\s+['\\\"].*['\\\"])\",\n        r\"(;|\\|\\||&amp;&amp;)\"\n    ]\n\n    # XSS-Patterns\n    XSS_PATTERNS = [\n        r\"&lt;script[^&gt;]*&gt;.*?&lt;/script&gt;\",\n        r\"javascript:\",\n        r\"on\\w+\\s*=\",\n        r\"&lt;iframe[^&gt;]*&gt;\",\n        r\"&lt;object[^&gt;]*&gt;\",\n        r\"&lt;embed[^&gt;]*&gt;\"\n    ]\n\n    @classmethod\n    def validate_sql_injection(cls, value: str) -&gt; bool:\n        \"\"\"Pr\u00fcft auf SQL-Injection-Versuche.\"\"\"\n        if not isinstance(value, str):\n            return True\n\n        value_lower = value.lower()\n\n        for pattern in cls.SQL_INJECTION_PATTERNS:\n            if re.search(pattern, value_lower, re.IGNORECASE):\n                return False\n\n        return True\n\n    @classmethod\n    def validate_xss(cls, value: str) -&gt; bool:\n        \"\"\"Pr\u00fcft auf XSS-Versuche.\"\"\"\n        if not isinstance(value, str):\n            return True\n\n        for pattern in cls.XSS_PATTERNS:\n            if re.search(pattern, value, re.IGNORECASE):\n                return False\n\n        return True\n\n    @classmethod\n    def sanitize_string(cls, value: str, max_length: int = 1000) -&gt; str:\n        \"\"\"Bereinigt und begrenzt String-Eingaben.\"\"\"\n        if not isinstance(value, str):\n            return str(value)\n\n        # L\u00e4nge begrenzen\n        value = value[:max_length]\n\n        # Gef\u00e4hrliche Zeichen entfernen\n        value = re.sub(r'[&lt;&gt;\"\\']', '', value)\n\n        # Mehrfache Leerzeichen normalisieren\n        value = re.sub(r'\\s+', ' ', value)\n\n        # F\u00fchrende/nachfolgende Leerzeichen entfernen\n        value = value.strip()\n\n        return value\n</code></pre>"},{"location":"enterprise/input-validation/#custom-validators","title":"Custom Validators","text":"<pre><code>from pydantic import validator\n\ndef secure_string_validator(field_name: str, max_length: int = 1000):\n    \"\"\"Erstellt einen sicheren String-Validator.\"\"\"\n\n    def validator_func(cls, v):\n        if v is None:\n            return v\n\n        if not isinstance(v, str):\n            raise ValueError(f\"{field_name} muss ein String sein\")\n\n        # Sicherheitspr\u00fcfungen\n        if not SecurityValidator.validate_sql_injection(v):\n            raise ValueError(f\"{field_name} enth\u00e4lt potentiell gef\u00e4hrliche SQL-Patterns\")\n\n        if not SecurityValidator.validate_xss(v):\n            raise ValueError(f\"{field_name} enth\u00e4lt potentiell gef\u00e4hrliche XSS-Patterns\")\n\n        # L\u00e4ngenpr\u00fcfung\n        if len(v) &gt; max_length:\n            raise ValueError(f\"{field_name} zu lang (max. {max_length} Zeichen)\")\n\n        # Bereinigung\n        return SecurityValidator.sanitize_string(v, max_length)\n\n    return validator(field_name, allow_reuse=True)(validator_func)\n</code></pre>"},{"location":"enterprise/input-validation/#rate-limiting-size-limits","title":"\ud83d\udcca Rate Limiting &amp; Size Limits","text":""},{"location":"enterprise/input-validation/#request-limits","title":"Request-Limits","text":"<pre><code>from fastapi import HTTPException, Request\nfrom typing import Dict\nimport time\n\nclass RateLimiter:\n    \"\"\"Rate-Limiting f\u00fcr API-Endpunkte.\"\"\"\n\n    def __init__(self):\n        self.requests: Dict[str, list] = {}\n        self.limits = {\n            \"default\": {\"requests\": 100, \"window\": 60},  # 100 req/min\n            \"auth\": {\"requests\": 10, \"window\": 60},      # 10 req/min\n            \"tasks\": {\"requests\": 20, \"window\": 60},     # 20 req/min\n            \"upload\": {\"requests\": 5, \"window\": 60}      # 5 req/min\n        }\n\n    def check_rate_limit(self, client_ip: str, endpoint_type: str = \"default\") -&gt; bool:\n        \"\"\"Pr\u00fcft Rate-Limit f\u00fcr Client.\"\"\"\n        now = time.time()\n        limit_config = self.limits.get(endpoint_type, self.limits[\"default\"])\n\n        # Client-Requests initialisieren\n        if client_ip not in self.requests:\n            self.requests[client_ip] = []\n\n        # Alte Requests entfernen\n        window_start = now - limit_config[\"window\"]\n        self.requests[client_ip] = [\n            req_time for req_time in self.requests[client_ip]\n            if req_time &gt; window_start\n        ]\n\n        # Limit pr\u00fcfen\n        if len(self.requests[client_ip]) &gt;= limit_config[\"requests\"]:\n            return False\n\n        # Request hinzuf\u00fcgen\n        self.requests[client_ip].append(now)\n        return True\n\n# FastAPI Dependency\nasync def rate_limit_dependency(request: Request, endpoint_type: str = \"default\"):\n    \"\"\"Rate-Limiting Dependency f\u00fcr FastAPI.\"\"\"\n    client_ip = request.client.host\n    rate_limiter = RateLimiter()\n\n    if not rate_limiter.check_rate_limit(client_ip, endpoint_type):\n        raise HTTPException(\n            status_code=429,\n            detail=\"Rate limit exceeded\",\n            headers={\"Retry-After\": \"60\"}\n        )\n</code></pre>"},{"location":"enterprise/input-validation/#content-size-limits","title":"Content-Size-Limits","text":"<pre><code>from fastapi import HTTPException, Request\nimport json\n\nclass ContentSizeValidator:\n    \"\"\"Validiert Content-Gr\u00f6\u00dfen.\"\"\"\n\n    MAX_SIZES = {\n        \"json\": 1024 * 1024,      # 1 MB\n        \"text\": 512 * 1024,       # 512 KB\n        \"file\": 10 * 1024 * 1024, # 10 MB\n        \"image\": 5 * 1024 * 1024   # 5 MB\n    }\n\n    @classmethod\n    async def validate_request_size(cls, request: Request, content_type: str = \"json\"):\n        \"\"\"Validiert Request-Gr\u00f6\u00dfe.\"\"\"\n        max_size = cls.MAX_SIZES.get(content_type, cls.MAX_SIZES[\"json\"])\n\n        # Content-Length Header pr\u00fcfen\n        content_length = request.headers.get(\"content-length\")\n        if content_length and int(content_length) &gt; max_size:\n            raise HTTPException(\n                status_code=413,\n                detail=f\"Request zu gro\u00df (max. {max_size} bytes)\"\n            )\n\n        # Body-Gr\u00f6\u00dfe pr\u00fcfen\n        body = await request.body()\n        if len(body) &gt; max_size:\n            raise HTTPException(\n                status_code=413,\n                detail=f\"Request-Body zu gro\u00df (max. {max_size} bytes)\"\n            )\n\n        return body\n</code></pre>"},{"location":"enterprise/input-validation/#validation-middleware","title":"\ud83d\udd0d Validation-Middleware","text":""},{"location":"enterprise/input-validation/#fastapi-middleware","title":"FastAPI-Middleware","text":"<pre><code>from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.middleware.base import BaseHTTPMiddleware\nimport json\n\nclass ValidationMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware f\u00fcr umfassende Input-Validation.\"\"\"\n\n    async def dispatch(self, request: Request, call_next):\n        # Content-Type validieren\n        content_type = request.headers.get(\"content-type\", \"\")\n\n        if request.method in [\"POST\", \"PUT\", \"PATCH\"]:\n            # JSON-Content validieren\n            if \"application/json\" in content_type:\n                try:\n                    body = await request.body()\n                    if body:\n                        # JSON-Parsing testen\n                        json.loads(body)\n\n                        # Gr\u00f6\u00dfe pr\u00fcfen\n                        await ContentSizeValidator.validate_request_size(\n                            request, \"json\"\n                        )\n                except json.JSONDecodeError:\n                    raise HTTPException(\n                        status_code=400,\n                        detail=\"Ung\u00fcltiges JSON-Format\"\n                    )\n                except Exception as e:\n                    raise HTTPException(\n                        status_code=400,\n                        detail=f\"Validation-Fehler: {str(e)}\"\n                    )\n\n        # Request weiterleiten\n        response = await call_next(request)\n        return response\n\n# Middleware registrieren\napp = FastAPI()\napp.add_middleware(ValidationMiddleware)\n</code></pre>"},{"location":"enterprise/input-validation/#validation-checkliste","title":"\ud83d\udccb Validation-Checkliste","text":""},{"location":"enterprise/input-validation/#input-validation_1","title":"Input-Validation","text":"<ul> <li> Schema-Validation mit Pydantic implementiert</li> <li> SQL-Injection-Schutz aktiviert</li> <li> XSS-Schutz implementiert</li> <li> Rate-Limiting konfiguriert</li> <li> Content-Size-Limits gesetzt</li> <li> Content-Type-Validation aktiviert</li> <li> Encoding-Validation implementiert</li> <li> File-Upload-Validation konfiguriert</li> </ul>"},{"location":"enterprise/input-validation/#sicherheits-validation_1","title":"Sicherheits-Validation","text":"<ul> <li> Gef\u00e4hrliche Patterns erkannt und blockiert</li> <li> Input-Sanitization implementiert</li> <li> Output-Encoding aktiviert</li> <li> CSRF-Schutz implementiert</li> <li> Path-Traversal-Schutz aktiviert</li> <li> Command-Injection-Schutz implementiert</li> </ul>"},{"location":"enterprise/input-validation/#performance-validation","title":"Performance-Validation","text":"<ul> <li> Request-Timeouts konfiguriert</li> <li> Memory-Limits gesetzt</li> <li> CPU-Limits definiert</li> <li> Concurrent-Request-Limits implementiert</li> </ul> <p>Sicherheitshinweis</p> <p>Input-Validation ist nur eine Schicht der Sicherheit. Kombinieren Sie sie mit anderen Sicherheitsma\u00dfnahmen wie Authentifizierung, Autorisierung und Monitoring.</p> <p>Performance-Tipp</p> <p>Implementieren Sie Validation-Caching f\u00fcr h\u00e4ufig validierte Patterns, um die Performance zu verbessern.</p>"},{"location":"enterprise/logging/","title":"Structured Logging","text":"<p>Diese Seite wird noch entwickelt.</p>"},{"location":"enterprise/logging/#ubersicht","title":"\u00dcbersicht","text":"<p>Enterprise-Grade Structured Logging f\u00fcr das KEI-Agent SDK.</p>"},{"location":"enterprise/logging/#features","title":"Features","text":"<ul> <li>Structured JSON Logging: Maschinenlesbare Log-Ausgaben</li> <li>Correlation IDs: Verfolgung von Requests \u00fcber Service-Grenzen</li> <li>Performance Metrics: Automatische Latenz- und Durchsatz-Messungen</li> <li>Security Audit: Sicherheitsrelevante Events</li> </ul>"},{"location":"enterprise/logging/#verwendung","title":"Verwendung","text":"<pre><code>from kei_agent import get_logger\n\nlogger = get_logger(\"my-component\")\nlogger.info(\"Operation started\", extra={\n    \"operation\": \"plan_task\",\n    \"agent_id\": \"my-agent\",\n    \"correlation_id\": \"req-123\"\n})\n</code></pre>"},{"location":"enterprise/logging/#konfiguration","title":"Konfiguration","text":"<pre><code>logging_config = {\n    \"level\": \"INFO\",\n    \"format\": \"json\",\n    \"correlation_enabled\": True,\n    \"audit_enabled\": True\n}\n</code></pre>"},{"location":"enterprise/logging/#weitere-informationen","title":"Weitere Informationen","text":"<ul> <li>Health Checks</li> <li>Monitoring</li> </ul>"},{"location":"enterprise/monitoring/","title":"\ud83d\udcca Enterprise-Monitoring","text":"<p>Keiko Personal Assistant bietet umfassende Monitoring- und Observability-Funktionen f\u00fcr Enterprise-Umgebungen.</p>"},{"location":"enterprise/monitoring/#monitoring-architektur","title":"\ud83c\udfd7\ufe0f Monitoring-Architektur","text":""},{"location":"enterprise/monitoring/#observability-stack","title":"Observability-Stack","text":"<pre><code>graph TB\n    subgraph \"Application Layer\"\n        APP[Keiko Application]\n        AGENTS[Agent Services]\n        MCP[MCP Servers]\n    end\n\n    subgraph \"Metrics Collection\"\n        PROM[Prometheus]\n        OTEL[OpenTelemetry Collector]\n        CUSTOM[Custom Metrics]\n    end\n\n    subgraph \"Logging\"\n        STRUCT[Structured Logging]\n        FLUENTD[Fluentd/Fluent Bit]\n        ELK[ELK Stack]\n    end\n\n    subgraph \"Tracing\"\n        JAEGER[Jaeger]\n        ZIPKIN[Zipkin]\n        TRACES[Distributed Traces]\n    end\n\n    subgraph \"Visualization\"\n        GRAFANA[Grafana Dashboards]\n        KIBANA[Kibana]\n        ALERTS[Alert Manager]\n    end\n\n    subgraph \"Storage\"\n        TSDB[Time Series DB]\n        ES[Elasticsearch]\n        S3[Object Storage]\n    end\n\n    APP --&gt; PROM\n    AGENTS --&gt; OTEL\n    MCP --&gt; CUSTOM\n\n    APP --&gt; STRUCT\n    STRUCT --&gt; FLUENTD\n    FLUENTD --&gt; ELK\n\n    APP --&gt; JAEGER\n    AGENTS --&gt; ZIPKIN\n    ZIPKIN --&gt; TRACES\n\n    PROM --&gt; GRAFANA\n    ELK --&gt; KIBANA\n    GRAFANA --&gt; ALERTS\n\n    PROM --&gt; TSDB\n    ELK --&gt; ES\n    TRACES --&gt; S3</code></pre>"},{"location":"enterprise/monitoring/#metriken-kpis","title":"\ud83d\udcc8 Metriken &amp; KPIs","text":""},{"location":"enterprise/monitoring/#system-metriken","title":"System-Metriken","text":""},{"location":"enterprise/monitoring/#performance-metriken","title":"Performance-Metriken","text":"<pre><code>from prometheus_client import Counter, Histogram, Gauge, Summary\nimport time\n\n# Request-Metriken\nREQUEST_COUNT = Counter(\n    'keiko_requests_total',\n    'Gesamtanzahl der Requests',\n    ['method', 'endpoint', 'status']\n)\n\nREQUEST_DURATION = Histogram(\n    'keiko_request_duration_seconds',\n    'Request-Dauer in Sekunden',\n    ['method', 'endpoint'],\n    buckets=[0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]\n)\n\n# Agent-Metriken\nAGENT_TASKS_ACTIVE = Gauge(\n    'keiko_agent_tasks_active',\n    'Anzahl aktiver Agent-Tasks',\n    ['agent_id', 'task_type']\n)\n\nAGENT_TASK_DURATION = Summary(\n    'keiko_agent_task_duration_seconds',\n    'Agent-Task-Dauer in Sekunden',\n    ['agent_id', 'task_type', 'status']\n)\n\n# MCP-Metriken\nMCP_TOOL_CALLS = Counter(\n    'keiko_mcp_tool_calls_total',\n    'Gesamtanzahl der MCP-Tool-Aufrufe',\n    ['server_name', 'tool_name', 'status']\n)\n\nMCP_SERVER_HEALTH = Gauge(\n    'keiko_mcp_server_health',\n    'MCP-Server-Gesundheitsstatus (1=healthy, 0=unhealthy)',\n    ['server_name']\n)\n</code></pre>"},{"location":"enterprise/monitoring/#business-metriken","title":"Business-Metriken","text":"<pre><code># Benutzer-Metriken\nUSER_SESSIONS_ACTIVE = Gauge(\n    'keiko_user_sessions_active',\n    'Anzahl aktiver Benutzer-Sessions'\n)\n\nUSER_ACTIONS = Counter(\n    'keiko_user_actions_total',\n    'Gesamtanzahl der Benutzer-Aktionen',\n    ['action_type', 'user_role']\n)\n\n# Fehler-Metriken\nERROR_RATE = Counter(\n    'keiko_errors_total',\n    'Gesamtanzahl der Fehler',\n    ['error_type', 'component', 'severity']\n)\n\nSECURITY_EVENTS = Counter(\n    'keiko_security_events_total',\n    'Gesamtanzahl der Sicherheitsereignisse',\n    ['event_type', 'severity', 'source']\n)\n</code></pre>"},{"location":"enterprise/monitoring/#custom-metrics-decorator","title":"Custom Metrics Decorator","text":"<pre><code>from functools import wraps\nimport time\nfrom typing import Callable\n\ndef monitor_performance(metric_name: str, labels: dict = None):\n    \"\"\"Decorator f\u00fcr Performance-Monitoring.\"\"\"\n\n    def decorator(func: Callable):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            start_time = time.time()\n            labels_dict = labels or {}\n            labels_dict.update({\n                'function': func.__name__,\n                'module': func.__module__\n            })\n\n            try:\n                result = await func(*args, **kwargs)\n                labels_dict['status'] = 'success'\n                return result\n            except Exception as e:\n                labels_dict['status'] = 'error'\n                labels_dict['error_type'] = type(e).__name__\n                ERROR_RATE.labels(**labels_dict).inc()\n                raise\n            finally:\n                duration = time.time() - start_time\n                REQUEST_DURATION.labels(**labels_dict).observe(duration)\n                REQUEST_COUNT.labels(**labels_dict).inc()\n\n        return wrapper\n    return decorator\n\n# Verwendung\n@monitor_performance('agent_task_execution', {'component': 'agent'})\nasync def execute_agent_task(agent_id: str, task: dict):\n    \"\"\"F\u00fchrt eine Agent-Task aus mit Performance-Monitoring.\"\"\"\n    # Implementation\n    pass\n</code></pre>"},{"location":"enterprise/monitoring/#structured-logging","title":"\ud83d\udcdd Structured Logging","text":""},{"location":"enterprise/monitoring/#logging-konfiguration","title":"Logging-Konfiguration","text":"<pre><code>import logging\nimport json\nfrom datetime import datetime\nfrom typing import Dict, Any\nimport uuid\n\nclass StructuredFormatter(logging.Formatter):\n    \"\"\"Strukturierter JSON-Formatter f\u00fcr Logs.\"\"\"\n\n    def format(self, record: logging.LogRecord) -&gt; str:\n        \"\"\"Formatiert Log-Record als JSON.\"\"\"\n        log_entry = {\n            'timestamp': datetime.utcnow().isoformat() + 'Z',\n            'level': record.levelname,\n            'logger': record.name,\n            'message': record.getMessage(),\n            'module': record.module,\n            'function': record.funcName,\n            'line': record.lineno\n        }\n\n        # Zus\u00e4tzliche Felder aus dem Record\n        if hasattr(record, 'correlation_id'):\n            log_entry['correlation_id'] = record.correlation_id\n\n        if hasattr(record, 'user_id'):\n            log_entry['user_id'] = record.user_id\n\n        if hasattr(record, 'agent_id'):\n            log_entry['agent_id'] = record.agent_id\n\n        if hasattr(record, 'task_id'):\n            log_entry['task_id'] = record.task_id\n\n        # Exception-Informationen\n        if record.exc_info:\n            log_entry['exception'] = {\n                'type': record.exc_info[0].__name__,\n                'message': str(record.exc_info[1]),\n                'traceback': self.formatException(record.exc_info)\n            }\n\n        return json.dumps(log_entry, ensure_ascii=False)\n\n# Logger-Konfiguration\ndef setup_logging():\n    \"\"\"Konfiguriert strukturiertes Logging.\"\"\"\n\n    # Root-Logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.INFO)\n\n    # Console-Handler\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(StructuredFormatter())\n    root_logger.addHandler(console_handler)\n\n    # File-Handler f\u00fcr Audit-Logs\n    audit_handler = logging.FileHandler('/var/log/keiko/audit.log')\n    audit_handler.setFormatter(StructuredFormatter())\n    audit_handler.setLevel(logging.WARNING)\n\n    audit_logger = logging.getLogger('keiko.audit')\n    audit_logger.addHandler(audit_handler)\n    audit_logger.setLevel(logging.INFO)\n</code></pre>"},{"location":"enterprise/monitoring/#correlation-id-middleware","title":"Correlation-ID-Middleware","text":"<pre><code>from fastapi import Request, Response\nfrom fastapi.middleware.base import BaseHTTPMiddleware\nimport uuid\nimport logging\n\nclass CorrelationMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware f\u00fcr Correlation-IDs.\"\"\"\n\n    async def dispatch(self, request: Request, call_next):\n        # Correlation-ID aus Header oder generieren\n        correlation_id = request.headers.get('X-Correlation-ID', str(uuid.uuid4()))\n\n        # Correlation-ID in Request-State speichern\n        request.state.correlation_id = correlation_id\n\n        # Logger mit Correlation-ID konfigurieren\n        logger = logging.getLogger('keiko.request')\n        logger = logging.LoggerAdapter(logger, {'correlation_id': correlation_id})\n\n        # Request verarbeiten\n        response = await call_next(request)\n\n        # Correlation-ID in Response-Header setzen\n        response.headers['X-Correlation-ID'] = correlation_id\n\n        return response\n</code></pre>"},{"location":"enterprise/monitoring/#distributed-tracing","title":"\ud83d\udd0d Distributed Tracing","text":""},{"location":"enterprise/monitoring/#opentelemetry-konfiguration","title":"OpenTelemetry-Konfiguration","text":"<pre><code>from opentelemetry import trace\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.instrumentation.fastapi import FastAPIInstrumentor\nfrom opentelemetry.instrumentation.requests import RequestsInstrumentor\n\ndef setup_tracing():\n    \"\"\"Konfiguriert OpenTelemetry Tracing.\"\"\"\n\n    # Tracer-Provider konfigurieren\n    trace.set_tracer_provider(TracerProvider())\n    tracer = trace.get_tracer(__name__)\n\n    # Jaeger-Exporter konfigurieren\n    jaeger_exporter = JaegerExporter(\n        agent_host_name=\"jaeger-agent\",\n        agent_port=6831,\n    )\n\n    # Span-Processor hinzuf\u00fcgen\n    span_processor = BatchSpanProcessor(jaeger_exporter)\n    trace.get_tracer_provider().add_span_processor(span_processor)\n\n    # Auto-Instrumentierung aktivieren\n    FastAPIInstrumentor.instrument()\n    RequestsInstrumentor.instrument()\n\n    return tracer\n\n# Custom Tracing\ntracer = setup_tracing()\n\nasync def traced_agent_execution(agent_id: str, task: dict):\n    \"\"\"Agent-Ausf\u00fchrung mit Tracing.\"\"\"\n\n    with tracer.start_as_current_span(\"agent_task_execution\") as span:\n        # Span-Attribute setzen\n        span.set_attribute(\"agent.id\", agent_id)\n        span.set_attribute(\"task.type\", task.get('task_type'))\n        span.set_attribute(\"task.priority\", task.get('priority', 'normal'))\n\n        try:\n            # Agent-Task ausf\u00fchren\n            result = await execute_task(agent_id, task)\n\n            span.set_attribute(\"task.status\", \"completed\")\n            span.set_attribute(\"task.result_size\", len(str(result)))\n\n            return result\n\n        except Exception as e:\n            span.set_attribute(\"task.status\", \"failed\")\n            span.set_attribute(\"error.type\", type(e).__name__)\n            span.set_attribute(\"error.message\", str(e))\n            span.record_exception(e)\n            raise\n</code></pre>"},{"location":"enterprise/monitoring/#alerting-notifications","title":"\ud83d\udea8 Alerting &amp; Notifications","text":""},{"location":"enterprise/monitoring/#alert-regeln","title":"Alert-Regeln","text":"<pre><code># Prometheus Alert Rules\ngroups:\n  - name: keiko.rules\n    rules:\n      # High Error Rate\n      - alert: HighErrorRate\n        expr: rate(keiko_errors_total[5m]) &gt; 0.1\n        for: 2m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Hohe Fehlerrate erkannt\"\n          description: \"Fehlerrate von {{ $value }} in den letzten 5 Minuten\"\n\n      # Agent Task Failures\n      - alert: AgentTaskFailures\n        expr: rate(keiko_agent_task_duration_seconds_count{status=\"failed\"}[5m]) &gt; 0.05\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Agent-Task-Fehler erkannt\"\n          description: \"Agent {{ $labels.agent_id }} hat Fehlerrate von {{ $value }}\"\n\n      # MCP Server Down\n      - alert: MCPServerDown\n        expr: keiko_mcp_server_health == 0\n        for: 30s\n        labels:\n          severity: critical\n        annotations:\n          summary: \"MCP-Server nicht erreichbar\"\n          description: \"MCP-Server {{ $labels.server_name }} ist nicht erreichbar\"\n\n      # High Memory Usage\n      - alert: HighMemoryUsage\n        expr: process_resident_memory_bytes / 1024 / 1024 &gt; 1000\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Hoher Speicherverbrauch\"\n          description: \"Speicherverbrauch: {{ $value }}MB\"\n</code></pre>"},{"location":"enterprise/monitoring/#notification-channels","title":"Notification-Channels","text":"<pre><code>from abc import ABC, abstractmethod\nfrom typing import Dict, Any\nimport aiohttp\nimport smtplib\nfrom email.mime.text import MIMEText\n\nclass NotificationChannel(ABC):\n    \"\"\"Basis-Klasse f\u00fcr Notification-Channels.\"\"\"\n\n    @abstractmethod\n    async def send_notification(self, alert: Dict[str, Any]) -&gt; bool:\n        \"\"\"Sendet eine Benachrichtigung.\"\"\"\n        pass\n\nclass SlackNotification(NotificationChannel):\n    \"\"\"Slack-Benachrichtigungen.\"\"\"\n\n    def __init__(self, webhook_url: str):\n        self.webhook_url = webhook_url\n\n    async def send_notification(self, alert: Dict[str, Any]) -&gt; bool:\n        \"\"\"Sendet Slack-Benachrichtigung.\"\"\"\n\n        severity_colors = {\n            'critical': '#FF0000',\n            'warning': '#FFA500',\n            'info': '#00FF00'\n        }\n\n        payload = {\n            'attachments': [{\n                'color': severity_colors.get(alert.get('severity'), '#808080'),\n                'title': alert.get('summary', 'Keiko Alert'),\n                'text': alert.get('description', ''),\n                'fields': [\n                    {\n                        'title': 'Severity',\n                        'value': alert.get('severity', 'unknown'),\n                        'short': True\n                    },\n                    {\n                        'title': 'Component',\n                        'value': alert.get('component', 'unknown'),\n                        'short': True\n                    }\n                ],\n                'timestamp': alert.get('timestamp')\n            }]\n        }\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(self.webhook_url, json=payload) as response:\n                return response.status == 200\n\nclass EmailNotification(NotificationChannel):\n    \"\"\"E-Mail-Benachrichtigungen.\"\"\"\n\n    def __init__(self, smtp_host: str, smtp_port: int, username: str, password: str):\n        self.smtp_host = smtp_host\n        self.smtp_port = smtp_port\n        self.username = username\n        self.password = password\n\n    async def send_notification(self, alert: Dict[str, Any]) -&gt; bool:\n        \"\"\"Sendet E-Mail-Benachrichtigung.\"\"\"\n\n        subject = f\"Keiko Alert: {alert.get('summary', 'Unknown Alert')}\"\n        body = f\"\"\"\n        Alert Details:\n\n        Summary: {alert.get('summary', 'N/A')}\n        Description: {alert.get('description', 'N/A')}\n        Severity: {alert.get('severity', 'N/A')}\n        Component: {alert.get('component', 'N/A')}\n        Timestamp: {alert.get('timestamp', 'N/A')}\n        \"\"\"\n\n        msg = MIMEText(body)\n        msg['Subject'] = subject\n        msg['From'] = self.username\n        msg['To'] = alert.get('recipient', 'admin@example.com')\n\n        try:\n            with smtplib.SMTP(self.smtp_host, self.smtp_port) as server:\n                server.starttls()\n                server.login(self.username, self.password)\n                server.send_message(msg)\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"enterprise/monitoring/#dashboards","title":"\ud83d\udcca Dashboards","text":""},{"location":"enterprise/monitoring/#grafana-dashboard-konfiguration","title":"Grafana-Dashboard-Konfiguration","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Keiko Personal Assistant - Overview\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(keiko_requests_total[5m])\",\n            \"legendFormat\": \"{{method}} {{endpoint}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(keiko_errors_total[5m])\",\n            \"legendFormat\": \"{{error_type}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Agent Tasks\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"keiko_agent_tasks_active\",\n            \"legendFormat\": \"{{agent_id}} - {{task_type}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"MCP Server Health\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"keiko_mcp_server_health\",\n            \"legendFormat\": \"{{server_name}}\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"enterprise/monitoring/#monitoring-checkliste","title":"\ud83d\udccb Monitoring-Checkliste","text":""},{"location":"enterprise/monitoring/#metriken","title":"Metriken","text":"<ul> <li> System-Metriken (CPU, Memory, Disk, Network) erfasst</li> <li> Application-Metriken (Requests, Errors, Latency) implementiert</li> <li> Business-Metriken (User Actions, Tasks) definiert</li> <li> Custom-Metriken f\u00fcr spezifische Use Cases erstellt</li> </ul>"},{"location":"enterprise/monitoring/#logging","title":"Logging","text":"<ul> <li> Strukturiertes Logging implementiert</li> <li> Correlation-IDs f\u00fcr Request-Tracking aktiviert</li> <li> Log-Aggregation konfiguriert</li> <li> Log-Retention definiert</li> </ul>"},{"location":"enterprise/monitoring/#tracing","title":"Tracing","text":"<ul> <li> Distributed Tracing aktiviert</li> <li> Service-Dependencies visualisiert</li> <li> Performance-Bottlenecks identifiziert</li> </ul>"},{"location":"enterprise/monitoring/#alerting","title":"Alerting","text":"<ul> <li> Alert-Regeln definiert</li> <li> Notification-Channels konfiguriert</li> <li> Escalation-Policies implementiert</li> <li> Alert-Fatigue vermieden</li> </ul>"},{"location":"enterprise/monitoring/#dashboards_1","title":"Dashboards","text":"<ul> <li> System-Overview Dashboard erstellt</li> <li> Application-Performance Dashboard konfiguriert</li> <li> Business-KPIs Dashboard implementiert</li> <li> Security-Monitoring Dashboard aktiviert</li> </ul> <p>Best Practices</p> <ul> <li>Implementieren Sie Monitoring von Anfang an, nicht als Nachgedanke</li> <li>Verwenden Sie aussagekr\u00e4ftige Metriken-Namen und Labels</li> <li>Setzen Sie sinnvolle Alert-Schwellwerte basierend auf historischen Daten</li> <li>Dokumentieren Sie Ihre Monitoring-Setup f\u00fcr das Operations-Team</li> </ul>"},{"location":"enterprise/security/","title":"\ud83d\udd12 Enterprise-Sicherheit","text":"<p>Keiko Personal Assistant implementiert umfassende Sicherheitsma\u00dfnahmen f\u00fcr Enterprise-Umgebungen mit mehrschichtigen Schutzkonzepten.</p>"},{"location":"enterprise/security/#sicherheitsarchitektur","title":"\ud83d\udee1\ufe0f Sicherheitsarchitektur","text":""},{"location":"enterprise/security/#mehrschichtige-sicherheit","title":"Mehrschichtige Sicherheit","text":"<pre><code>graph TB\n    subgraph \"Perimeter Security\"\n        WAF[Web Application Firewall]\n        LB[Load Balancer + DDoS Protection]\n    end\n\n    subgraph \"Application Security\"\n        AUTH[Multi-Factor Authentication]\n        AUTHZ[Role-Based Authorization]\n        RATE[Rate Limiting]\n    end\n\n    subgraph \"Data Security\"\n        ENCRYPT[End-to-End Encryption]\n        VAULT[Secret Management]\n        AUDIT[Audit Logging]\n    end\n\n    subgraph \"Infrastructure Security\"\n        MTLS[Mutual TLS]\n        NET[Network Segmentation]\n        MONITOR[Security Monitoring]\n    end\n\n    WAF --&gt; AUTH\n    LB --&gt; AUTHZ\n    AUTH --&gt; ENCRYPT\n    AUTHZ --&gt; VAULT\n    RATE --&gt; AUDIT\n    ENCRYPT --&gt; MTLS\n    VAULT --&gt; NET\n    AUDIT --&gt; MONITOR</code></pre>"},{"location":"enterprise/security/#authentifizierung-autorisierung","title":"\ud83d\udd10 Authentifizierung &amp; Autorisierung","text":""},{"location":"enterprise/security/#multi-faktor-authentifizierung-mfa","title":"Multi-Faktor-Authentifizierung (MFA)","text":""},{"location":"enterprise/security/#unterstutzte-faktoren","title":"Unterst\u00fctzte Faktoren","text":"Faktor Typ Beschreibung Sicherheitslevel Passwort Wissen Starke Passwort-Richtlinien Basis TOTP Besitz Time-based One-Time Password Hoch Hardware-Token Besitz FIDO2/WebAuthn Sehr hoch Biometrie Eigenschaft Fingerabdruck/Gesichtserkennung Hoch"},{"location":"enterprise/security/#mfa-konfiguration","title":"MFA-Konfiguration","text":"<pre><code># MFA-Einstellungen\nMFA_SETTINGS = {\n    \"required\": True,\n    \"methods\": [\"totp\", \"hardware_token\"],\n    \"backup_codes\": True,\n    \"session_timeout\": 3600,  # 1 Stunde\n    \"remember_device\": False\n}\n</code></pre>"},{"location":"enterprise/security/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":""},{"location":"enterprise/security/#vordefinierte-rollen","title":"Vordefinierte Rollen","text":"<pre><code>roles:\n  admin:\n    permissions:\n      - \"system:*\"\n      - \"agents:*\"\n      - \"users:*\"\n    description: \"Vollzugriff auf alle Systemfunktionen\"\n\n  operator:\n    permissions:\n      - \"agents:read\"\n      - \"agents:execute\"\n      - \"tasks:*\"\n    description: \"Agent-Verwaltung und Task-Ausf\u00fchrung\"\n\n  viewer:\n    permissions:\n      - \"agents:read\"\n      - \"tasks:read\"\n      - \"metrics:read\"\n    description: \"Nur-Lese-Zugriff auf System-Informationen\"\n\n  api_user:\n    permissions:\n      - \"api:execute\"\n      - \"tasks:create\"\n    description: \"Programmatischer API-Zugriff\"\n</code></pre>"},{"location":"enterprise/security/#berechtigungsprufung","title":"Berechtigungspr\u00fcfung","text":"<pre><code>from keiko.security import require_permission\n\n@require_permission(\"agents:execute\")\nasync def execute_agent_task(agent_id: str, task: dict):\n    \"\"\"F\u00fchrt eine Agent-Task aus (erfordert agents:execute Berechtigung).\"\"\"\n    # Implementation\n    pass\n</code></pre>"},{"location":"enterprise/security/#kryptographie-verschlusselung","title":"\ud83d\udd11 Kryptographie &amp; Verschl\u00fcsselung","text":""},{"location":"enterprise/security/#verschlusselungsstandards","title":"Verschl\u00fcsselungsstandards","text":"Komponente Algorithmus Schl\u00fcssell\u00e4nge Verwendung Daten\u00fcbertragung TLS 1.3 256-bit HTTPS/WSS Daten-at-Rest AES-256-GCM 256-bit Datenbank/Storage JWT-Signierung RS256 2048-bit Token-Authentifizierung Passwort-Hashing Argon2id - Benutzer-Passw\u00f6rter"},{"location":"enterprise/security/#schlusselverwaltung","title":"Schl\u00fcsselverwaltung","text":""},{"location":"enterprise/security/#azure-key-vault-integration","title":"Azure Key Vault Integration","text":"<pre><code>from keiko.security import KeyVaultManager\n\n# Schl\u00fcssel-Manager initialisieren\nkey_manager = KeyVaultManager(\n    vault_url=\"https://keiko-vault.vault.azure.net/\",\n    credential=DefaultAzureCredential()\n)\n\n# Verschl\u00fcsselungsschl\u00fcssel abrufen\nencryption_key = await key_manager.get_secret(\"data-encryption-key\")\n\n# Automatische Schl\u00fcsselrotation\nawait key_manager.rotate_key(\"data-encryption-key\", schedule=\"monthly\")\n</code></pre>"},{"location":"enterprise/security/#schlusselrotation","title":"Schl\u00fcsselrotation","text":"<pre><code>key_rotation:\n  schedule: \"0 2 1 * *\"  # Monatlich um 2:00 Uhr\n  keys:\n    - name: \"jwt-signing-key\"\n      type: \"rsa\"\n      size: 2048\n      retention_period: \"90d\"\n    - name: \"data-encryption-key\"\n      type: \"aes\"\n      size: 256\n      retention_period: \"30d\"\n</code></pre>"},{"location":"enterprise/security/#netzwerksicherheit","title":"\ud83c\udf10 Netzwerksicherheit","text":""},{"location":"enterprise/security/#mutual-tls-mtls","title":"Mutual TLS (mTLS)","text":""},{"location":"enterprise/security/#client-zertifikat-authentifizierung","title":"Client-Zertifikat-Authentifizierung","text":"<pre><code># mTLS-Konfiguration\nMTLS_CONFIG = {\n    \"enabled\": True,\n    \"ca_cert_path\": \"/etc/ssl/certs/ca.pem\",\n    \"server_cert_path\": \"/etc/ssl/certs/server.pem\",\n    \"server_key_path\": \"/etc/ssl/private/server.key\",\n    \"client_cert_required\": True,\n    \"verify_mode\": \"CERT_REQUIRED\"\n}\n</code></pre>"},{"location":"enterprise/security/#zertifikatsverwaltung","title":"Zertifikatsverwaltung","text":"<pre><code># Neues Client-Zertifikat erstellen\nopenssl genrsa -out client.key 2048\nopenssl req -new -key client.key -out client.csr\nopenssl x509 -req -in client.csr -CA ca.pem -CAkey ca.key -out client.pem\n\n# Zertifikat validieren\nopenssl verify -CAfile ca.pem client.pem\n</code></pre>"},{"location":"enterprise/security/#netzwerk-segmentierung","title":"Netzwerk-Segmentierung","text":"<pre><code>network_policies:\n  api_tier:\n    ingress:\n      - from: \"load_balancer\"\n        ports: [443]\n    egress:\n      - to: \"service_tier\"\n        ports: [8080]\n\n  service_tier:\n    ingress:\n      - from: \"api_tier\"\n        ports: [8080]\n    egress:\n      - to: \"data_tier\"\n        ports: [5432, 6379]\n\n  data_tier:\n    ingress:\n      - from: \"service_tier\"\n        ports: [5432, 6379]\n    egress: []  # Keine ausgehenden Verbindungen\n</code></pre>"},{"location":"enterprise/security/#security-monitoring","title":"\ud83d\udcca Security Monitoring","text":""},{"location":"enterprise/security/#sicherheitsereignisse","title":"Sicherheitsereignisse","text":""},{"location":"enterprise/security/#event-kategorien","title":"Event-Kategorien","text":"Kategorie Ereignisse Schweregrad Aktion Authentifizierung Login-Versuche, MFA-Fehler INFO/WARN Logging Autorisierung Zugriffsverweigerung WARN Alert Anomalien Ungew\u00f6hnliche API-Nutzung WARN Investigation Angriffe SQL-Injection, XSS CRITICAL Block + Alert"},{"location":"enterprise/security/#security-information-and-event-management-siem","title":"Security Information and Event Management (SIEM)","text":"<pre><code>from keiko.security import SecurityEventLogger\n\n# Sicherheitsereignis protokollieren\nsecurity_logger = SecurityEventLogger()\n\nawait security_logger.log_event(\n    event_type=\"authentication_failure\",\n    severity=\"WARNING\",\n    user_id=\"user123\",\n    ip_address=\"192.168.1.100\",\n    details={\n        \"reason\": \"invalid_password\",\n        \"attempts\": 3,\n        \"user_agent\": \"Mozilla/5.0...\"\n    }\n)\n</code></pre>"},{"location":"enterprise/security/#intrusion-detection","title":"Intrusion Detection","text":""},{"location":"enterprise/security/#anomalie-erkennung","title":"Anomalie-Erkennung","text":"<pre><code># Anomalie-Erkennungsregeln\nANOMALY_RULES = {\n    \"failed_login_threshold\": {\n        \"count\": 5,\n        \"window\": \"5m\",\n        \"action\": \"block_ip\"\n    },\n    \"api_rate_anomaly\": {\n        \"threshold\": \"3x_baseline\",\n        \"window\": \"1h\",\n        \"action\": \"alert\"\n    },\n    \"privilege_escalation\": {\n        \"pattern\": \"role_change\",\n        \"action\": \"immediate_alert\"\n    }\n}\n</code></pre>"},{"location":"enterprise/security/#compliance-audit","title":"\ud83d\udd0d Compliance &amp; Audit","text":""},{"location":"enterprise/security/#audit-logging","title":"Audit-Logging","text":""},{"location":"enterprise/security/#audit-ereignisse","title":"Audit-Ereignisse","text":"<pre><code>from keiko.audit import AuditLogger\n\naudit_logger = AuditLogger()\n\n# Kritische Aktion protokollieren\nawait audit_logger.log_action(\n    action=\"agent_task_execution\",\n    user_id=\"user123\",\n    resource_id=\"agent_456\",\n    details={\n        \"task_type\": \"data_processing\",\n        \"data_classification\": \"confidential\",\n        \"approval_required\": True,\n        \"approver\": \"manager789\"\n    }\n)\n</code></pre>"},{"location":"enterprise/security/#compliance-standards","title":"Compliance-Standards","text":"Standard Abdeckung Status Zertifizierung ISO 27001 Informationssicherheit \u2705 Implementiert Geplant SOC 2 Type II Service-Sicherheit \u2705 Implementiert In Arbeit GDPR Datenschutz \u2705 Implementiert Konform HIPAA Gesundheitsdaten \ud83d\udd04 In Entwicklung Geplant"},{"location":"enterprise/security/#datenschutz","title":"Datenschutz","text":""},{"location":"enterprise/security/#datenklassifizierung","title":"Datenklassifizierung","text":"<pre><code>from keiko.security import DataClassifier\n\n# Daten klassifizieren\nclassifier = DataClassifier()\n\nclassification = await classifier.classify_data(\n    data=user_input,\n    context=\"agent_task\"\n)\n\n# Basierend auf Klassifizierung handeln\nif classification.level == \"confidential\":\n    await apply_enhanced_encryption(data)\n    await log_confidential_access(user_id, data_id)\n</code></pre>"},{"location":"enterprise/security/#incident-response","title":"\ud83d\udea8 Incident Response","text":""},{"location":"enterprise/security/#sicherheitsvorfalle","title":"Sicherheitsvorf\u00e4lle","text":""},{"location":"enterprise/security/#incident-kategorien","title":"Incident-Kategorien","text":"Kategorie Beispiele Response-Zeit Eskalation P1 - Kritisch Datenleck, System-Kompromittierung &lt; 15 Min CISO P2 - Hoch Authentifizierungs-Bypass &lt; 1 Std Security Team P3 - Mittel Anomale API-Nutzung &lt; 4 Std Operations P4 - Niedrig Policy-Verletzung &lt; 24 Std Team Lead"},{"location":"enterprise/security/#automatisierte-response","title":"Automatisierte Response","text":"<pre><code>from keiko.security import IncidentResponse\n\n# Incident-Response-System\nincident_response = IncidentResponse()\n\n# Automatische Reaktion auf Sicherheitsereignis\n@incident_response.handler(\"authentication_attack\")\nasync def handle_auth_attack(event):\n    # IP-Adresse blockieren\n    await firewall.block_ip(event.source_ip)\n\n    # Benutzer benachrichtigen\n    await notify_security_team(event)\n\n    # Forensische Daten sammeln\n    await collect_forensic_data(event)\n</code></pre>"},{"location":"enterprise/security/#security-checklist","title":"\ud83d\udccb Security Checklist","text":""},{"location":"enterprise/security/#deployment-sicherheit","title":"Deployment-Sicherheit","text":"<ul> <li> TLS 1.3 f\u00fcr alle externen Verbindungen aktiviert</li> <li> mTLS f\u00fcr interne Service-Kommunikation konfiguriert</li> <li> Starke Passwort-Richtlinien implementiert</li> <li> MFA f\u00fcr alle privilegierten Accounts aktiviert</li> <li> RBAC korrekt konfiguriert und getestet</li> <li> Audit-Logging f\u00fcr alle kritischen Aktionen aktiviert</li> <li> Security Monitoring und Alerting eingerichtet</li> <li> Vulnerability Scanning regelm\u00e4\u00dfig durchgef\u00fchrt</li> <li> Penetration Testing j\u00e4hrlich durchgef\u00fchrt</li> <li> Incident Response Plan dokumentiert und getestet</li> </ul>"},{"location":"enterprise/security/#laufende-sicherheit","title":"Laufende Sicherheit","text":"<ul> <li> Sicherheits-Updates regelm\u00e4\u00dfig eingespielt</li> <li> Schl\u00fcsselrotation nach Plan durchgef\u00fchrt</li> <li> Access Reviews quartalsweise durchgef\u00fchrt</li> <li> Security Metrics \u00fcberwacht</li> <li> Compliance-Audits bestanden</li> <li> Mitarbeiter-Schulungen durchgef\u00fchrt</li> </ul> <p>Sicherheitshinweis</p> <p>Diese Dokumentation enth\u00e4lt allgemeine Sicherheitsrichtlinien. F\u00fcr produktive Umgebungen sollten zus\u00e4tzliche, umgebungsspezifische Sicherheitsma\u00dfnahmen implementiert werden.</p> <p>Weitere Informationen</p> <p>Detaillierte Sicherheitskonfigurationen finden Sie in der Monitoring-Dokumentation und Input-Validation-Dokumentation.</p>"},{"location":"examples/","title":"Beispiele","text":"<p>Praktische Code-Beispiele f\u00fcr verschiedene Anwendungsf\u00e4lle des KEI-Agent Python SDK.</p>"},{"location":"examples/#beispiel-kategorien","title":"\ud83d\udcda Beispiel-Kategorien","text":""},{"location":"examples/#grundlagen","title":"Grundlagen","text":"<ul> <li>Basis-Verwendung - Einfache Agent-Operationen und Client-Setup</li> <li>Multi-Protocol - Verwendung verschiedener Protokolle</li> <li>Enterprise Setup - Production-ready Konfiguration</li> </ul>"},{"location":"examples/#erweiterte-anwendungen","title":"Erweiterte Anwendungen","text":"<ul> <li>Custom Integrations - Eigene Protokoll-Clients und Validatoren</li> <li>Performance Tuning - Optimierung f\u00fcr High-Performance Szenarien</li> </ul>"},{"location":"examples/#quick-start-beispiele","title":"\ud83d\ude80 Quick Start Beispiele","text":""},{"location":"examples/#einfacher-agent-client","title":"Einfacher Agent-Client","text":"<pre><code>import asyncio\nfrom kei_agent import UnifiedKeiAgentClient, AgentClientConfig\n\nasync def simple_agent_example():\n    \"\"\"Einfaches Beispiel f\u00fcr Agent-Operationen.\"\"\"\n\n    # Konfiguration\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"simple-example-agent\"\n    )\n\n    # Client verwenden\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Plan erstellen\n        plan = await client.plan_task(\n            objective=\"Analysiere Verkaufsdaten f\u00fcr Q4 2024\",\n            context={\n                \"data_source\": \"sales_database\",\n                \"format\": \"quarterly_report\",\n                \"include_charts\": True\n            }\n        )\n        print(f\"Plan erstellt: {plan['plan_id']}\")\n\n        # Aktion ausf\u00fchren\n        result = await client.execute_action(\n            action=\"analyze_sales_data\",\n            parameters={\n                \"quarter\": \"Q4-2024\",\n                \"include_trends\": True,\n                \"output_format\": \"pdf\"\n            }\n        )\n        print(f\"Analyse abgeschlossen: {result['action_id']}\")\n\n        # Ergebnis erkl\u00e4ren\n        explanation = await client.explain_reasoning(\n            query=\"Welche Trends wurden in den Verkaufsdaten identifiziert?\",\n            context={\"action_id\": result['action_id']}\n        )\n        print(f\"Erkl\u00e4rung: {explanation['explanation']}\")\n\n# Ausf\u00fchren\nasyncio.run(simple_agent_example())\n</code></pre>"},{"location":"examples/#multi-agent-kommunikation","title":"Multi-Agent Kommunikation","text":"<pre><code>async def multi_agent_example():\n    \"\"\"Beispiel f\u00fcr Agent-to-Agent Kommunikation.\"\"\"\n\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"coordinator-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Aufgabe an Datenanalyse-Agent delegieren\n        response = await client.send_agent_message(\n            target_agent=\"data-analysis-agent\",\n            message_type=\"analysis_request\",\n            payload={\n                \"dataset\": \"customer_behavior_2024\",\n                \"analysis_type\": \"clustering\",\n                \"priority\": \"high\",\n                \"deadline\": \"2024-12-31T23:59:59Z\"\n            }\n        )\n        print(f\"Nachricht gesendet: {response['message_id']}\")\n\n        # Aufgabe an Report-Generator delegieren\n        report_response = await client.send_agent_message(\n            target_agent=\"report-generator-agent\",\n            message_type=\"report_request\",\n            payload={\n                \"template\": \"executive_summary\",\n                \"data_source\": response['message_id'],\n                \"format\": \"pdf\",\n                \"recipients\": [\"ceo@company.com\", \"cfo@company.com\"]\n            }\n        )\n        print(f\"Report-Request gesendet: {report_response['message_id']}\")\n\nasyncio.run(multi_agent_example())\n</code></pre>"},{"location":"examples/#tool-integration-mit-mcp","title":"Tool-Integration mit MCP","text":"<pre><code>async def tool_integration_example():\n    \"\"\"Beispiel f\u00fcr Tool-Integration \u00fcber MCP.\"\"\"\n\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"tool-integration-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Verf\u00fcgbare Tools entdecken\n        math_tools = await client.discover_available_tools(\"math\")\n        print(f\"Verf\u00fcgbare Math-Tools: {[tool['name'] for tool in math_tools]}\")\n\n        data_tools = await client.discover_available_tools(\"data\")\n        print(f\"Verf\u00fcgbare Data-Tools: {[tool['name'] for tool in data_tools]}\")\n\n        # Calculator-Tool verwenden\n        if any(tool['name'] == 'calculator' for tool in math_tools):\n            calc_result = await client.use_tool(\n                \"calculator\",\n                expression=\"(1000 * 1.08) + (500 * 0.95) - 200\"\n            )\n            print(f\"Berechnungsergebnis: {calc_result['result']}\")\n\n        # CSV-Analyzer-Tool verwenden\n        if any(tool['name'] == 'csv_analyzer' for tool in data_tools):\n            analysis_result = await client.use_tool(\n                \"csv_analyzer\",\n                file_path=\"/data/sales_q4_2024.csv\",\n                analysis_type=\"summary_statistics\"\n            )\n            print(f\"CSV-Analyse: {analysis_result['summary']}\")\n\nasyncio.run(tool_integration_example())\n</code></pre>"},{"location":"examples/#konfiguration-beispiele","title":"\ud83d\udd27 Konfiguration-Beispiele","text":""},{"location":"examples/#development-konfiguration","title":"Development-Konfiguration","text":"<pre><code>from kei_agent import ProtocolConfig, SecurityConfig, AuthType\n\ndef create_development_config():\n    \"\"\"Erstellt Development-Konfiguration.\"\"\"\n\n    agent_config = AgentClientConfig(\n        base_url=\"http://localhost:8000\",\n        api_token=\"dev-token\",\n        agent_id=\"dev-agent\",\n        timeout=10,\n        max_retries=1\n    )\n\n    # Vereinfachte Protokoll-Konfiguration\n    protocol_config = ProtocolConfig(\n        rpc_enabled=True,\n        stream_enabled=False,  # Vereinfacht f\u00fcr Development\n        bus_enabled=False,\n        mcp_enabled=True,\n        auto_protocol_selection=False\n    )\n\n    # Einfache Security f\u00fcr Development\n    security_config = SecurityConfig(\n        auth_type=AuthType.BEARER,\n        api_token=\"dev-token\",\n        rbac_enabled=False,\n        audit_enabled=False\n    )\n\n    return agent_config, protocol_config, security_config\n</code></pre>"},{"location":"examples/#production-konfiguration","title":"Production-Konfiguration","text":"<pre><code>def create_production_config():\n    \"\"\"Erstellt Production-Konfiguration.\"\"\"\n\n    agent_config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=os.getenv(\"KEI_API_TOKEN\"),\n        agent_id=f\"prod-agent-{socket.gethostname()}\",\n        timeout=30,\n        max_retries=5,\n        retry_delay=2.0\n    )\n\n    # Vollst\u00e4ndige Protokoll-Unterst\u00fctzung\n    protocol_config = ProtocolConfig(\n        rpc_enabled=True,\n        stream_enabled=True,\n        bus_enabled=True,\n        mcp_enabled=True,\n        auto_protocol_selection=True,\n        protocol_fallback_enabled=True\n    )\n\n    # Enterprise Security\n    security_config = SecurityConfig(\n        auth_type=AuthType.OIDC,\n        oidc_issuer=os.getenv(\"OIDC_ISSUER\"),\n        oidc_client_id=os.getenv(\"OIDC_CLIENT_ID\"),\n        oidc_client_secret=os.getenv(\"OIDC_CLIENT_SECRET\"),\n        rbac_enabled=True,\n        audit_enabled=True,\n        token_refresh_enabled=True\n    )\n\n    return agent_config, protocol_config, security_config\n</code></pre>"},{"location":"examples/#monitoring-beispiele","title":"\ud83d\udcca Monitoring-Beispiele","text":""},{"location":"examples/#health-check-setup","title":"Health Check Setup","text":"<pre><code>from kei_agent import get_health_manager, APIHealthCheck, MemoryHealthCheck\n\nasync def setup_monitoring():\n    \"\"\"Richtet umfassendes Monitoring ein.\"\"\"\n\n    health_manager = get_health_manager()\n\n    # API Health Checks\n    health_manager.register_check(APIHealthCheck(\n        name=\"kei_api\",\n        url=\"https://api.kei-framework.com/health\",\n        timeout_seconds=10,\n        critical=True\n    ))\n\n    health_manager.register_check(APIHealthCheck(\n        name=\"external_data_api\",\n        url=\"https://data-api.company.com/health\",\n        timeout_seconds=5,\n        critical=False\n    ))\n\n    # System Health Checks\n    health_manager.register_check(MemoryHealthCheck(\n        name=\"system_memory\",\n        warning_threshold=0.8,\n        critical_threshold=0.95,\n        critical=True\n    ))\n\n    # Kontinuierliches Monitoring\n    while True:\n        summary = await health_manager.run_all_checks()\n\n        if summary.overall_status != \"healthy\":\n            print(f\"\u26a0\ufe0f System Status: {summary.overall_status}\")\n            for check in summary.checks:\n                if check.status != \"healthy\":\n                    print(f\"  - {check.name}: {check.status} - {check.message}\")\n        else:\n            print(\"\u2705 All systems healthy\")\n\n        await asyncio.sleep(60)  # Check every minute\n\n# Background monitoring starten\nasyncio.create_task(setup_monitoring())\n</code></pre>"},{"location":"examples/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>import time\nimport psutil\nfrom kei_agent import get_logger\n\nasync def performance_monitoring_example():\n    \"\"\"Beispiel f\u00fcr Performance-Monitoring.\"\"\"\n\n    logger = get_logger(\"performance_monitor\")\n\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"performance-monitored-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Performance-Tracking f\u00fcr Operation\n        start_time = time.time()\n        start_memory = psutil.Process().memory_info().rss\n\n        try:\n            # Agent-Operation ausf\u00fchren\n            result = await client.plan_task(\"Performance-Test-Operation\")\n\n            # Performance-Metriken berechnen\n            duration = (time.time() - start_time) * 1000\n            end_memory = psutil.Process().memory_info().rss\n            memory_delta = (end_memory - start_memory) / 1024 / 1024  # MB\n\n            # Performance-Metriken loggen\n            logger.log_performance(\n                operation=\"plan_task\",\n                duration_ms=duration,\n                memory_usage=memory_delta,\n                cpu_usage=psutil.cpu_percent(),\n                success=True\n            )\n\n            print(f\"Operation completed in {duration:.2f}ms\")\n            print(f\"Memory usage: {memory_delta:.2f}MB\")\n\n        except Exception as e:\n            duration = (time.time() - start_time) * 1000\n            logger.log_performance(\n                operation=\"plan_task\",\n                duration_ms=duration,\n                success=False,\n                error=str(e)\n            )\n            raise\n\nasyncio.run(performance_monitoring_example())\n</code></pre>"},{"location":"examples/#security-beispiele","title":"\ud83d\udd10 Security-Beispiele","text":""},{"location":"examples/#input-validation","title":"Input Validation","text":"<pre><code>from kei_agent import get_input_validator, ValidationSeverity\n\ndef secure_input_handling_example():\n    \"\"\"Beispiel f\u00fcr sichere Input-Verarbeitung.\"\"\"\n\n    validator = get_input_validator()\n\n    # Unsichere Eingaben testen\n    test_inputs = [\n        {\n            \"objective\": \"Normal objective\",\n            \"context\": {\"format\": \"pdf\"}\n        },\n        {\n            \"objective\": \"&lt;script&gt;alert('xss')&lt;/script&gt;\",\n            \"context\": {\"format\": \"pdf\"}\n        },\n        {\n            \"objective\": \"'; DROP TABLE users; --\",\n            \"context\": {\"format\": \"pdf\"}\n        }\n    ]\n\n    for i, input_data in enumerate(test_inputs):\n        print(f\"\\n--- Test Input {i+1} ---\")\n\n        result = validator.validate_agent_operation(\"plan\", input_data)\n\n        if result.valid:\n            print(\"\u2705 Input valid\")\n            print(f\"Sanitized: {result.sanitized_value}\")\n        else:\n            print(\"\u274c Input invalid\")\n            for error in result.errors:\n                print(f\"  Error: {error}\")\n            for warning in result.warnings:\n                print(f\"  Warning: {warning}\")\n\nsecure_input_handling_example()\n</code></pre>"},{"location":"examples/#audit-logging","title":"Audit Logging","text":"<pre><code>from kei_agent import get_logger, LogContext\n\nasync def audit_logging_example():\n    \"\"\"Beispiel f\u00fcr Audit-Logging.\"\"\"\n\n    logger = get_logger(\"audit_example\")\n\n    # Audit-Kontext setzen\n    logger.set_context(LogContext(\n        correlation_id=logger.create_correlation_id(),\n        user_id=\"user-123\",\n        agent_id=\"audit-agent\",\n        operation=\"sensitive_data_access\"\n    ))\n\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"audit-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Sensitive Operation mit Audit-Logging\n        logger.log_security_event(\n            event_type=\"sensitive_operation_started\",\n            severity=\"info\",\n            description=\"User accessing sensitive financial data\",\n            user_id=\"user-123\",\n            resource=\"financial_reports\",\n            action=\"read\"\n        )\n\n        try:\n            result = await client.plan_task(\n                \"Generate confidential financial report\",\n                context={\"classification\": \"confidential\"}\n            )\n\n            logger.log_security_event(\n                event_type=\"sensitive_operation_completed\",\n                severity=\"info\",\n                description=\"Sensitive operation completed successfully\",\n                result_id=result.get('plan_id')\n            )\n\n        except Exception as e:\n            logger.log_security_event(\n                event_type=\"sensitive_operation_failed\",\n                severity=\"error\",\n                description=\"Sensitive operation failed\",\n                error=str(e)\n            )\n            raise\n\nasyncio.run(audit_logging_example())\n</code></pre>"},{"location":"examples/#error-handling-beispiele","title":"\ud83d\udd04 Error Handling Beispiele","text":""},{"location":"examples/#robuste-fehlerbehandlung","title":"Robuste Fehlerbehandlung","text":"<pre><code>from kei_agent.exceptions import KeiSDKError, ProtocolError, SecurityError\n\nasync def robust_error_handling_example():\n    \"\"\"Beispiel f\u00fcr robuste Fehlerbehandlung.\"\"\"\n\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"error-handling-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        max_retries = 3\n        retry_delay = 1.0\n\n        for attempt in range(max_retries):\n            try:\n                result = await client.plan_task(\"Potentially failing operation\")\n                print(f\"\u2705 Operation successful: {result['plan_id']}\")\n                break\n\n            except SecurityError as e:\n                print(f\"\ud83d\udd12 Security error (attempt {attempt + 1}): {e}\")\n                # Security errors sind nicht retry-bar\n                raise\n\n            except ProtocolError as e:\n                print(f\"\ud83d\udd0c Protocol error (attempt {attempt + 1}): {e}\")\n                if attempt &lt; max_retries - 1:\n                    print(f\"Retrying in {retry_delay} seconds...\")\n                    await asyncio.sleep(retry_delay)\n                    retry_delay *= 2  # Exponential backoff\n                else:\n                    print(\"\u274c All retry attempts failed\")\n                    raise\n\n            except KeiSDKError as e:\n                print(f\"\u26a0\ufe0f SDK error (attempt {attempt + 1}): {e}\")\n                if attempt &lt; max_retries - 1:\n                    await asyncio.sleep(retry_delay)\n                else:\n                    raise\n\n            except Exception as e:\n                print(f\"\u274c Unexpected error: {e}\")\n                raise\n\nasyncio.run(robust_error_handling_example())\n</code></pre>"},{"location":"examples/#vollstandige-anwendungsbeispiele","title":"\ud83d\udcc1 Vollst\u00e4ndige Anwendungsbeispiele","text":"<p>Die folgenden Seiten enthalten vollst\u00e4ndige, ausf\u00fchrbare Beispiele f\u00fcr spezifische Anwendungsf\u00e4lle:</p> <ul> <li>Basis-Verwendung \u2192 - Grundlegende Agent-Operationen</li> <li>Multi-Protocol \u2192 - Protokoll-spezifische Features</li> <li>Enterprise Setup \u2192 - Production-Deployment</li> <li>Custom Integrations \u2192 - Erweiterungen und Anpassungen</li> <li>Performance Tuning \u2192 - Optimierung f\u00fcr High-Performance</li> </ul> <p>Tipp: Alle Beispiele sind vollst\u00e4ndig ausf\u00fchrbar. Ersetzen Sie einfach die Platzhalter-Werte (API-Token, URLs) durch Ihre tats\u00e4chlichen Konfigurationsdaten.</p>"},{"location":"examples/enterprise-setup/","title":"\ud83c\udfe2 Enterprise Setup Examples","text":"<p>Beispiele f\u00fcr Enterprise-grade Deployment und Konfiguration von Keiko Personal Assistant.</p>"},{"location":"examples/enterprise-setup/#security-configuration","title":"\ud83d\udd10 Security Configuration","text":""},{"location":"examples/enterprise-setup/#multi-factor-authentication-setup","title":"Multi-Factor Authentication Setup","text":"<pre><code># config/security.py\nfrom keiko.security import SecurityConfig, MFAConfig, EncryptionConfig\n\nENTERPRISE_SECURITY_CONFIG = SecurityConfig(\n    # Multi-Factor Authentication\n    mfa=MFAConfig(\n        enabled=True,\n        required_methods=[\"totp\", \"hardware_token\"],\n        backup_codes_enabled=True,\n        session_timeout_minutes=60,\n        remember_device_days=0  # Keine Device-Erinnerung in Enterprise\n    ),\n\n    # Encryption\n    encryption=EncryptionConfig(\n        algorithm=\"AES-256-GCM\",\n        key_rotation_days=30,\n        data_at_rest_encryption=True,\n        data_in_transit_encryption=True\n    ),\n\n    # Password Policy\n    password_policy={\n        \"min_length\": 12,\n        \"require_uppercase\": True,\n        \"require_lowercase\": True,\n        \"require_numbers\": True,\n        \"require_special_chars\": True,\n        \"max_age_days\": 90,\n        \"history_count\": 12\n    },\n\n    # Session Management\n    session_config={\n        \"secure_cookies\": True,\n        \"httponly_cookies\": True,\n        \"samesite\": \"strict\",\n        \"session_timeout\": 3600,\n        \"concurrent_sessions_limit\": 3\n    }\n)\n\n# Anwendung der Konfiguration\nfrom keiko.core.auth import AuthService\n\nauth_service = AuthService(ENTERPRISE_SECURITY_CONFIG)\n</code></pre>"},{"location":"examples/enterprise-setup/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<pre><code># config/rbac.py\nfrom keiko.security.rbac import Role, Permission, RBACConfig\n\n# Berechtigungen definieren\nPERMISSIONS = {\n    # System-Berechtigungen\n    \"system:admin\": Permission(\"system:admin\", \"Vollzugriff auf System\"),\n    \"system:config\": Permission(\"system:config\", \"System-Konfiguration\"),\n    \"system:monitoring\": Permission(\"system:monitoring\", \"System-Monitoring\"),\n\n    # Agent-Berechtigungen\n    \"agents:create\": Permission(\"agents:create\", \"Agenten erstellen\"),\n    \"agents:read\": Permission(\"agents:read\", \"Agenten anzeigen\"),\n    \"agents:update\": Permission(\"agents:update\", \"Agenten bearbeiten\"),\n    \"agents:delete\": Permission(\"agents:delete\", \"Agenten l\u00f6schen\"),\n    \"agents:execute\": Permission(\"agents:execute\", \"Agenten ausf\u00fchren\"),\n\n    # Task-Berechtigungen\n    \"tasks:create\": Permission(\"tasks:create\", \"Tasks erstellen\"),\n    \"tasks:read\": Permission(\"tasks:read\", \"Tasks anzeigen\"),\n    \"tasks:cancel\": Permission(\"tasks:cancel\", \"Tasks abbrechen\"),\n\n    # User-Berechtigungen\n    \"users:create\": Permission(\"users:create\", \"Benutzer erstellen\"),\n    \"users:read\": Permission(\"users:read\", \"Benutzer anzeigen\"),\n    \"users:update\": Permission(\"users:update\", \"Benutzer bearbeiten\"),\n    \"users:delete\": Permission(\"users:delete\", \"Benutzer l\u00f6schen\")\n}\n\n# Rollen definieren\nROLES = {\n    \"system_admin\": Role(\n        name=\"system_admin\",\n        description=\"System-Administrator\",\n        permissions=[\n            PERMISSIONS[\"system:admin\"],\n            PERMISSIONS[\"system:config\"],\n            PERMISSIONS[\"system:monitoring\"],\n            PERMISSIONS[\"users:create\"],\n            PERMISSIONS[\"users:read\"],\n            PERMISSIONS[\"users:update\"],\n            PERMISSIONS[\"users:delete\"]\n        ]\n    ),\n\n    \"agent_operator\": Role(\n        name=\"agent_operator\",\n        description=\"Agent-Operator\",\n        permissions=[\n            PERMISSIONS[\"agents:create\"],\n            PERMISSIONS[\"agents:read\"],\n            PERMISSIONS[\"agents:update\"],\n            PERMISSIONS[\"agents:execute\"],\n            PERMISSIONS[\"tasks:create\"],\n            PERMISSIONS[\"tasks:read\"],\n            PERMISSIONS[\"tasks:cancel\"]\n        ]\n    ),\n\n    \"business_user\": Role(\n        name=\"business_user\",\n        description=\"Business-Benutzer\",\n        permissions=[\n            PERMISSIONS[\"agents:read\"],\n            PERMISSIONS[\"agents:execute\"],\n            PERMISSIONS[\"tasks:create\"],\n            PERMISSIONS[\"tasks:read\"]\n        ]\n    ),\n\n    \"viewer\": Role(\n        name=\"viewer\",\n        description=\"Nur-Lese-Zugriff\",\n        permissions=[\n            PERMISSIONS[\"agents:read\"],\n            PERMISSIONS[\"tasks:read\"],\n            PERMISSIONS[\"system:monitoring\"]\n        ]\n    )\n}\n\n# RBAC-Konfiguration\nRBAC_CONFIG = RBACConfig(\n    roles=ROLES,\n    permissions=PERMISSIONS,\n    default_role=\"viewer\",\n    role_inheritance_enabled=True,\n    permission_caching_enabled=True,\n    cache_ttl_seconds=300\n)\n</code></pre>"},{"location":"examples/enterprise-setup/#high-availability-setup","title":"\ud83c\udfd7\ufe0f High-Availability Setup","text":""},{"location":"examples/enterprise-setup/#load-balancer-configuration","title":"Load Balancer Configuration","text":"<pre><code># nginx/keiko.conf\nupstream keiko_backend {\n    least_conn;\n    server keiko-app-1:8000 max_fails=3 fail_timeout=30s;\n    server keiko-app-2:8000 max_fails=3 fail_timeout=30s;\n    server keiko-app-3:8000 max_fails=3 fail_timeout=30s;\n}\n\nupstream keiko_websocket {\n    ip_hash;  # Sticky sessions f\u00fcr WebSocket\n    server keiko-app-1:8000;\n    server keiko-app-2:8000;\n    server keiko-app-3:8000;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name api.keiko.enterprise.com;\n\n    # SSL-Konfiguration\n    ssl_certificate /etc/ssl/certs/keiko.crt;\n    ssl_certificate_key /etc/ssl/private/keiko.key;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;\n    ssl_prefer_server_ciphers off;\n\n    # Security Headers\n    add_header Strict-Transport-Security \"max-age=63072000\" always;\n    add_header X-Frame-Options DENY;\n    add_header X-Content-Type-Options nosniff;\n    add_header X-XSS-Protection \"1; mode=block\";\n\n    # API-Routen\n    location /api/ {\n        proxy_pass http://keiko_backend;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # Timeouts\n        proxy_connect_timeout 60s;\n        proxy_send_timeout 60s;\n        proxy_read_timeout 60s;\n\n        # Rate Limiting\n        limit_req zone=api burst=20 nodelay;\n    }\n\n    # WebSocket-Routen\n    location /ws {\n        proxy_pass http://keiko_websocket;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # WebSocket-spezifische Timeouts\n        proxy_read_timeout 86400;\n    }\n\n    # Health Check\n    location /health {\n        proxy_pass http://keiko_backend;\n        access_log off;\n    }\n}\n\n# Rate Limiting\nhttp {\n    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\n    limit_req_zone $binary_remote_addr zone=auth:10m rate=1r/s;\n}\n</code></pre>"},{"location":"examples/enterprise-setup/#database-cluster-setup","title":"Database Cluster Setup","text":"<pre><code># docker-compose.enterprise.yml\nversion: '3.8'\n\nservices:\n  # PostgreSQL Master\n  postgres-master:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: keiko\n      POSTGRES_USER: keiko_user\n      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password\n      POSTGRES_REPLICATION_USER: replicator\n      POSTGRES_REPLICATION_PASSWORD_FILE: /run/secrets/replication_password\n    volumes:\n      - postgres_master_data:/var/lib/postgresql/data\n      - ./postgres/master.conf:/etc/postgresql/postgresql.conf\n      - ./postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf\n    secrets:\n      - postgres_password\n      - replication_password\n    networks:\n      - keiko_db_network\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - node.role == manager\n\n  # PostgreSQL Read Replicas\n  postgres-replica-1:\n    image: postgres:15\n    environment:\n      PGUSER: postgres\n      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password\n      POSTGRES_MASTER_SERVICE: postgres-master\n    volumes:\n      - postgres_replica1_data:/var/lib/postgresql/data\n      - ./postgres/replica.conf:/etc/postgresql/postgresql.conf\n    secrets:\n      - postgres_password\n      - replication_password\n    networks:\n      - keiko_db_network\n    depends_on:\n      - postgres-master\n\n  # Redis Cluster\n  redis-master:\n    image: redis:7-alpine\n    command: redis-server --appendonly yes --replica-announce-ip redis-master\n    volumes:\n      - redis_master_data:/data\n    networks:\n      - keiko_cache_network\n\n  redis-replica-1:\n    image: redis:7-alpine\n    command: redis-server --replicaof redis-master 6379\n    volumes:\n      - redis_replica1_data:/data\n    networks:\n      - keiko_cache_network\n    depends_on:\n      - redis-master\n\n  # Keiko Application Instances\n  keiko-app-1:\n    build: .\n    environment:\n      DATABASE_URL: postgresql://keiko_user:${POSTGRES_PASSWORD}@postgres-master:5432/keiko\n      DATABASE_REPLICA_URLS: postgresql://keiko_user:${POSTGRES_PASSWORD}@postgres-replica-1:5432/keiko\n      REDIS_URL: redis://redis-master:6379\n      INSTANCE_ID: app-1\n    secrets:\n      - postgres_password\n      - azure_ai_key\n      - jwt_secret\n    networks:\n      - keiko_app_network\n      - keiko_db_network\n      - keiko_cache_network\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n        order: start-first\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n\nsecrets:\n  postgres_password:\n    external: true\n  replication_password:\n    external: true\n  azure_ai_key:\n    external: true\n  jwt_secret:\n    external: true\n\nnetworks:\n  keiko_app_network:\n    driver: overlay\n  keiko_db_network:\n    driver: overlay\n  keiko_cache_network:\n    driver: overlay\n\nvolumes:\n  postgres_master_data:\n  postgres_replica1_data:\n  redis_master_data:\n  redis_replica1_data:\n</code></pre>"},{"location":"examples/enterprise-setup/#enterprise-monitoring","title":"\ud83d\udcca Enterprise Monitoring","text":""},{"location":"examples/enterprise-setup/#comprehensive-monitoring-stack","title":"Comprehensive Monitoring Stack","text":"<pre><code># monitoring/docker-compose.monitoring.yml\nversion: '3.8'\n\nservices:\n  # Prometheus\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n      - ./prometheus/rules:/etc/prometheus/rules\n      - prometheus_data:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--web.console.libraries=/etc/prometheus/console_libraries'\n      - '--web.console.templates=/etc/prometheus/consoles'\n      - '--storage.tsdb.retention.time=30d'\n      - '--web.enable-lifecycle'\n      - '--web.enable-admin-api'\n\n  # Grafana\n  grafana:\n    image: grafana/grafana:latest\n    ports:\n      - \"3000:3000\"\n    environment:\n      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}\n      GF_USERS_ALLOW_SIGN_UP: false\n      GF_AUTH_ANONYMOUS_ENABLED: false\n    volumes:\n      - grafana_data:/var/lib/grafana\n      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards\n      - ./grafana/datasources:/etc/grafana/provisioning/datasources\n\n  # AlertManager\n  alertmanager:\n    image: prom/alertmanager:latest\n    ports:\n      - \"9093:9093\"\n    volumes:\n      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n      - alertmanager_data:/alertmanager\n\n  # Jaeger (Distributed Tracing)\n  jaeger:\n    image: jaegertracing/all-in-one:latest\n    ports:\n      - \"16686:16686\"\n      - \"14268:14268\"\n    environment:\n      COLLECTOR_OTLP_ENABLED: true\n\n  # ELK Stack f\u00fcr Logging\n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0\n    environment:\n      - discovery.type=single-node\n      - \"ES_JAVA_OPTS=-Xms2g -Xmx2g\"\n      - xpack.security.enabled=false\n    volumes:\n      - elasticsearch_data:/usr/share/elasticsearch/data\n\n  logstash:\n    image: docker.elastic.co/logstash/logstash:8.8.0\n    volumes:\n      - ./logstash/pipeline:/usr/share/logstash/pipeline\n    depends_on:\n      - elasticsearch\n\n  kibana:\n    image: docker.elastic.co/kibana/kibana:8.8.0\n    ports:\n      - \"5601:5601\"\n    environment:\n      ELASTICSEARCH_HOSTS: http://elasticsearch:9200\n    depends_on:\n      - elasticsearch\n\nvolumes:\n  prometheus_data:\n  grafana_data:\n  alertmanager_data:\n  elasticsearch_data:\n</code></pre>"},{"location":"examples/enterprise-setup/#enterprise-alerting-configuration","title":"Enterprise Alerting Configuration","text":"<pre><code># alertmanager/alertmanager.yml\nglobal:\n  smtp_smarthost: 'smtp.enterprise.com:587'\n  smtp_from: 'alerts@keiko.enterprise.com'\n  smtp_auth_username: 'alerts@keiko.enterprise.com'\n  smtp_auth_password: '${SMTP_PASSWORD}'\n\nroute:\n  group_by: ['alertname', 'cluster', 'service']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 1h\n  receiver: 'default'\n  routes:\n    - match:\n        severity: critical\n      receiver: 'critical-alerts'\n      group_wait: 0s\n      repeat_interval: 5m\n    - match:\n        severity: warning\n      receiver: 'warning-alerts'\n      repeat_interval: 30m\n\nreceivers:\n  - name: 'default'\n    email_configs:\n      - to: 'ops-team@enterprise.com'\n        subject: 'Keiko Alert: {{ .GroupLabels.alertname }}'\n        body: |\n          {{ range .Alerts }}\n          Alert: {{ .Annotations.summary }}\n          Description: {{ .Annotations.description }}\n          Severity: {{ .Labels.severity }}\n          Instance: {{ .Labels.instance }}\n          {{ end }}\n\n  - name: 'critical-alerts'\n    email_configs:\n      - to: 'critical-alerts@enterprise.com'\n        subject: 'CRITICAL: Keiko Alert'\n    slack_configs:\n      - api_url: '${SLACK_WEBHOOK_URL}'\n        channel: '#critical-alerts'\n        title: 'Critical Keiko Alert'\n        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'\n\n  - name: 'warning-alerts'\n    email_configs:\n      - to: 'warnings@enterprise.com'\n        subject: 'WARNING: Keiko Alert'\n\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'cluster', 'service']\n</code></pre>"},{"location":"examples/enterprise-setup/#compliance-audit","title":"\ud83d\udd12 Compliance &amp; Audit","text":""},{"location":"examples/enterprise-setup/#gdpr-compliance-setup","title":"GDPR Compliance Setup","text":"<pre><code># compliance/gdpr.py\nfrom keiko.compliance import GDPRCompliance, DataProcessor, ConsentManager\n\nclass EnterpriseGDPRCompliance(GDPRCompliance):\n    \"\"\"Enterprise GDPR-Compliance-Implementation.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.data_processor = DataProcessor()\n        self.consent_manager = ConsentManager()\n        self.audit_logger = AuditLogger()\n\n    async def process_data_subject_request(self, request_type: str, user_id: str) -&gt; dict:\n        \"\"\"Verarbeitet Data Subject Requests.\"\"\"\n\n        await self.audit_logger.log_gdpr_request(request_type, user_id)\n\n        if request_type == \"access\":\n            return await self._handle_data_access_request(user_id)\n        elif request_type == \"portability\":\n            return await self._handle_data_portability_request(user_id)\n        elif request_type == \"erasure\":\n            return await self._handle_data_erasure_request(user_id)\n        elif request_type == \"rectification\":\n            return await self._handle_data_rectification_request(user_id)\n        else:\n            raise ValueError(f\"Unbekannter Request-Typ: {request_type}\")\n\n    async def _handle_data_access_request(self, user_id: str) -&gt; dict:\n        \"\"\"Behandelt Data Access Request (Art. 15 GDPR).\"\"\"\n\n        # Alle Benutzerdaten sammeln\n        user_data = await self.data_processor.collect_user_data(user_id)\n\n        # Daten anonymisieren/pseudonymisieren wo n\u00f6tig\n        processed_data = await self.data_processor.prepare_for_export(user_data)\n\n        # Export-Datei erstellen\n        export_file = await self.data_processor.create_export_file(\n            user_id, processed_data, format=\"json\"\n        )\n\n        return {\n            \"request_type\": \"access\",\n            \"user_id\": user_id,\n            \"export_file\": export_file,\n            \"data_categories\": list(processed_data.keys()),\n            \"processing_date\": datetime.utcnow().isoformat()\n        }\n\n    async def _handle_data_erasure_request(self, user_id: str) -&gt; dict:\n        \"\"\"Behandelt Right to be Forgotten (Art. 17 GDPR).\"\"\"\n\n        # Pr\u00fcfen ob L\u00f6schung rechtlich zul\u00e4ssig\n        legal_check = await self.data_processor.check_erasure_legality(user_id)\n\n        if not legal_check.allowed:\n            return {\n                \"request_type\": \"erasure\",\n                \"user_id\": user_id,\n                \"status\": \"rejected\",\n                \"reason\": legal_check.reason\n            }\n\n        # Daten l\u00f6schen\n        deletion_result = await self.data_processor.erase_user_data(\n            user_id,\n            categories=legal_check.erasable_categories\n        )\n\n        # Audit-Log erstellen\n        await self.audit_logger.log_data_erasure(user_id, deletion_result)\n\n        return {\n            \"request_type\": \"erasure\",\n            \"user_id\": user_id,\n            \"status\": \"completed\",\n            \"deleted_categories\": deletion_result.deleted_categories,\n            \"retained_categories\": deletion_result.retained_categories,\n            \"retention_reasons\": deletion_result.retention_reasons\n        }\n\n# GDPR-Service konfigurieren\ngdpr_service = EnterpriseGDPRCompliance()\n\n# Data Subject Request verarbeiten\n@app.post(\"/api/v1/gdpr/data-subject-request\")\nasync def handle_data_subject_request(\n    request: DataSubjectRequest,\n    current_user: User = Depends(get_current_user)\n):\n    \"\"\"Endpoint f\u00fcr Data Subject Requests.\"\"\"\n\n    # Berechtigung pr\u00fcfen (nur eigene Daten oder Admin)\n    if request.user_id != current_user.id and not current_user.is_admin:\n        raise HTTPException(403, \"Nicht berechtigt\")\n\n    result = await gdpr_service.process_data_subject_request(\n        request.request_type,\n        request.user_id\n    )\n\n    return result\n</code></pre>"},{"location":"examples/enterprise-setup/#soc-2-compliance","title":"SOC 2 Compliance","text":"<pre><code># compliance/soc2.py\nfrom keiko.compliance import SOC2Compliance, SecurityControl\n\nclass EnterpriseSOC2Compliance(SOC2Compliance):\n    \"\"\"SOC 2 Type II Compliance-Implementation.\"\"\"\n\n    def __init__(self):\n        self.security_controls = self._initialize_security_controls()\n        self.audit_logger = AuditLogger()\n        self.evidence_collector = EvidenceCollector()\n\n    def _initialize_security_controls(self) -&gt; Dict[str, SecurityControl]:\n        \"\"\"Initialisiert SOC 2 Security Controls.\"\"\"\n\n        return {\n            # CC1: Control Environment\n            \"CC1.1\": SecurityControl(\n                id=\"CC1.1\",\n                description=\"Management establishes structures, reporting lines, and appropriate authorities\",\n                implementation=self._check_organizational_structure,\n                frequency=\"quarterly\"\n            ),\n\n            # CC2: Communication and Information\n            \"CC2.1\": SecurityControl(\n                id=\"CC2.1\",\n                description=\"Management communicates information security policies\",\n                implementation=self._check_security_communication,\n                frequency=\"monthly\"\n            ),\n\n            # CC6: Logical and Physical Access Controls\n            \"CC6.1\": SecurityControl(\n                id=\"CC6.1\",\n                description=\"Logical access security measures\",\n                implementation=self._check_logical_access_controls,\n                frequency=\"daily\"\n            ),\n\n            # CC7: System Operations\n            \"CC7.1\": SecurityControl(\n                id=\"CC7.1\",\n                description=\"System operations procedures\",\n                implementation=self._check_system_operations,\n                frequency=\"daily\"\n            ),\n\n            # CC8: Change Management\n            \"CC8.1\": SecurityControl(\n                id=\"CC8.1\",\n                description=\"Change management procedures\",\n                implementation=self._check_change_management,\n                frequency=\"per_change\"\n            )\n        }\n\n    async def run_compliance_check(self) -&gt; SOC2ComplianceReport:\n        \"\"\"F\u00fchrt vollst\u00e4ndige SOC 2 Compliance-Pr\u00fcfung durch.\"\"\"\n\n        report = SOC2ComplianceReport()\n\n        for control_id, control in self.security_controls.items():\n            try:\n                result = await control.implementation()\n\n                report.add_control_result(control_id, result)\n\n                # Evidence sammeln\n                evidence = await self.evidence_collector.collect_evidence(\n                    control_id, result\n                )\n                report.add_evidence(control_id, evidence)\n\n            except Exception as e:\n                report.add_control_failure(control_id, str(e))\n\n        # Audit-Log erstellen\n        await self.audit_logger.log_compliance_check(\"SOC2\", report)\n\n        return report\n\n    async def _check_logical_access_controls(self) -&gt; ControlResult:\n        \"\"\"Pr\u00fcft logische Zugangskontrollen (CC6.1).\"\"\"\n\n        checks = []\n\n        # Multi-Factor Authentication\n        mfa_enabled = await self._check_mfa_enforcement()\n        checks.append((\"MFA Enforcement\", mfa_enabled))\n\n        # Password Policy\n        password_policy = await self._check_password_policy_compliance()\n        checks.append((\"Password Policy\", password_policy))\n\n        # Session Management\n        session_controls = await self._check_session_controls()\n        checks.append((\"Session Controls\", session_controls))\n\n        # Access Reviews\n        access_reviews = await self._check_access_reviews()\n        checks.append((\"Access Reviews\", access_reviews))\n\n        # Privileged Access\n        privileged_access = await self._check_privileged_access_controls()\n        checks.append((\"Privileged Access\", privileged_access))\n\n        passed_checks = sum(1 for _, result in checks if result.passed)\n        total_checks = len(checks)\n\n        return ControlResult(\n            control_id=\"CC6.1\",\n            passed=passed_checks == total_checks,\n            score=passed_checks / total_checks,\n            details=checks,\n            evidence_collected=True\n        )\n</code></pre> <p>Enterprise-Sicherheit</p> <p>Diese Beispiele zeigen Enterprise-grade Konfigurationen. Passen Sie sie an Ihre spezifischen Sicherheitsanforderungen und Compliance-Standards an.</p> <p>Skalierung</p> <p>F\u00fcr gro\u00dfe Enterprise-Deployments sollten Sie zus\u00e4tzlich Container-Orchestrierung (Kubernetes), Service-Mesh (Istio) und erweiterte Monitoring-L\u00f6sungen in Betracht ziehen.</p>"},{"location":"examples/multi-protocol/","title":"\ud83c\udf10 Multi-Protocol Examples","text":"<p>Beispiele f\u00fcr die Nutzung verschiedener Kommunikationsprotokolle in Keiko Personal Assistant.</p>"},{"location":"examples/multi-protocol/#protocol-client-setup","title":"\ud83d\udd0c Protocol-Client-Setup","text":""},{"location":"examples/multi-protocol/#httprest-client","title":"HTTP/REST-Client","text":"<pre><code>from keiko.protocols.http import HTTPClient, HTTPConfig\n\n# HTTP-Client konfigurieren\nhttp_config = HTTPConfig(\n    base_url=\"https://api.example.com\",\n    timeout=30.0,\n    max_retries=3,\n    auth_token=\"your-api-token\",\n    verify_ssl=True\n)\n\n# Client verwenden\nasync with HTTPClient(http_config) as client:\n    # GET-Request\n    response = await client.get(\"/users\", params={\"limit\": 10})\n    users = response.json[\"users\"]\n\n    # POST-Request\n    new_user = {\n        \"username\": \"newuser\",\n        \"email\": \"user@example.com\"\n    }\n    response = await client.post(\"/users\", data=new_user)\n    created_user = response.json\n\n    print(f\"Benutzer erstellt: {created_user['id']}\")\n</code></pre>"},{"location":"examples/multi-protocol/#websocket-client","title":"WebSocket-Client","text":"<pre><code>from keiko.protocols.websocket import WebSocketClient, WebSocketConfig\n\n# WebSocket-Client konfigurieren\nws_config = WebSocketConfig(\n    url=\"wss://api.example.com/ws\",\n    auth_token=\"your-token\",\n    ping_interval=30.0,\n    max_message_size=1024*1024\n)\n\n# Event-Handler definieren\nasync def handle_notification(data):\n    print(f\"Benachrichtigung: {data['message']}\")\n\nasync def handle_task_update(data):\n    print(f\"Task-Update: {data['task_id']} -&gt; {data['status']}\")\n\n# Client verwenden\nclient = WebSocketClient(ws_config)\n\n# Handler registrieren\nclient.register_handler(\"notification\", handle_notification)\nclient.register_handler(\"task_update\", handle_task_update)\n\n# Verbindung herstellen\nawait client.connect()\n\n# Nachrichten senden\nawait client.send_message(\"subscribe\", {\n    \"events\": [\"notifications\", \"task_updates\"],\n    \"user_id\": \"user123\"\n})\n\n# Verbindung offen halten\ntry:\n    while client.is_connected:\n        await asyncio.sleep(1)\nexcept KeyboardInterrupt:\n    await client.disconnect()\n</code></pre>"},{"location":"examples/multi-protocol/#mcp-client","title":"MCP-Client","text":"<pre><code>from keiko.protocols.mcp import MCPClient\n\n# MCP-Client konfigurieren\nmcp_config = {\n    'server_url': 'http://localhost:8080',\n    'auth_config': {\n        'type': 'api_key',\n        'api_key': 'your-mcp-key'\n    }\n}\n\nasync with MCPClient(**mcp_config) as client:\n    # Server-Informationen abrufen\n    server_info = await client.get_server_info()\n    print(f\"MCP-Server: {server_info['name']} v{server_info['version']}\")\n\n    # Verf\u00fcgbare Tools auflisten\n    tools = await client.list_tools()\n    for tool in tools:\n        print(f\"Tool: {tool['name']} - {tool['description']}\")\n\n    # Tool ausf\u00fchren\n    result = await client.execute_tool(\n        tool_name=\"weather_forecast\",\n        arguments={\n            \"location\": \"Berlin, Germany\",\n            \"days\": 3\n        }\n    )\n\n    print(f\"Wettervorhersage: {result}\")\n</code></pre>"},{"location":"examples/multi-protocol/#protocol-selection","title":"\ud83c\udfaf Protocol-Selection","text":""},{"location":"examples/multi-protocol/#automatische-protocol-auswahl","title":"Automatische Protocol-Auswahl","text":"<pre><code>from keiko.protocols import ProtocolSelector, ProtocolRequirements, ServiceCapabilities\n\n# Service-Capabilities definieren\nservice_caps = ServiceCapabilities(\n    supports_http=True,\n    supports_websocket=True,\n    supports_grpc=False,\n    supports_mcp=True,\n    real_time_required=False,\n    high_throughput=False\n)\n\n# Anforderungen definieren\nrequirements = ProtocolRequirements(\n    operation_type=\"query\",\n    data_size=1024,  # 1KB\n    expected_response_time=2.0,\n    reliability_level=\"normal\"\n)\n\n# Protocol-Selector verwenden\nselector = ProtocolSelector()\nbest_protocol = selector.select_protocol(service_caps, requirements)\n\nprint(f\"Empfohlenes Protokoll: {best_protocol.protocol.value}\")\nprint(f\"Score: {best_protocol.score:.2f}\")\nprint(f\"Gr\u00fcnde: {best_protocol.reasons}\")\n</code></pre>"},{"location":"examples/multi-protocol/#conditional-protocol-usage","title":"Conditional Protocol Usage","text":"<pre><code>class AdaptiveClient:\n    \"\"\"Client der sich automatisch an verf\u00fcgbare Protokolle anpasst.\"\"\"\n\n    def __init__(self, service_url: str):\n        self.service_url = service_url\n        self.available_protocols = self._detect_protocols()\n        self.current_client = None\n\n    async def _detect_protocols(self) -&gt; List[str]:\n        \"\"\"Erkennt verf\u00fcgbare Protokolle.\"\"\"\n        protocols = []\n\n        # HTTP-Verf\u00fcgbarkeit pr\u00fcfen\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(f\"{self.service_url}/health\") as response:\n                    if response.status == 200:\n                        protocols.append(\"http\")\n        except:\n            pass\n\n        # WebSocket-Verf\u00fcgbarkeit pr\u00fcfen\n        try:\n            ws_url = self.service_url.replace(\"http\", \"ws\") + \"/ws\"\n            async with websockets.connect(ws_url) as ws:\n                protocols.append(\"websocket\")\n        except:\n            pass\n\n        return protocols\n\n    async def send_request(self, operation: str, data: dict) -&gt; dict:\n        \"\"\"Sendet Request mit bestem verf\u00fcgbaren Protokoll.\"\"\"\n\n        if operation == \"real_time_stream\" and \"websocket\" in self.available_protocols:\n            return await self._send_websocket_request(operation, data)\n        elif \"http\" in self.available_protocols:\n            return await self._send_http_request(operation, data)\n        else:\n            raise Exception(\"Keine verf\u00fcgbaren Protokolle\")\n\n    async def _send_http_request(self, operation: str, data: dict) -&gt; dict:\n        \"\"\"Sendet HTTP-Request.\"\"\"\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\n                f\"{self.service_url}/api/{operation}\",\n                json=data\n            ) as response:\n                return await response.json()\n\n    async def _send_websocket_request(self, operation: str, data: dict) -&gt; dict:\n        \"\"\"Sendet WebSocket-Request.\"\"\"\n        ws_url = self.service_url.replace(\"http\", \"ws\") + \"/ws\"\n\n        async with websockets.connect(ws_url) as ws:\n            request = {\n                \"operation\": operation,\n                \"data\": data,\n                \"request_id\": str(uuid.uuid4())\n            }\n\n            await ws.send(json.dumps(request))\n            response = await ws.recv()\n            return json.loads(response)\n\n# Verwendung\nclient = AdaptiveClient(\"http://localhost:8000\")\n\n# Normale Anfrage (wird HTTP verwenden)\nresult = await client.send_request(\"get_data\", {\"query\": \"users\"})\n\n# Real-Time-Anfrage (wird WebSocket verwenden wenn verf\u00fcgbar)\nstream_result = await client.send_request(\"real_time_stream\", {\"topic\": \"events\"})\n</code></pre>"},{"location":"examples/multi-protocol/#protocol-switching","title":"\ud83d\udd04 Protocol-Switching","text":""},{"location":"examples/multi-protocol/#fallback-mechanismus","title":"Fallback-Mechanismus","text":"<pre><code>class ResilientClient:\n    \"\"\"Client mit automatischem Protocol-Fallback.\"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config\n        self.protocol_priority = [\"grpc\", \"websocket\", \"http\"]\n        self.clients = {}\n\n    async def initialize(self):\n        \"\"\"Initialisiert verf\u00fcgbare Clients.\"\"\"\n\n        # HTTP-Client (immer verf\u00fcgbar)\n        self.clients[\"http\"] = HTTPClient(HTTPConfig(**self.config[\"http\"]))\n\n        # WebSocket-Client (optional)\n        if \"websocket\" in self.config:\n            try:\n                self.clients[\"websocket\"] = WebSocketClient(\n                    WebSocketConfig(**self.config[\"websocket\"])\n                )\n                await self.clients[\"websocket\"].connect()\n            except Exception as e:\n                print(f\"WebSocket nicht verf\u00fcgbar: {e}\")\n\n        # gRPC-Client (optional)\n        if \"grpc\" in self.config:\n            try:\n                self.clients[\"grpc\"] = GRPCClient(GRPCConfig(**self.config[\"grpc\"]))\n                await self.clients[\"grpc\"].connect()\n            except Exception as e:\n                print(f\"gRPC nicht verf\u00fcgbar: {e}\")\n\n    async def execute_with_fallback(self, operation: str, data: dict) -&gt; dict:\n        \"\"\"F\u00fchrt Operation mit Fallback-Mechanismus aus.\"\"\"\n\n        last_error = None\n\n        for protocol in self.protocol_priority:\n            if protocol not in self.clients:\n                continue\n\n            try:\n                client = self.clients[protocol]\n\n                if protocol == \"http\":\n                    return await client.post(f\"/api/{operation}\", data=data)\n                elif protocol == \"websocket\":\n                    await client.send_message(operation, data)\n                    # Warten auf Response (vereinfacht)\n                    return {\"status\": \"sent\"}\n                elif protocol == \"grpc\":\n                    # gRPC-spezifische Implementierung\n                    return await client.call_method(operation, data)\n\n            except Exception as e:\n                last_error = e\n                print(f\"Protokoll {protocol} fehlgeschlagen: {e}\")\n                continue\n\n        raise Exception(f\"Alle Protokolle fehlgeschlagen. Letzter Fehler: {last_error}\")\n\n# Verwendung\nconfig = {\n    \"http\": {\n        \"base_url\": \"http://localhost:8000\",\n        \"timeout\": 30.0\n    },\n    \"websocket\": {\n        \"url\": \"ws://localhost:8000/ws\"\n    },\n    \"grpc\": {\n        \"server_address\": \"localhost:9000\"\n    }\n}\n\nclient = ResilientClient(config)\nawait client.initialize()\n\n# Operation ausf\u00fchren (automatischer Fallback)\nresult = await client.execute_with_fallback(\"process_data\", {\n    \"input\": \"test data\",\n    \"options\": {\"format\": \"json\"}\n})\n</code></pre>"},{"location":"examples/multi-protocol/#protocol-performance-monitoring","title":"\ud83d\udcca Protocol-Performance-Monitoring","text":""},{"location":"examples/multi-protocol/#performance-vergleich","title":"Performance-Vergleich","text":"<pre><code>import time\nfrom typing import Dict, List\n\nclass ProtocolBenchmark:\n    \"\"\"Benchmark f\u00fcr verschiedene Protokolle.\"\"\"\n\n    def __init__(self):\n        self.results: Dict[str, List[float]] = {}\n\n    async def benchmark_protocol(\n        self,\n        protocol_name: str,\n        client,\n        operation: str,\n        data: dict,\n        iterations: int = 100\n    ):\n        \"\"\"Benchmarkt ein Protokoll.\"\"\"\n\n        times = []\n\n        for i in range(iterations):\n            start_time = time.time()\n\n            try:\n                if protocol_name == \"http\":\n                    await client.post(f\"/api/{operation}\", data=data)\n                elif protocol_name == \"websocket\":\n                    await client.send_message(operation, data)\n                elif protocol_name == \"grpc\":\n                    await client.call_method(operation, data)\n\n                duration = time.time() - start_time\n                times.append(duration)\n\n            except Exception as e:\n                print(f\"Fehler in Iteration {i}: {e}\")\n\n        self.results[protocol_name] = times\n\n        # Statistiken berechnen\n        avg_time = sum(times) / len(times)\n        min_time = min(times)\n        max_time = max(times)\n\n        print(f\"{protocol_name} Benchmark:\")\n        print(f\"  Durchschnitt: {avg_time:.3f}s\")\n        print(f\"  Minimum: {min_time:.3f}s\")\n        print(f\"  Maximum: {max_time:.3f}s\")\n        print(f\"  Erfolgreiche Requests: {len(times)}/{iterations}\")\n\n    async def compare_protocols(self):\n        \"\"\"Vergleicht alle benchmarkten Protokolle.\"\"\"\n\n        if not self.results:\n            print(\"Keine Benchmark-Daten verf\u00fcgbar\")\n            return\n\n        print(\"\\nProtokoll-Vergleich:\")\n        print(\"-\" * 50)\n\n        for protocol, times in self.results.items():\n            avg_time = sum(times) / len(times)\n            throughput = len(times) / sum(times)\n\n            print(f\"{protocol:12} | Avg: {avg_time:.3f}s | Throughput: {throughput:.1f} req/s\")\n\n# Benchmark ausf\u00fchren\nbenchmark = ProtocolBenchmark()\n\n# HTTP-Benchmark\nhttp_client = HTTPClient(HTTPConfig(base_url=\"http://localhost:8000\"))\nawait benchmark.benchmark_protocol(\n    \"http\", http_client, \"echo\", {\"message\": \"test\"}, 100\n)\n\n# WebSocket-Benchmark\nws_client = WebSocketClient(WebSocketConfig(url=\"ws://localhost:8000/ws\"))\nawait ws_client.connect()\nawait benchmark.benchmark_protocol(\n    \"websocket\", ws_client, \"echo\", {\"message\": \"test\"}, 100\n)\n\n# Vergleich anzeigen\nawait benchmark.compare_protocols()\n</code></pre>"},{"location":"examples/multi-protocol/#protocol-konfiguration","title":"\ud83d\udd27 Protocol-Konfiguration","text":""},{"location":"examples/multi-protocol/#umgebungs-spezifische-protokolle","title":"Umgebungs-spezifische Protokolle","text":"<pre><code># config/protocols.py\nPROTOCOL_CONFIGS = {\n    \"development\": {\n        \"preferred_protocols\": [\"http\", \"websocket\"],\n        \"http\": {\n            \"base_url\": \"http://localhost:8000\",\n            \"timeout\": 30.0,\n            \"verify_ssl\": False\n        },\n        \"websocket\": {\n            \"url\": \"ws://localhost:8000/ws\",\n            \"ping_interval\": 30.0\n        }\n    },\n    \"production\": {\n        \"preferred_protocols\": [\"grpc\", \"https\", \"websocket\"],\n        \"https\": {\n            \"base_url\": \"https://api.keiko.com\",\n            \"timeout\": 10.0,\n            \"verify_ssl\": True,\n            \"cert_file\": \"/etc/ssl/client.pem\"\n        },\n        \"grpc\": {\n            \"server_address\": \"grpc.keiko.com:443\",\n            \"use_tls\": True\n        },\n        \"websocket\": {\n            \"url\": \"wss://api.keiko.com/ws\",\n            \"ping_interval\": 60.0\n        }\n    }\n}\n\ndef get_protocol_config(environment: str = \"development\") -&gt; dict:\n    \"\"\"L\u00e4dt Protocol-Konfiguration f\u00fcr Umgebung.\"\"\"\n    return PROTOCOL_CONFIGS.get(environment, PROTOCOL_CONFIGS[\"development\"])\n\n# Verwendung\nimport os\nenv = os.getenv(\"ENVIRONMENT\", \"development\")\nconfig = get_protocol_config(env)\n\n# Client-Factory mit Umgebungs-Konfiguration\nclass ProtocolClientFactory:\n    \"\"\"Factory f\u00fcr umgebungs-spezifische Protocol-Clients.\"\"\"\n\n    @staticmethod\n    def create_clients(config: dict) -&gt; Dict[str, Any]:\n        \"\"\"Erstellt Clients basierend auf Konfiguration.\"\"\"\n        clients = {}\n\n        for protocol in config[\"preferred_protocols\"]:\n            if protocol in config:\n                if protocol == \"http\" or protocol == \"https\":\n                    clients[protocol] = HTTPClient(HTTPConfig(**config[protocol]))\n                elif protocol == \"websocket\":\n                    clients[protocol] = WebSocketClient(WebSocketConfig(**config[protocol]))\n                elif protocol == \"grpc\":\n                    clients[protocol] = GRPCClient(GRPCConfig(**config[protocol]))\n\n        return clients\n\n# Clients erstellen\nclients = ProtocolClientFactory.create_clients(config)\n</code></pre>"},{"location":"examples/multi-protocol/#advanced-protocol-usage","title":"\ud83d\ude80 Advanced Protocol Usage","text":""},{"location":"examples/multi-protocol/#protocol-multiplexing","title":"Protocol-Multiplexing","text":"<pre><code>class MultiplexedClient:\n    \"\"\"Client der mehrere Protokolle gleichzeitig nutzt.\"\"\"\n\n    def __init__(self, clients: Dict[str, Any]):\n        self.clients = clients\n        self.load_balancer = RoundRobinBalancer(list(clients.keys()))\n\n    async def parallel_request(self, operation: str, data: dict) -&gt; List[dict]:\n        \"\"\"Sendet Request parallel \u00fcber alle Protokolle.\"\"\"\n\n        tasks = []\n        for protocol, client in self.clients.items():\n            task = asyncio.create_task(\n                self._send_request(protocol, client, operation, data)\n            )\n            tasks.append(task)\n\n        # Warten auf alle Responses\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Erfolgreiche Responses filtern\n        successful_results = [\n            result for result in results\n            if not isinstance(result, Exception)\n        ]\n\n        return successful_results\n\n    async def fastest_response(self, operation: str, data: dict) -&gt; dict:\n        \"\"\"Nutzt das schnellste verf\u00fcgbare Protokoll.\"\"\"\n\n        tasks = []\n        for protocol, client in self.clients.items():\n            task = asyncio.create_task(\n                self._send_request(protocol, client, operation, data)\n            )\n            tasks.append(task)\n\n        # Erstes erfolgreiches Ergebnis zur\u00fcckgeben\n        done, pending = await asyncio.wait(\n            tasks,\n            return_when=asyncio.FIRST_COMPLETED\n        )\n\n        # Verbleibende Tasks abbrechen\n        for task in pending:\n            task.cancel()\n\n        # Erstes Ergebnis zur\u00fcckgeben\n        result = done.pop().result()\n        return result\n\n    async def _send_request(self, protocol: str, client, operation: str, data: dict) -&gt; dict:\n        \"\"\"Sendet Request \u00fcber spezifisches Protokoll.\"\"\"\n\n        if protocol == \"http\":\n            response = await client.post(f\"/api/{operation}\", data=data)\n            return response.json\n        elif protocol == \"websocket\":\n            await client.send_message(operation, data)\n            return {\"protocol\": protocol, \"status\": \"sent\"}\n        # Weitere Protokolle...\n\n# Verwendung\nmultiplexed = MultiplexedClient(clients)\n\n# Parallele Requests\nall_results = await multiplexed.parallel_request(\"get_status\", {})\nprint(f\"Ergebnisse von {len(all_results)} Protokollen\")\n\n# Schnellste Response\nfastest = await multiplexed.fastest_response(\"get_data\", {\"id\": 123})\nprint(f\"Schnellste Antwort: {fastest}\")\n</code></pre> <p>Protocol-Auswahl</p> <p>W\u00e4hlen Sie das Protokoll basierend auf Ihren spezifischen Anforderungen: - HTTP: Einfache Request/Response-Patterns - WebSocket: Real-Time-Kommunikation - gRPC: High-Performance mit starker Typisierung - MCP: Model Context Protocol-spezifische Operationen</p> <p>Performance-Optimierung</p> <p>Nutzen Sie Connection-Pooling, Keep-Alive und Compression f\u00fcr bessere Performance bei allen Protokollen.</p>"},{"location":"examples/performance-tuning/","title":"\u26a1 Performance Tuning Examples","text":"<p>Beispiele f\u00fcr Performance-Optimierung und Tuning von Keiko Personal Assistant.</p>"},{"location":"examples/performance-tuning/#database-performance","title":"\ud83d\ude80 Database Performance","text":""},{"location":"examples/performance-tuning/#connection-pooling-optimization","title":"Connection Pooling Optimization","text":"<pre><code># config/database.py\nfrom sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker\nfrom sqlalchemy.pool import QueuePool\n\n# Optimierte Database-Konfiguration\nDATABASE_CONFIG = {\n    \"pool_size\": 20,           # Basis-Pool-Gr\u00f6\u00dfe\n    \"max_overflow\": 30,        # Zus\u00e4tzliche Verbindungen bei Bedarf\n    \"pool_timeout\": 30,        # Timeout f\u00fcr Pool-Verbindung\n    \"pool_recycle\": 3600,      # Verbindungen nach 1h recyceln\n    \"pool_pre_ping\": True,     # Verbindungen vor Nutzung testen\n    \"echo\": False,             # SQL-Logging deaktivieren in Produktion\n    \"future\": True\n}\n\n# Engine mit optimierten Einstellungen\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:password@localhost/keiko\",\n    poolclass=QueuePool,\n    **DATABASE_CONFIG\n)\n\n# Session-Factory\nasync_session = async_sessionmaker(\n    engine,\n    expire_on_commit=False,\n    autoflush=False  # Manuelles Flushing f\u00fcr bessere Kontrolle\n)\n\n# Optimierte Repository-Implementierung\nclass OptimizedAgentRepository:\n    \"\"\"Performance-optimiertes Agent-Repository.\"\"\"\n\n    def __init__(self, session_factory):\n        self.session_factory = session_factory\n\n    async def get_agents_batch(self, agent_ids: List[str]) -&gt; List[Agent]:\n        \"\"\"L\u00e4dt mehrere Agenten in einem Query.\"\"\"\n\n        async with self.session_factory() as session:\n            # Batch-Loading mit IN-Clause\n            query = select(AgentModel).where(AgentModel.id.in_(agent_ids))\n            result = await session.execute(query)\n            agent_models = result.scalars().all()\n\n            return [Agent.from_model(model) for model in agent_models]\n\n    async def get_agents_with_stats(self, limit: int = 100) -&gt; List[Dict[str, Any]]:\n        \"\"\"L\u00e4dt Agenten mit Statistiken in einem Query.\"\"\"\n\n        async with self.session_factory() as session:\n            # JOIN-Query f\u00fcr bessere Performance\n            query = (\n                select(\n                    AgentModel.id,\n                    AgentModel.name,\n                    AgentModel.type,\n                    func.count(TaskModel.id).label('task_count'),\n                    func.avg(TaskModel.duration).label('avg_duration')\n                )\n                .outerjoin(TaskModel, AgentModel.id == TaskModel.agent_id)\n                .group_by(AgentModel.id, AgentModel.name, AgentModel.type)\n                .limit(limit)\n            )\n\n            result = await session.execute(query)\n            return [dict(row) for row in result]\n\n    async def bulk_update_status(self, updates: List[Dict[str, Any]]) -&gt; None:\n        \"\"\"Bulk-Update f\u00fcr bessere Performance.\"\"\"\n\n        async with self.session_factory() as session:\n            # Bulk-Update mit bulk_update_mappings\n            await session.execute(\n                update(AgentModel),\n                updates\n            )\n            await session.commit()\n</code></pre>"},{"location":"examples/performance-tuning/#query-optimization","title":"Query Optimization","text":"<pre><code># Optimierte Queries mit Eager Loading\nclass OptimizedTaskService:\n    \"\"\"Performance-optimierter Task-Service.\"\"\"\n\n    async def get_tasks_with_relations(self, user_id: str) -&gt; List[Dict[str, Any]]:\n        \"\"\"L\u00e4dt Tasks mit allen Relationen in einem Query.\"\"\"\n\n        async with self.session_factory() as session:\n            # Eager Loading mit joinedload\n            query = (\n                select(TaskModel)\n                .options(\n                    joinedload(TaskModel.agent),\n                    joinedload(TaskModel.user),\n                    joinedload(TaskModel.results)\n                )\n                .where(TaskModel.user_id == user_id)\n                .order_by(TaskModel.created_at.desc())\n            )\n\n            result = await session.execute(query)\n            tasks = result.unique().scalars().all()\n\n            return [self._task_to_dict(task) for task in tasks]\n\n    async def get_task_statistics(self, date_range: Tuple[datetime, datetime]) -&gt; Dict[str, Any]:\n        \"\"\"Berechnet Task-Statistiken mit optimierten Aggregationen.\"\"\"\n\n        async with self.session_factory() as session:\n            # Aggregation-Query\n            query = (\n                select(\n                    TaskModel.status,\n                    TaskModel.type,\n                    func.count().label('count'),\n                    func.avg(TaskModel.duration).label('avg_duration'),\n                    func.min(TaskModel.duration).label('min_duration'),\n                    func.max(TaskModel.duration).label('max_duration')\n                )\n                .where(\n                    TaskModel.created_at.between(date_range[0], date_range[1])\n                )\n                .group_by(TaskModel.status, TaskModel.type)\n            )\n\n            result = await session.execute(query)\n\n            statistics = {}\n            for row in result:\n                key = f\"{row.status}_{row.type}\"\n                statistics[key] = {\n                    'count': row.count,\n                    'avg_duration': float(row.avg_duration or 0),\n                    'min_duration': float(row.min_duration or 0),\n                    'max_duration': float(row.max_duration or 0)\n                }\n\n            return statistics\n\n# Database-Indizes f\u00fcr bessere Performance\n\"\"\"\n-- Wichtige Indizes f\u00fcr Performance\nCREATE INDEX CONCURRENTLY idx_tasks_user_created\nON tasks(user_id, created_at DESC);\n\nCREATE INDEX CONCURRENTLY idx_tasks_status_type\nON tasks(status, type);\n\nCREATE INDEX CONCURRENTLY idx_tasks_agent_status\nON tasks(agent_id, status)\nWHERE status IN ('running', 'pending');\n\nCREATE INDEX CONCURRENTLY idx_agents_type_status\nON agents(type, status);\n\n-- Partial Index f\u00fcr aktive Tasks\nCREATE INDEX CONCURRENTLY idx_tasks_active\nON tasks(created_at DESC)\nWHERE status IN ('running', 'pending');\n\"\"\"\n</code></pre>"},{"location":"examples/performance-tuning/#async-performance","title":"\ud83d\udd04 Async Performance","text":""},{"location":"examples/performance-tuning/#optimized-async-processing","title":"Optimized Async Processing","text":"<pre><code>import asyncio\nfrom asyncio import Semaphore, Queue\nfrom typing import List, Callable, Any\n\nclass AsyncTaskProcessor:\n    \"\"\"Hochperformanter asynchroner Task-Processor.\"\"\"\n\n    def __init__(self, max_concurrent: int = 100, queue_size: int = 1000):\n        self.max_concurrent = max_concurrent\n        self.semaphore = Semaphore(max_concurrent)\n        self.task_queue = Queue(maxsize=queue_size)\n        self.workers = []\n        self.running = False\n\n    async def start(self, num_workers: int = 10):\n        \"\"\"Startet Worker-Pool.\"\"\"\n        self.running = True\n\n        for i in range(num_workers):\n            worker = asyncio.create_task(self._worker(f\"worker-{i}\"))\n            self.workers.append(worker)\n\n    async def stop(self):\n        \"\"\"Stoppt Worker-Pool.\"\"\"\n        self.running = False\n\n        # Alle Worker beenden\n        for worker in self.workers:\n            worker.cancel()\n\n        await asyncio.gather(*self.workers, return_exceptions=True)\n\n    async def submit_task(self, coro: Callable, *args, **kwargs) -&gt; asyncio.Future:\n        \"\"\"F\u00fcgt Task zur Queue hinzu.\"\"\"\n        future = asyncio.Future()\n\n        await self.task_queue.put({\n            'coro': coro,\n            'args': args,\n            'kwargs': kwargs,\n            'future': future\n        })\n\n        return future\n\n    async def _worker(self, worker_id: str):\n        \"\"\"Worker-Loop.\"\"\"\n        while self.running:\n            try:\n                # Task aus Queue holen\n                task_item = await asyncio.wait_for(\n                    self.task_queue.get(),\n                    timeout=1.0\n                )\n\n                # Task mit Semaphore ausf\u00fchren\n                async with self.semaphore:\n                    try:\n                        result = await task_item['coro'](\n                            *task_item['args'],\n                            **task_item['kwargs']\n                        )\n                        task_item['future'].set_result(result)\n                    except Exception as e:\n                        task_item['future'].set_exception(e)\n\n                self.task_queue.task_done()\n\n            except asyncio.TimeoutError:\n                continue\n            except Exception as e:\n                print(f\"Worker {worker_id} error: {e}\")\n\n# Batch-Processing f\u00fcr bessere Performance\nclass BatchProcessor:\n    \"\"\"Batch-Processor f\u00fcr effiziente Verarbeitung.\"\"\"\n\n    def __init__(self, batch_size: int = 100, flush_interval: float = 5.0):\n        self.batch_size = batch_size\n        self.flush_interval = flush_interval\n        self.batch = []\n        self.last_flush = time.time()\n        self.processors = {}\n\n    async def add_item(self, processor_name: str, item: Any):\n        \"\"\"F\u00fcgt Item zum Batch hinzu.\"\"\"\n        if processor_name not in self.batch:\n            self.batch[processor_name] = []\n\n        self.batch[processor_name].append(item)\n\n        # Batch verarbeiten wenn voll oder Timeout erreicht\n        if (len(self.batch[processor_name]) &gt;= self.batch_size or\n            time.time() - self.last_flush &gt; self.flush_interval):\n            await self._flush_batch(processor_name)\n\n    async def _flush_batch(self, processor_name: str):\n        \"\"\"Verarbeitet Batch.\"\"\"\n        if processor_name not in self.batch or not self.batch[processor_name]:\n            return\n\n        items = self.batch[processor_name]\n        self.batch[processor_name] = []\n        self.last_flush = time.time()\n\n        # Batch-Processor ausf\u00fchren\n        if processor_name in self.processors:\n            await self.processors[processor_name](items)\n\n    def register_processor(self, name: str, processor: Callable):\n        \"\"\"Registriert Batch-Processor.\"\"\"\n        self.processors[name] = processor\n\n# Verwendung f\u00fcr Agent-Task-Verarbeitung\nclass HighPerformanceAgentService:\n    \"\"\"High-Performance Agent-Service.\"\"\"\n\n    def __init__(self):\n        self.task_processor = AsyncTaskProcessor(max_concurrent=50)\n        self.batch_processor = BatchProcessor(batch_size=50)\n\n        # Batch-Processors registrieren\n        self.batch_processor.register_processor(\n            \"task_results\",\n            self._process_task_results_batch\n        )\n        self.batch_processor.register_processor(\n            \"metrics\",\n            self._process_metrics_batch\n        )\n\n    async def execute_tasks_parallel(self, tasks: List[Task]) -&gt; List[TaskResult]:\n        \"\"\"F\u00fchrt Tasks parallel aus.\"\"\"\n\n        # Tasks in Gruppen aufteilen\n        task_groups = [tasks[i:i+10] for i in range(0, len(tasks), 10)]\n\n        # Gruppen parallel verarbeiten\n        results = []\n        for group in task_groups:\n            group_results = await asyncio.gather(*[\n                self.task_processor.submit_task(self._execute_single_task, task)\n                for task in group\n            ])\n            results.extend(group_results)\n\n        return results\n\n    async def _execute_single_task(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt einzelne Task aus.\"\"\"\n        start_time = time.time()\n\n        try:\n            # Task-Ausf\u00fchrung\n            result = await self._perform_task_execution(task)\n\n            # Ergebnis zum Batch hinzuf\u00fcgen\n            await self.batch_processor.add_item(\"task_results\", {\n                'task_id': task.id,\n                'result': result,\n                'duration': time.time() - start_time\n            })\n\n            return result\n\n        except Exception as e:\n            # Fehler-Metrik zum Batch hinzuf\u00fcgen\n            await self.batch_processor.add_item(\"metrics\", {\n                'type': 'task_error',\n                'task_id': task.id,\n                'error': str(e)\n            })\n            raise\n\n    async def _process_task_results_batch(self, results: List[Dict[str, Any]]):\n        \"\"\"Verarbeitet Task-Ergebnisse im Batch.\"\"\"\n\n        # Bulk-Insert in Database\n        async with self.session_factory() as session:\n            result_models = [\n                TaskResultModel(\n                    task_id=item['task_id'],\n                    result_data=item['result'],\n                    duration=item['duration']\n                )\n                for item in results\n            ]\n\n            session.add_all(result_models)\n            await session.commit()\n\n    async def _process_metrics_batch(self, metrics: List[Dict[str, Any]]):\n        \"\"\"Verarbeitet Metriken im Batch.\"\"\"\n\n        for metric in metrics:\n            if metric['type'] == 'task_error':\n                TASK_ERRORS_COUNTER.labels(\n                    task_id=metric['task_id']\n                ).inc()\n</code></pre>"},{"location":"examples/performance-tuning/#caching-strategies","title":"\ud83d\uddc4\ufe0f Caching Strategies","text":""},{"location":"examples/performance-tuning/#multi-level-caching","title":"Multi-Level Caching","text":"<pre><code>from typing import Optional, Any, Union\nimport pickle\nimport json\nimport hashlib\n\nclass MultiLevelCache:\n    \"\"\"Multi-Level-Cache mit Memory, Redis und Database.\"\"\"\n\n    def __init__(self, redis_client, db_session_factory):\n        self.memory_cache = {}  # L1 Cache\n        self.redis_client = redis_client  # L2 Cache\n        self.db_session_factory = db_session_factory  # L3 Cache\n\n        # Cache-Konfiguration\n        self.memory_ttl = 300  # 5 Minuten\n        self.redis_ttl = 3600  # 1 Stunde\n        self.db_ttl = 86400    # 24 Stunden\n\n        self.memory_max_size = 1000\n\n    async def get(self, key: str) -&gt; Optional[Any]:\n        \"\"\"Ruft Wert aus Cache ab (L1 -&gt; L2 -&gt; L3).\"\"\"\n\n        # L1: Memory Cache\n        if key in self.memory_cache:\n            item = self.memory_cache[key]\n            if time.time() &lt; item['expires_at']:\n                return item['value']\n            else:\n                del self.memory_cache[key]\n\n        # L2: Redis Cache\n        redis_value = await self.redis_client.get(f\"cache:{key}\")\n        if redis_value:\n            try:\n                value = pickle.loads(redis_value)\n                # Zur\u00fcck in L1 Cache\n                await self._set_memory_cache(key, value)\n                return value\n            except Exception:\n                pass\n\n        # L3: Database Cache\n        db_value = await self._get_from_db_cache(key)\n        if db_value:\n            # Zur\u00fcck in L2 und L1 Cache\n            await self._set_redis_cache(key, db_value)\n            await self._set_memory_cache(key, db_value)\n            return db_value\n\n        return None\n\n    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -&gt; None:\n        \"\"\"Setzt Wert in allen Cache-Leveln.\"\"\"\n\n        # L1: Memory Cache\n        await self._set_memory_cache(key, value, ttl)\n\n        # L2: Redis Cache\n        await self._set_redis_cache(key, value, ttl)\n\n        # L3: Database Cache\n        await self._set_db_cache(key, value, ttl)\n\n    async def _set_memory_cache(self, key: str, value: Any, ttl: Optional[int] = None):\n        \"\"\"Setzt Wert in Memory Cache.\"\"\"\n\n        # Memory-Cache-Gr\u00f6\u00dfe begrenzen\n        if len(self.memory_cache) &gt;= self.memory_max_size:\n            # LRU-Eviction (vereinfacht)\n            oldest_key = min(\n                self.memory_cache.keys(),\n                key=lambda k: self.memory_cache[k]['created_at']\n            )\n            del self.memory_cache[oldest_key]\n\n        expires_at = time.time() + (ttl or self.memory_ttl)\n        self.memory_cache[key] = {\n            'value': value,\n            'created_at': time.time(),\n            'expires_at': expires_at\n        }\n\n    async def _set_redis_cache(self, key: str, value: Any, ttl: Optional[int] = None):\n        \"\"\"Setzt Wert in Redis Cache.\"\"\"\n\n        try:\n            serialized_value = pickle.dumps(value)\n            await self.redis_client.setex(\n                f\"cache:{key}\",\n                ttl or self.redis_ttl,\n                serialized_value\n            )\n        except Exception as e:\n            print(f\"Redis cache error: {e}\")\n\n    async def _set_db_cache(self, key: str, value: Any, ttl: Optional[int] = None):\n        \"\"\"Setzt Wert in Database Cache.\"\"\"\n\n        async with self.db_session_factory() as session:\n            try:\n                # Bestehenden Cache-Eintrag aktualisieren oder erstellen\n                cache_entry = CacheEntryModel(\n                    key=key,\n                    value=json.dumps(value, default=str),\n                    expires_at=datetime.utcnow() + timedelta(seconds=ttl or self.db_ttl)\n                )\n\n                await session.merge(cache_entry)\n                await session.commit()\n\n            except Exception as e:\n                print(f\"Database cache error: {e}\")\n                await session.rollback()\n\n# Smart Caching Decorator\ndef smart_cache(\n    ttl: int = 3600,\n    key_prefix: str = \"\",\n    cache_null: bool = False,\n    serialize_args: bool = True\n):\n    \"\"\"Smart Caching Decorator mit automatischer Key-Generierung.\"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            # Cache-Key generieren\n            if serialize_args:\n                key_data = {\n                    'func': f\"{func.__module__}.{func.__name__}\",\n                    'args': args,\n                    'kwargs': kwargs\n                }\n                key_hash = hashlib.md5(\n                    json.dumps(key_data, sort_keys=True, default=str).encode()\n                ).hexdigest()\n            else:\n                key_hash = f\"{func.__name__}_{hash((args, tuple(kwargs.items())))}\"\n\n            cache_key = f\"{key_prefix}{key_hash}\"\n\n            # Cache pr\u00fcfen\n            cached_value = await cache.get(cache_key)\n            if cached_value is not None:\n                return cached_value\n\n            # Funktion ausf\u00fchren\n            result = await func(*args, **kwargs)\n\n            # Ergebnis cachen (wenn nicht None oder cache_null=True)\n            if result is not None or cache_null:\n                await cache.set(cache_key, result, ttl)\n\n            return result\n\n        return wrapper\n    return decorator\n\n# Verwendung\n@smart_cache(ttl=1800, key_prefix=\"agent_stats:\")\nasync def get_agent_statistics(agent_id: str, date_range: Tuple[datetime, datetime]) -&gt; Dict[str, Any]:\n    \"\"\"Ruft Agent-Statistiken ab (gecacht).\"\"\"\n\n    # Teure Database-Query\n    async with session_factory() as session:\n        query = (\n            select(\n                func.count(TaskModel.id).label('total_tasks'),\n                func.avg(TaskModel.duration).label('avg_duration'),\n                func.sum(case((TaskModel.status == 'completed', 1), else_=0)).label('completed_tasks')\n            )\n            .where(\n                TaskModel.agent_id == agent_id,\n                TaskModel.created_at.between(date_range[0], date_range[1])\n            )\n        )\n\n        result = await session.execute(query)\n        row = result.first()\n\n        return {\n            'total_tasks': row.total_tasks or 0,\n            'avg_duration': float(row.avg_duration or 0),\n            'completed_tasks': row.completed_tasks or 0,\n            'success_rate': (row.completed_tasks or 0) / max(row.total_tasks or 1, 1)\n        }\n</code></pre>"},{"location":"examples/performance-tuning/#memory-optimization","title":"\ud83d\udd27 Memory Optimization","text":""},{"location":"examples/performance-tuning/#memory-efficient-data-processing","title":"Memory-Efficient Data Processing","text":"<pre><code>import gc\nfrom typing import Iterator, Generator\nimport psutil\nimport os\n\nclass MemoryOptimizedProcessor:\n    \"\"\"Memory-optimierter Daten-Processor.\"\"\"\n\n    def __init__(self, memory_limit_mb: int = 1024):\n        self.memory_limit_bytes = memory_limit_mb * 1024 * 1024\n        self.process = psutil.Process(os.getpid())\n\n    def get_memory_usage(self) -&gt; int:\n        \"\"\"Ruft aktuellen Speicherverbrauch ab.\"\"\"\n        return self.process.memory_info().rss\n\n    def check_memory_limit(self) -&gt; bool:\n        \"\"\"Pr\u00fcft ob Speicherlimit erreicht ist.\"\"\"\n        return self.get_memory_usage() &gt; self.memory_limit_bytes\n\n    async def process_large_dataset(self, data_source: str, chunk_size: int = 1000) -&gt; Iterator[Dict[str, Any]]:\n        \"\"\"Verarbeitet gro\u00dfe Datasets in Chunks.\"\"\"\n\n        async for chunk in self._read_data_chunks(data_source, chunk_size):\n            # Memory-Check vor Verarbeitung\n            if self.check_memory_limit():\n                gc.collect()  # Garbage Collection erzwingen\n\n                if self.check_memory_limit():\n                    raise MemoryError(\"Memory limit exceeded\")\n\n            # Chunk verarbeiten\n            processed_chunk = await self._process_chunk(chunk)\n\n            yield processed_chunk\n\n            # Chunk aus Memory entfernen\n            del chunk\n            del processed_chunk\n\n    async def _read_data_chunks(self, data_source: str, chunk_size: int) -&gt; Generator[List[Dict[str, Any]], None, None]:\n        \"\"\"Liest Daten in Chunks.\"\"\"\n\n        if data_source.endswith('.csv'):\n            import pandas as pd\n\n            # Pandas Chunking f\u00fcr CSV\n            for chunk_df in pd.read_csv(data_source, chunksize=chunk_size):\n                yield chunk_df.to_dict('records')\n\n        elif data_source.endswith('.json'):\n            import ijson\n\n            # Streaming JSON Parser\n            with open(data_source, 'rb') as file:\n                parser = ijson.items(file, 'item')\n\n                chunk = []\n                for item in parser:\n                    chunk.append(item)\n\n                    if len(chunk) &gt;= chunk_size:\n                        yield chunk\n                        chunk = []\n\n                if chunk:\n                    yield chunk\n\n    async def _process_chunk(self, chunk: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Verarbeitet einzelnen Chunk.\"\"\"\n\n        # Memory-effiziente Verarbeitung\n        result = {\n            'processed_count': len(chunk),\n            'memory_usage_mb': self.get_memory_usage() / 1024 / 1024\n        }\n\n        # Chunk-spezifische Verarbeitung\n        for item in chunk:\n            # Verarbeitung ohne gro\u00dfe Zwischenspeicherung\n            pass\n\n        return result\n\n# Memory-Pool f\u00fcr Object-Reuse\nclass ObjectPool:\n    \"\"\"Object-Pool f\u00fcr Memory-Optimierung.\"\"\"\n\n    def __init__(self, factory_func: Callable, max_size: int = 100):\n        self.factory_func = factory_func\n        self.max_size = max_size\n        self.pool = []\n        self.in_use = set()\n\n    def acquire(self):\n        \"\"\"Holt Objekt aus Pool.\"\"\"\n        if self.pool:\n            obj = self.pool.pop()\n        else:\n            obj = self.factory_func()\n\n        self.in_use.add(id(obj))\n        return obj\n\n    def release(self, obj):\n        \"\"\"Gibt Objekt an Pool zur\u00fcck.\"\"\"\n        obj_id = id(obj)\n\n        if obj_id in self.in_use:\n            self.in_use.remove(obj_id)\n\n            # Objekt zur\u00fccksetzen\n            if hasattr(obj, 'reset'):\n                obj.reset()\n\n            # Pool-Gr\u00f6\u00dfe begrenzen\n            if len(self.pool) &lt; self.max_size:\n                self.pool.append(obj)\n\n# Task-Result-Pool f\u00fcr bessere Memory-Nutzung\ntask_result_pool = ObjectPool(\n    factory_func=lambda: TaskResult(success=False, data=None),\n    max_size=50\n)\n\nclass MemoryOptimizedTaskExecutor:\n    \"\"\"Memory-optimierter Task-Executor.\"\"\"\n\n    async def execute_task(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task memory-optimiert aus.\"\"\"\n\n        # TaskResult aus Pool holen\n        result = task_result_pool.acquire()\n\n        try:\n            # Task ausf\u00fchren\n            execution_result = await self._perform_task_execution(task)\n\n            # Result konfigurieren\n            result.success = True\n            result.data = execution_result\n            result.execution_time = time.time() - task.start_time\n\n            # Kopie f\u00fcr R\u00fcckgabe erstellen\n            result_copy = TaskResult(\n                success=result.success,\n                data=result.data.copy() if isinstance(result.data, dict) else result.data,\n                execution_time=result.execution_time\n            )\n\n            return result_copy\n\n        finally:\n            # Result an Pool zur\u00fcckgeben\n            task_result_pool.release(result)\n</code></pre> <p>Performance-Monitoring</p> <p>\u00dcberwachen Sie kontinuierlich die Performance-Metriken und passen Sie die Optimierungen basierend auf realen Nutzungsmustern an.</p> <p>Memory-Management</p> <p>Bei gro\u00dfen Datasets ist sorgf\u00e4ltiges Memory-Management essentiell. Nutzen Sie Streaming, Chunking und Object-Pooling f\u00fcr optimale Speichernutzung.</p>"},{"location":"getting-started/","title":"Erste Schritte","text":"<p>Willkommen zum KEI-Agent Python SDK! Diese Sektion f\u00fchrt Sie durch die ersten Schritte zur Verwendung des SDK in Ihren Projekten.</p>"},{"location":"getting-started/#voraussetzungen","title":"\ud83d\udccb Voraussetzungen","text":"<p>Bevor Sie beginnen, stellen Sie sicher, dass Ihr System die folgenden Anforderungen erf\u00fcllt:</p>"},{"location":"getting-started/#system-anforderungen","title":"System-Anforderungen","text":"<ul> <li>Python: Version 3.9 oder h\u00f6her</li> <li>Betriebssystem: Windows, macOS, Linux</li> <li>Speicher: Mindestens 512 MB RAM</li> <li>Netzwerk: Internetverbindung f\u00fcr Package-Installation</li> </ul>"},{"location":"getting-started/#python-version-prufen","title":"Python-Version pr\u00fcfen","text":"<pre><code>python --version\n# oder\npython3 --version\n</code></pre> <p>Python-Version</p> <p>Das KEI-Agent SDK nutzt moderne Python-Features und erfordert mindestens Python 3.9. F\u00fcr die beste Performance empfehlen wir Python 3.11 oder h\u00f6her.</p>"},{"location":"getting-started/#schnellstart-ubersicht","title":"\ud83d\ude80 Schnellstart-\u00dcbersicht","text":"<ol> <li>Installation - SDK installieren und einrichten</li> <li>Quick Start - Erste Schritte in 5 Minuten</li> <li>Konfiguration - Client-Setup und Optionen</li> </ol>"},{"location":"getting-started/#was-sie-lernen-werden","title":"\ud83c\udfaf Was Sie lernen werden","text":"<p>Nach Abschluss dieser Sektion k\u00f6nnen Sie:</p> <ul> <li>\u2705 Das KEI-Agent SDK in verschiedenen Umgebungen installieren</li> <li>\u2705 Einen einfachen Agent-Client erstellen und konfigurieren</li> <li>\u2705 Basis-Operationen wie Plan, Act, Observe ausf\u00fchren</li> <li>\u2705 Enterprise-Features wie Logging und Health Checks nutzen</li> <li>\u2705 Verschiedene Protokolle (RPC, Stream, Bus, MCP) verwenden</li> </ul>"},{"location":"getting-started/#lernpfad","title":"\ud83d\udcda Lernpfad","text":""},{"location":"getting-started/#fur-einsteiger","title":"F\u00fcr Einsteiger","text":"<ol> <li>Beginnen Sie mit der Installation</li> <li>Folgen Sie dem Quick Start Guide</li> <li>Erkunden Sie die Basis-Konzepte</li> </ol>"},{"location":"getting-started/#fur-erfahrene-entwickler","title":"F\u00fcr erfahrene Entwickler","text":"<ol> <li>\u00dcberspringen Sie zur Konfiguration</li> <li>Lesen Sie die API-Referenz</li> <li>Erkunden Sie Enterprise Features</li> </ol>"},{"location":"getting-started/#fur-migration-von-legacy-sdk","title":"F\u00fcr Migration von Legacy SDK","text":"<ol> <li>Lesen Sie den Migration Guide</li> <li>\u00dcberpr\u00fcfen Sie Breaking Changes</li> <li>Folgen Sie dem Upgrade Guide</li> </ol>"},{"location":"getting-started/#entwicklungsumgebung","title":"\ud83d\udd27 Entwicklungsumgebung","text":""},{"location":"getting-started/#empfohlene-ides","title":"Empfohlene IDEs","text":"<ul> <li>PyCharm: Vollst\u00e4ndige Type Hints-Unterst\u00fctzung</li> <li>VS Code: Mit Python-Extension</li> <li>Vim/Neovim: Mit LSP-Support</li> </ul>"},{"location":"getting-started/#virtuelle-umgebung","title":"Virtuelle Umgebung","text":"<p>Wir empfehlen die Verwendung einer virtuellen Umgebung:</p> <pre><code># Mit venv\npython -m venv kei-agent-env\nsource kei-agent-env/bin/activate  # Linux/macOS\n# oder\nkei-agent-env\\Scripts\\activate     # Windows\n\n# Mit conda\nconda create -n kei-agent python=3.11\nconda activate kei-agent\n</code></pre>"},{"location":"getting-started/#hilfe-benotigt","title":"\ud83c\udd98 Hilfe ben\u00f6tigt?","text":"<p>Falls Sie Probleme haben:</p> <ol> <li>Dokumentation durchsuchen: Nutzen Sie die Suchfunktion oben</li> <li>Troubleshooting: Besuchen Sie H\u00e4ufige Probleme</li> <li>Community: Stellen Sie Fragen in GitHub Discussions</li> <li>Issues: Melden Sie Bugs in GitHub Issues</li> </ol> <p>Bereit? Beginnen Sie mit der Installation \u2192</p>"},{"location":"getting-started/configuration/","title":"Konfiguration","text":"<p>Lernen Sie, wie Sie das KEI-Agent SDK f\u00fcr verschiedene Umgebungen und Anwendungsf\u00e4lle konfigurieren.</p>"},{"location":"getting-started/configuration/#basis-konfiguration","title":"\ud83d\udd27 Basis-Konfiguration","text":""},{"location":"getting-started/configuration/#agentclientconfig","title":"AgentClientConfig","text":"<p>Die <code>AgentClientConfig</code> ist die Hauptkonfigurationsklasse f\u00fcr den Client:</p> <pre><code>from kei_agent import AgentClientConfig\n\nconfig = AgentClientConfig(\n    base_url=\"https://api.kei-framework.com\",\n    api_token=\"your-api-token\",\n    agent_id=\"my-agent\",\n    timeout=30,\n    max_retries=3,\n    retry_delay=1.0\n)\n</code></pre>"},{"location":"getting-started/configuration/#parameter-referenz","title":"Parameter-Referenz","text":"Parameter Typ Standard Beschreibung <code>base_url</code> <code>str</code> Erforderlich Basis-URL der KEI-API <code>api_token</code> <code>str</code> Erforderlich API-Token f\u00fcr Authentifizierung <code>agent_id</code> <code>str</code> Erforderlich Eindeutige Agent-ID <code>timeout</code> <code>float</code> <code>30.0</code> Request-Timeout in Sekunden <code>max_retries</code> <code>int</code> <code>3</code> Maximale Anzahl Wiederholungen <code>retry_delay</code> <code>float</code> <code>1.0</code> Verz\u00f6gerung zwischen Wiederholungen"},{"location":"getting-started/configuration/#protokoll-konfiguration","title":"\ud83d\udd0c Protokoll-Konfiguration","text":""},{"location":"getting-started/configuration/#protocolconfig","title":"ProtocolConfig","text":"<p>Konfiguriert die verf\u00fcgbaren Protokolle und deren Verhalten:</p> <pre><code>from kei_agent import ProtocolConfig\n\nprotocol_config = ProtocolConfig(\n    # Protokoll-Aktivierung\n    rpc_enabled=True,\n    stream_enabled=True,\n    bus_enabled=True,\n    mcp_enabled=True,\n\n    # Endpunkt-Konfiguration\n    rpc_endpoint=\"/api/v1/rpc\",\n    stream_endpoint=\"/api/v1/stream\",\n    bus_endpoint=\"/api/v1/bus\",\n    mcp_endpoint=\"/api/v1/mcp\",\n\n    # Intelligente Features\n    auto_protocol_selection=True,\n    protocol_fallback_enabled=True\n)\n</code></pre>"},{"location":"getting-started/configuration/#protokoll-spezifische-endpunkte","title":"Protokoll-spezifische Endpunkte","text":"<pre><code># Custom Endpunkte\nprotocol_config = ProtocolConfig(\n    rpc_endpoint=\"/custom/rpc/v2\",\n    stream_endpoint=\"/ws/stream\",\n    bus_endpoint=\"/messaging/bus\",\n    mcp_endpoint=\"/tools/mcp\"\n)\n</code></pre>"},{"location":"getting-started/configuration/#protokoll-auswahl-strategien","title":"Protokoll-Auswahl-Strategien","text":"<pre><code># Nur RPC und Bus\nminimal_config = ProtocolConfig(\n    rpc_enabled=True,\n    stream_enabled=False,\n    bus_enabled=True,\n    mcp_enabled=False,\n    auto_protocol_selection=False\n)\n\n# Vollst\u00e4ndig mit Fallback\nenterprise_config = ProtocolConfig(\n    rpc_enabled=True,\n    stream_enabled=True,\n    bus_enabled=True,\n    mcp_enabled=True,\n    auto_protocol_selection=True,\n    protocol_fallback_enabled=True\n)\n</code></pre>"},{"location":"getting-started/configuration/#sicherheitskonfiguration","title":"\ud83d\udee1\ufe0f Sicherheitskonfiguration","text":""},{"location":"getting-started/configuration/#securityconfig","title":"SecurityConfig","text":"<p>Konfiguriert Authentifizierung und Sicherheits-Features:</p> <pre><code>from kei_agent import SecurityConfig, AuthType\n\n# Bearer Token Authentifizierung\nbearer_config = SecurityConfig(\n    auth_type=AuthType.BEARER,\n    api_token=\"your-bearer-token\",\n    rbac_enabled=True,\n    audit_enabled=True\n)\n\n# OIDC Authentifizierung\noidc_config = SecurityConfig(\n    auth_type=AuthType.OIDC,\n    oidc_issuer=\"https://auth.example.com\",\n    oidc_client_id=\"your-client-id\",\n    oidc_client_secret=\"your-client-secret\",\n    oidc_scope=\"openid profile kei-agent\",\n    token_refresh_enabled=True,\n    token_cache_ttl=3600\n)\n\n# mTLS Authentifizierung\nmtls_config = SecurityConfig(\n    auth_type=AuthType.MTLS,\n    mtls_cert_path=\"/path/to/client.crt\",\n    mtls_key_path=\"/path/to/client.key\",\n    mtls_ca_path=\"/path/to/ca.crt\"\n)\n</code></pre>"},{"location":"getting-started/configuration/#security-features","title":"Security Features","text":"<pre><code># Enterprise Security\nenterprise_security = SecurityConfig(\n    auth_type=AuthType.BEARER,\n    api_token=\"enterprise-token\",\n    rbac_enabled=True,        # Role-Based Access Control\n    audit_enabled=True,       # Audit-Logging\n    token_refresh_enabled=True,  # Automatische Token-Erneuerung\n    token_cache_ttl=1800     # 30 Minuten Cache\n)\n</code></pre>"},{"location":"getting-started/configuration/#umgebungs-spezifische-konfiguration","title":"\ud83c\udf0d Umgebungs-spezifische Konfiguration","text":""},{"location":"getting-started/configuration/#development","title":"Development","text":"<pre><code>from kei_agent import UnifiedKeiAgentClient, AgentClientConfig, ProtocolConfig\n\n# Development-Konfiguration\ndev_config = AgentClientConfig(\n    base_url=\"http://localhost:8000\",\n    api_token=\"dev-token\",\n    agent_id=\"dev-agent\",\n    timeout=10,\n    max_retries=1\n)\n\ndev_protocols = ProtocolConfig(\n    rpc_enabled=True,\n    stream_enabled=False,  # Vereinfacht f\u00fcr Development\n    bus_enabled=False,\n    mcp_enabled=True,\n    auto_protocol_selection=False\n)\n</code></pre>"},{"location":"getting-started/configuration/#staging","title":"Staging","text":"<pre><code># Staging-Konfiguration\nstaging_config = AgentClientConfig(\n    base_url=\"https://staging-api.kei-framework.com\",\n    api_token=\"staging-token\",\n    agent_id=\"staging-agent\",\n    timeout=20,\n    max_retries=2\n)\n\nstaging_protocols = ProtocolConfig(\n    rpc_enabled=True,\n    stream_enabled=True,\n    bus_enabled=True,\n    mcp_enabled=True,\n    auto_protocol_selection=True,\n    protocol_fallback_enabled=False  # Explizite Fehler in Staging\n)\n</code></pre>"},{"location":"getting-started/configuration/#production","title":"Production","text":"<pre><code># Production-Konfiguration\nprod_config = AgentClientConfig(\n    base_url=\"https://api.kei-framework.com\",\n    api_token=\"prod-token\",\n    agent_id=\"prod-agent-001\",\n    timeout=30,\n    max_retries=5,\n    retry_delay=2.0\n)\n\nprod_protocols = ProtocolConfig(\n    rpc_enabled=True,\n    stream_enabled=True,\n    bus_enabled=True,\n    mcp_enabled=True,\n    auto_protocol_selection=True,\n    protocol_fallback_enabled=True  # Maximale Resilience\n)\n\nprod_security = SecurityConfig(\n    auth_type=AuthType.OIDC,\n    oidc_issuer=\"https://auth.company.com\",\n    oidc_client_id=\"prod-client\",\n    oidc_client_secret=\"prod-secret\",\n    rbac_enabled=True,\n    audit_enabled=True,\n    token_refresh_enabled=True\n)\n</code></pre>"},{"location":"getting-started/configuration/#konfiguration-aus-dateien","title":"\ud83d\udcc1 Konfiguration aus Dateien","text":""},{"location":"getting-started/configuration/#yaml-konfiguration","title":"YAML-Konfiguration","text":"<pre><code># config.yaml\nagent:\n  base_url: \"https://api.kei-framework.com\"\n  api_token: \"${KEI_API_TOKEN}\"\n  agent_id: \"yaml-configured-agent\"\n  timeout: 30\n  max_retries: 3\n\nprotocols:\n  rpc_enabled: true\n  stream_enabled: true\n  bus_enabled: true\n  mcp_enabled: true\n  auto_protocol_selection: true\n  protocol_fallback_enabled: true\n\nsecurity:\n  auth_type: \"bearer\"\n  rbac_enabled: true\n  audit_enabled: true\n</code></pre> <pre><code>import yaml\nimport os\nfrom kei_agent import AgentClientConfig, ProtocolConfig, SecurityConfig, AuthType\n\ndef load_config_from_yaml(file_path: str):\n    \"\"\"L\u00e4dt Konfiguration aus YAML-Datei.\"\"\"\n    with open(file_path, 'r') as f:\n        config_data = yaml.safe_load(f)\n\n    # Umgebungsvariablen ersetzen\n    api_token = os.getenv('KEI_API_TOKEN', config_data['agent']['api_token'])\n\n    agent_config = AgentClientConfig(\n        base_url=config_data['agent']['base_url'],\n        api_token=api_token,\n        agent_id=config_data['agent']['agent_id'],\n        timeout=config_data['agent']['timeout'],\n        max_retries=config_data['agent']['max_retries']\n    )\n\n    protocol_config = ProtocolConfig(**config_data['protocols'])\n\n    security_config = SecurityConfig(\n        auth_type=AuthType(config_data['security']['auth_type']),\n        api_token=api_token,\n        rbac_enabled=config_data['security']['rbac_enabled'],\n        audit_enabled=config_data['security']['audit_enabled']\n    )\n\n    return agent_config, protocol_config, security_config\n\n# Verwendung\nagent_config, protocol_config, security_config = load_config_from_yaml('config.yaml')\n</code></pre>"},{"location":"getting-started/configuration/#json-konfiguration","title":"JSON-Konfiguration","text":"<pre><code>{\n  \"agent\": {\n    \"base_url\": \"https://api.kei-framework.com\",\n    \"api_token\": \"${KEI_API_TOKEN}\",\n    \"agent_id\": \"json-configured-agent\",\n    \"timeout\": 30,\n    \"max_retries\": 3\n  },\n  \"protocols\": {\n    \"rpc_enabled\": true,\n    \"stream_enabled\": true,\n    \"bus_enabled\": true,\n    \"mcp_enabled\": true,\n    \"auto_protocol_selection\": true,\n    \"protocol_fallback_enabled\": true\n  },\n  \"security\": {\n    \"auth_type\": \"bearer\",\n    \"rbac_enabled\": true,\n    \"audit_enabled\": true\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#umgebungsvariablen","title":"\ud83d\udd10 Umgebungsvariablen","text":""},{"location":"getting-started/configuration/#standard-umgebungsvariablen","title":"Standard-Umgebungsvariablen","text":"<pre><code># Basis-Konfiguration\nexport KEI_API_URL=\"https://api.kei-framework.com\"\nexport KEI_API_TOKEN=\"your-api-token\"\nexport KEI_AGENT_ID=\"env-configured-agent\"\n\n# Erweiterte Konfiguration\nexport KEI_TIMEOUT=\"30\"\nexport KEI_MAX_RETRIES=\"3\"\nexport KEI_RETRY_DELAY=\"1.0\"\n\n# Protokoll-Konfiguration\nexport KEI_RPC_ENABLED=\"true\"\nexport KEI_STREAM_ENABLED=\"true\"\nexport KEI_BUS_ENABLED=\"true\"\nexport KEI_MCP_ENABLED=\"true\"\n\n# Security\nexport KEI_AUTH_TYPE=\"bearer\"\nexport KEI_RBAC_ENABLED=\"true\"\nexport KEI_AUDIT_ENABLED=\"true\"\n</code></pre>"},{"location":"getting-started/configuration/#konfiguration-aus-umgebungsvariablen","title":"Konfiguration aus Umgebungsvariablen","text":"<pre><code>import os\nfrom kei_agent import AgentClientConfig, ProtocolConfig, SecurityConfig, AuthType\n\ndef config_from_env():\n    \"\"\"Erstellt Konfiguration aus Umgebungsvariablen.\"\"\"\n    agent_config = AgentClientConfig(\n        base_url=os.getenv('KEI_API_URL', 'https://api.kei-framework.com'),\n        api_token=os.getenv('KEI_API_TOKEN'),\n        agent_id=os.getenv('KEI_AGENT_ID', 'default-agent'),\n        timeout=float(os.getenv('KEI_TIMEOUT', '30')),\n        max_retries=int(os.getenv('KEI_MAX_RETRIES', '3')),\n        retry_delay=float(os.getenv('KEI_RETRY_DELAY', '1.0'))\n    )\n\n    protocol_config = ProtocolConfig(\n        rpc_enabled=os.getenv('KEI_RPC_ENABLED', 'true').lower() == 'true',\n        stream_enabled=os.getenv('KEI_STREAM_ENABLED', 'true').lower() == 'true',\n        bus_enabled=os.getenv('KEI_BUS_ENABLED', 'true').lower() == 'true',\n        mcp_enabled=os.getenv('KEI_MCP_ENABLED', 'true').lower() == 'true'\n    )\n\n    security_config = SecurityConfig(\n        auth_type=AuthType(os.getenv('KEI_AUTH_TYPE', 'bearer')),\n        api_token=os.getenv('KEI_API_TOKEN'),\n        rbac_enabled=os.getenv('KEI_RBAC_ENABLED', 'true').lower() == 'true',\n        audit_enabled=os.getenv('KEI_AUDIT_ENABLED', 'true').lower() == 'true'\n    )\n\n    return agent_config, protocol_config, security_config\n\n# Verwendung\nagent_config, protocol_config, security_config = config_from_env()\n</code></pre>"},{"location":"getting-started/configuration/#erweiterte-konfiguration","title":"\ud83d\udd27 Erweiterte Konfiguration","text":""},{"location":"getting-started/configuration/#custom-configuration-factory","title":"Custom Configuration Factory","text":"<pre><code>from typing import Optional\nfrom kei_agent import UnifiedKeiAgentClient, AgentClientConfig, ProtocolConfig, SecurityConfig\n\nclass KEIAgentConfigFactory:\n    \"\"\"Factory f\u00fcr KEI-Agent-Konfigurationen.\"\"\"\n\n    @staticmethod\n    def create_development_client() -&gt; UnifiedKeiAgentClient:\n        \"\"\"Erstellt Development-Client.\"\"\"\n        config = AgentClientConfig(\n            base_url=\"http://localhost:8000\",\n            api_token=\"dev-token\",\n            agent_id=\"dev-agent\",\n            timeout=10\n        )\n        return UnifiedKeiAgentClient(config=config)\n\n    @staticmethod\n    def create_production_client(\n        api_token: str,\n        agent_id: str,\n        base_url: Optional[str] = None\n    ) -&gt; UnifiedKeiAgentClient:\n        \"\"\"Erstellt Production-Client.\"\"\"\n        agent_config = AgentClientConfig(\n            base_url=base_url or \"https://api.kei-framework.com\",\n            api_token=api_token,\n            agent_id=agent_id,\n            timeout=30,\n            max_retries=5\n        )\n\n        protocol_config = ProtocolConfig(\n            auto_protocol_selection=True,\n            protocol_fallback_enabled=True\n        )\n\n        security_config = SecurityConfig(\n            auth_type=AuthType.BEARER,\n            api_token=api_token,\n            rbac_enabled=True,\n            audit_enabled=True\n        )\n\n        return UnifiedKeiAgentClient(\n            config=agent_config,\n            protocol_config=protocol_config,\n            security_config=security_config\n        )\n\n# Verwendung\ndev_client = KEIAgentConfigFactory.create_development_client()\nprod_client = KEIAgentConfigFactory.create_production_client(\n    api_token=\"prod-token\",\n    agent_id=\"prod-agent-001\"\n)\n</code></pre>"},{"location":"getting-started/configuration/#konfiguration-validieren","title":"\ud83d\udea8 Konfiguration validieren","text":"<pre><code>async def validate_configuration():\n    \"\"\"Validiert Client-Konfiguration.\"\"\"\n    try:\n        config = AgentClientConfig(\n            base_url=\"https://api.kei-framework.com\",\n            api_token=\"test-token\",\n            agent_id=\"validation-test\"\n        )\n\n        async with UnifiedKeiAgentClient(config=config) as client:\n            # Basis-Validierung\n            info = client.get_client_info()\n            print(f\"\u2705 Client konfiguriert: {info['agent_id']}\")\n\n            # Protokoll-Validierung\n            protocols = client.get_available_protocols()\n            print(f\"\u2705 Verf\u00fcgbare Protokolle: {protocols}\")\n\n            # Health Check\n            health = await client.health_check()\n            print(f\"\u2705 Health Status: {health.get('status', 'unknown')}\")\n\n    except Exception as e:\n        print(f\"\u274c Konfigurationsfehler: {e}\")\n\n# Ausf\u00fchren\nimport asyncio\nasyncio.run(validate_configuration())\n</code></pre> <p>N\u00e4chster Schritt: Basis-Konzepte \u2192</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Diese Anleitung f\u00fchrt Sie durch die Installation des KEI-Agent Python SDK in verschiedenen Umgebungen.</p>"},{"location":"getting-started/installation/#installation-mit-pip","title":"\ud83d\udce6 Installation mit pip","text":""},{"location":"getting-started/installation/#standard-installation","title":"Standard-Installation","text":"<p>Die einfachste Methode ist die Installation \u00fcber PyPI:</p> <pre><code>pip install kei-agent-sdk\n</code></pre>"},{"location":"getting-started/installation/#mit-enterprise-features","title":"Mit Enterprise-Features","text":"<p>F\u00fcr vollst\u00e4ndige Enterprise-Funktionalit\u00e4t installieren Sie alle optionalen Dependencies:</p> <pre><code>pip install \"kei-agent-sdk[security,dev,docs]\"\n</code></pre>"},{"location":"getting-started/installation/#spezifische-version","title":"Spezifische Version","text":"<pre><code># Neueste stabile Version\npip install \"kei-agent-sdk&gt;=0.0.1\"\n\n# Spezifische Version\npip install \"kei-agent-sdk==0.0.1-beta\"\n\n# Neueste Pre-Release\npip install --pre kei-agent-sdk\n</code></pre>"},{"location":"getting-started/installation/#installation-mit-conda","title":"\ud83d\udc0d Installation mit conda","text":"<pre><code># Aus conda-forge (falls verf\u00fcgbar)\nconda install -c conda-forge kei-agent-sdk\n\n# Oder mit pip in conda-Umgebung\nconda create -n kei-agent python=3.11\nconda activate kei-agent\npip install kei-agent-sdk\n</code></pre>"},{"location":"getting-started/installation/#development-installation","title":"\ud83d\udd27 Development-Installation","text":"<p>F\u00fcr Entwicklung und Beitr\u00e4ge zum SDK:</p>"},{"location":"getting-started/installation/#repository-klonen","title":"Repository klonen","text":"<pre><code>git clone https://github.com/kei-framework/kei-agent.git\ncd kei-agent/sdk/python/kei_agent\n</code></pre>"},{"location":"getting-started/installation/#editable-installation","title":"Editable Installation","text":"<pre><code># Mit allen Development-Dependencies\npip install -e \".[dev,docs,security]\"\n\n# Oder mit Make\nmake dev-setup\n</code></pre>"},{"location":"getting-started/installation/#pre-commit-hooks","title":"Pre-Commit Hooks","text":"<pre><code>pre-commit install\n</code></pre>"},{"location":"getting-started/installation/#docker-installation","title":"\ud83d\udc33 Docker-Installation","text":""},{"location":"getting-started/installation/#dockerfile-beispiel","title":"Dockerfile-Beispiel","text":"<pre><code>FROM python:3.11-slim\n\n# System-Dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Python-Dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# KEI-Agent SDK\nRUN pip install kei-agent-sdk\n\n# Anwendung\nCOPY . /app\nWORKDIR /app\n\nCMD [\"python\", \"main.py\"]\n</code></pre>"},{"location":"getting-started/installation/#docker-compose","title":"Docker Compose","text":"<pre><code>version: '3.8'\nservices:\n  kei-agent:\n    build: .\n    environment:\n      - KEI_API_URL=https://api.kei-framework.com\n      - KEI_API_TOKEN=${KEI_API_TOKEN}\n    volumes:\n      - ./logs:/app/logs\n    restart: unless-stopped\n</code></pre>"},{"location":"getting-started/installation/#installation-verifizieren","title":"\u2705 Installation verifizieren","text":""},{"location":"getting-started/installation/#basis-verifikation","title":"Basis-Verifikation","text":"<pre><code>import kei_agent\nprint(f\"KEI-Agent SDK Version: {kei_agent.__version__}\")\n</code></pre>"},{"location":"getting-started/installation/#vollstandige-verifikation","title":"Vollst\u00e4ndige Verifikation","text":"<pre><code>from kei_agent import (\n    UnifiedKeiAgentClient,\n    AgentClientConfig,\n    ProtocolConfig,\n    SecurityConfig,\n    get_logger,\n    get_health_manager\n)\n\nprint(\"\u2705 Alle Hauptkomponenten erfolgreich importiert\")\n\n# Version und Features anzeigen\nprint(f\"Version: {kei_agent.__version__}\")\nprint(f\"Verf\u00fcgbare Features: {kei_agent.__all__[:5]}...\")\n</code></pre>"},{"location":"getting-started/installation/#test-script","title":"Test-Script","text":"<p>Erstellen Sie eine Datei <code>test_installation.py</code>:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"Test-Script f\u00fcr KEI-Agent SDK Installation.\"\"\"\n\nimport sys\nimport asyncio\nfrom kei_agent import UnifiedKeiAgentClient, AgentClientConfig\n\nasync def test_installation():\n    \"\"\"Testet die SDK-Installation.\"\"\"\n    try:\n        # Basis-Konfiguration\n        config = AgentClientConfig(\n            base_url=\"https://httpbin.org\",  # Test-Endpunkt\n            api_token=\"test-token\",\n            agent_id=\"installation-test\"\n        )\n\n        # Client erstellen (ohne Verbindung)\n        client = UnifiedKeiAgentClient(config=config)\n\n        # Client-Info abrufen\n        info = client.get_client_info()\n        print(f\"\u2705 Client erstellt: {info['agent_id']}\")\n\n        # Verf\u00fcgbare Protokolle\n        protocols = client.get_available_protocols()\n        print(f\"\u2705 Verf\u00fcgbare Protokolle: {len(protocols)}\")\n\n        print(\"\ud83c\udf89 Installation erfolgreich!\")\n        return True\n\n    except Exception as e:\n        print(f\"\u274c Installation-Test fehlgeschlagen: {e}\")\n        return False\n\nif __name__ == \"__main__\":\n    success = asyncio.run(test_installation())\n    sys.exit(0 if success else 1)\n</code></pre> <p>Ausf\u00fchren:</p> <pre><code>python test_installation.py\n</code></pre>"},{"location":"getting-started/installation/#optionale-dependencies","title":"\ud83d\udd27 Optionale Dependencies","text":""},{"location":"getting-started/installation/#security-features","title":"Security-Features","text":"<pre><code>pip install \"kei-agent-sdk[security]\"\n</code></pre> <p>Enth\u00e4lt: - <code>authlib</code> - OIDC-Authentifizierung - <code>cryptography</code> - Kryptographische Funktionen - <code>pyopenssl</code> - SSL/TLS-Unterst\u00fctzung</p>"},{"location":"getting-started/installation/#development-tools","title":"Development-Tools","text":"<pre><code>pip install \"kei-agent-sdk[dev]\"\n</code></pre> <p>Enth\u00e4lt: - <code>pytest</code> - Testing-Framework - <code>ruff</code> - Linting und Formatierung - <code>mypy</code> - Type-Checking - <code>bandit</code> - Security-Linting</p>"},{"location":"getting-started/installation/#dokumentation","title":"Dokumentation","text":"<pre><code>pip install \"kei-agent-sdk[docs]\"\n</code></pre> <p>Enth\u00e4lt: - <code>mkdocs</code> - Dokumentations-Generator - <code>mkdocs-material</code> - Material-Theme - <code>mkdocstrings</code> - API-Dokumentation</p>"},{"location":"getting-started/installation/#haufige-probleme","title":"\ud83d\udea8 H\u00e4ufige Probleme","text":""},{"location":"getting-started/installation/#problem-modulenotfounderror","title":"Problem: ModuleNotFoundError","text":"<pre><code>ModuleNotFoundError: No module named 'kei_agent'\n</code></pre> <p>L\u00f6sung: <pre><code># Virtuelle Umgebung aktivieren\nsource venv/bin/activate  # Linux/macOS\n# oder\nvenv\\Scripts\\activate     # Windows\n\n# SDK neu installieren\npip install --upgrade kei-agent-sdk\n</code></pre></p>"},{"location":"getting-started/installation/#problem-version-konflikte","title":"Problem: Version-Konflikte","text":"<pre><code>ERROR: pip's dependency resolver does not currently consider all the ways...\n</code></pre> <p>L\u00f6sung: <pre><code># Dependency-Resolver verwenden\npip install --use-feature=2020-resolver kei-agent-sdk\n\n# Oder neue pip-Version\npip install --upgrade pip\npip install kei-agent-sdk\n</code></pre></p>"},{"location":"getting-started/installation/#problem-ssl-zertifikat-fehler","title":"Problem: SSL-Zertifikat-Fehler","text":"<pre><code>SSL: CERTIFICATE_VERIFY_FAILED\n</code></pre> <p>L\u00f6sung: <pre><code># Zertifikate aktualisieren (macOS)\n/Applications/Python\\ 3.x/Install\\ Certificates.command\n\n# Oder mit pip\npip install --trusted-host pypi.org --trusted-host pypi.python.org kei-agent-sdk\n</code></pre></p>"},{"location":"getting-started/installation/#problem-permission-fehler","title":"Problem: Permission-Fehler","text":"<pre><code>PermissionError: [Errno 13] Permission denied\n</code></pre> <p>L\u00f6sung: <pre><code># User-Installation\npip install --user kei-agent-sdk\n\n# Oder virtuelle Umgebung verwenden\npython -m venv venv\nsource venv/bin/activate\npip install kei-agent-sdk\n</code></pre></p>"},{"location":"getting-started/installation/#upgrade","title":"\ud83d\udd04 Upgrade","text":""},{"location":"getting-started/installation/#auf-neueste-version","title":"Auf neueste Version","text":"<pre><code>pip install --upgrade kei-agent-sdk\n</code></pre>"},{"location":"getting-started/installation/#upgrade-mit-dependencies","title":"Upgrade mit Dependencies","text":"<pre><code>pip install --upgrade \"kei-agent-sdk[security,dev]\"\n</code></pre>"},{"location":"getting-started/installation/#upgrade-verifikation","title":"Upgrade-Verifikation","text":"<pre><code>import kei_agent\nprint(f\"Neue Version: {kei_agent.__version__}\")\n</code></pre>"},{"location":"getting-started/installation/#deinstallation","title":"\ud83d\uddd1\ufe0f Deinstallation","text":"<pre><code>pip uninstall kei-agent-sdk\n</code></pre> <p>Mit Dependencies:</p> <pre><code># Liste installierter Packages\npip freeze | grep -E \"(kei-agent|httpx|websockets|pydantic)\"\n\n# Manuell entfernen\npip uninstall kei-agent-sdk httpx websockets pydantic\n</code></pre> <p>N\u00e4chster Schritt: Quick Start Guide \u2192</p>"},{"location":"getting-started/quickstart/","title":"Quick Start Guide","text":"<p>Lernen Sie die Grundlagen des KEI-Agent SDK in nur 5 Minuten! Diese Anleitung zeigt Ihnen die wichtigsten Features anhand praktischer Beispiele.</p>"},{"location":"getting-started/quickstart/#ihr-erster-agent-client","title":"\ud83d\ude80 Ihr erster Agent-Client","text":""},{"location":"getting-started/quickstart/#1-basis-setup","title":"1. Basis-Setup","text":"<pre><code>import asyncio\nfrom kei_agent import UnifiedKeiAgentClient, AgentClientConfig\n\nasync def main():\n    # Konfiguration erstellen\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"my-first-agent\"\n    )\n\n    # Client verwenden\n    async with UnifiedKeiAgentClient(config=config) as client:\n        print(\"\ud83c\udf89 Client erfolgreich verbunden!\")\n\n        # Client-Informationen anzeigen\n        info = client.get_client_info()\n        print(f\"Agent ID: {info['agent_id']}\")\n        print(f\"Verf\u00fcgbare Protokolle: {info['available_protocols']}\")\n\n# Ausf\u00fchren\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/quickstart/#2-erste-agent-operationen","title":"2. Erste Agent-Operationen","text":"<pre><code>async def agent_operations():\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"demo-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # \ud83d\udccb Plan erstellen\n        plan = await client.plan_task(\n            objective=\"Erstelle einen Quartalsbericht f\u00fcr Q4 2024\",\n            context={\n                \"format\": \"pdf\",\n                \"sections\": [\"executive_summary\", \"financials\", \"outlook\"],\n                \"deadline\": \"2024-12-31\"\n            }\n        )\n        print(f\"Plan erstellt: {plan['plan_id']}\")\n\n        # \u26a1 Aktion ausf\u00fchren\n        result = await client.execute_action(\n            action=\"generate_report\",\n            parameters={\n                \"template\": \"quarterly_template\",\n                \"data_source\": \"financial_db\",\n                \"output_format\": \"pdf\"\n            }\n        )\n        print(f\"Aktion ausgef\u00fchrt: {result['action_id']}\")\n\n        # \ud83d\udc41\ufe0f Umgebung beobachten\n        observation = await client.observe_environment(\n            observation_type=\"system_metrics\",\n            data={\"interval\": 60, \"metrics\": [\"cpu\", \"memory\", \"disk\"]}\n        )\n        print(f\"Beobachtung: {observation['observation_id']}\")\n\n        # \ud83d\udca1 Reasoning erkl\u00e4ren\n        explanation = await client.explain_reasoning(\n            query=\"Warum wurde diese Vorlage gew\u00e4hlt?\",\n            context={\"action_id\": result['action_id']}\n        )\n        print(f\"Erkl\u00e4rung: {explanation['explanation']}\")\n\nasyncio.run(agent_operations())\n</code></pre>"},{"location":"getting-started/quickstart/#multi-protocol-features","title":"\ud83d\udd0c Multi-Protocol Features","text":""},{"location":"getting-started/quickstart/#automatische-protokoll-auswahl","title":"Automatische Protokoll-Auswahl","text":"<pre><code>async def multi_protocol_demo():\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"multi-protocol-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # \ud83d\udd04 RPC f\u00fcr synchrone Operationen (automatisch gew\u00e4hlt)\n        sync_result = await client.plan_task(\"Synchrone Planung\")\n\n        # \ud83c\udf0a Stream f\u00fcr Real-time (automatisch gew\u00e4hlt f\u00fcr \"stream_\" Prefix)\n        await client.execute_agent_operation(\n            \"stream_data_processing\",\n            {\"data\": \"real-time-feed\"}\n        )\n\n        # \ud83d\udce8 Bus f\u00fcr asynchrone Nachrichten (automatisch gew\u00e4hlt f\u00fcr \"async_\" Prefix)\n        await client.execute_agent_operation(\n            \"async_background_task\",\n            {\"task\": \"data_cleanup\", \"priority\": \"low\"}\n        )\n\n        # \ud83d\udee0\ufe0f MCP f\u00fcr Tool-Integration (automatisch gew\u00e4hlt f\u00fcr \"tool_\" Prefix)\n        tools = await client.discover_available_tools(\"utilities\")\n        print(f\"Verf\u00fcgbare Tools: {len(tools)}\")\n\nasyncio.run(multi_protocol_demo())\n</code></pre>"},{"location":"getting-started/quickstart/#spezifische-protokoll-auswahl","title":"Spezifische Protokoll-Auswahl","text":"<pre><code>from kei_agent import ProtocolType\n\nasync def specific_protocol_demo():\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"protocol-specific-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Explizit RPC verwenden\n        rpc_result = await client.execute_agent_operation(\n            \"custom_operation\",\n            {\"data\": \"test\"},\n            protocol=ProtocolType.RPC\n        )\n\n        # Explizit Stream verwenden\n        stream_result = await client.execute_agent_operation(\n            \"real_time_operation\",\n            {\"stream\": True},\n            protocol=ProtocolType.STREAM\n        )\n\nasyncio.run(specific_protocol_demo())\n</code></pre>"},{"location":"getting-started/quickstart/#enterprise-features","title":"\ud83d\udee1\ufe0f Enterprise Features","text":""},{"location":"getting-started/quickstart/#structured-logging","title":"Structured Logging","text":"<pre><code>from kei_agent import get_logger, LogContext\n\nasync def logging_demo():\n    # Logger konfigurieren\n    logger = get_logger(\"my_agent\")\n\n    # Kontext setzen\n    correlation_id = logger.create_correlation_id()\n    logger.set_context(LogContext(\n        correlation_id=correlation_id,\n        user_id=\"user-123\",\n        agent_id=\"demo-agent\"\n    ))\n\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"logging-demo-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Operation mit Logging\n        operation_id = logger.log_operation_start(\"plan_creation\")\n\n        try:\n            plan = await client.plan_task(\"Demo-Plan mit Logging\")\n            logger.log_operation_end(\"plan_creation\", operation_id, time.time(), success=True)\n            logger.info(\"Plan erfolgreich erstellt\", plan_id=plan.get('plan_id'))\n\n        except Exception as e:\n            logger.log_operation_end(\"plan_creation\", operation_id, time.time(), success=False)\n            logger.error(\"Plan-Erstellung fehlgeschlagen\", error=str(e))\n\nimport time\nasyncio.run(logging_demo())\n</code></pre>"},{"location":"getting-started/quickstart/#health-checks","title":"Health Checks","text":"<pre><code>from kei_agent import get_health_manager, APIHealthCheck, MemoryHealthCheck\n\nasync def health_check_demo():\n    # Health Manager konfigurieren\n    health_manager = get_health_manager()\n\n    # Health Checks registrieren\n    health_manager.register_check(APIHealthCheck(\n        name=\"kei_api\",\n        url=\"https://api.kei-framework.com/health\"\n    ))\n\n    health_manager.register_check(MemoryHealthCheck(\n        name=\"system_memory\",\n        warning_threshold=0.8,\n        critical_threshold=0.95\n    ))\n\n    # Health Checks ausf\u00fchren\n    summary = await health_manager.run_all_checks()\n\n    print(f\"Gesamtstatus: {summary.overall_status}\")\n    print(f\"Gesunde Komponenten: {summary.healthy_count}\")\n    print(f\"Problematische Komponenten: {summary.unhealthy_count}\")\n\n    # Detaillierte Ergebnisse\n    for check in summary.checks:\n        status_emoji = \"\u2705\" if check.status == \"healthy\" else \"\u274c\"\n        print(f\"{status_emoji} {check.name}: {check.message}\")\n\nasyncio.run(health_check_demo())\n</code></pre>"},{"location":"getting-started/quickstart/#input-validation","title":"Input Validation","text":"<pre><code>from kei_agent import get_input_validator\n\ndef validation_demo():\n    validator = get_input_validator()\n\n    # Agent-Operation validieren\n    operation_data = {\n        \"objective\": \"Erstelle einen Bericht\",\n        \"context\": {\n            \"format\": \"pdf\",\n            \"deadline\": \"2024-12-31\"\n        }\n    }\n\n    result = validator.validate_agent_operation(\"plan\", operation_data)\n\n    if result.valid:\n        print(\"\u2705 Input-Validierung erfolgreich\")\n        print(f\"Bereinigte Daten: {result.sanitized_value}\")\n    else:\n        print(\"\u274c Validierungsfehler:\")\n        for error in result.errors:\n            print(f\"  - {error}\")\n\nvalidation_demo()\n</code></pre>"},{"location":"getting-started/quickstart/#erweiterte-konfiguration","title":"\ud83d\udd27 Erweiterte Konfiguration","text":""},{"location":"getting-started/quickstart/#vollstandige-client-konfiguration","title":"Vollst\u00e4ndige Client-Konfiguration","text":"<pre><code>from kei_agent import (\n    UnifiedKeiAgentClient,\n    AgentClientConfig,\n    ProtocolConfig,\n    SecurityConfig,\n    AuthType\n)\n\nasync def advanced_config_demo():\n    # Basis-Konfiguration\n    agent_config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"advanced-agent\",\n        timeout=30,\n        max_retries=3\n    )\n\n    # Protokoll-Konfiguration\n    protocol_config = ProtocolConfig(\n        rpc_enabled=True,\n        stream_enabled=True,\n        bus_enabled=True,\n        mcp_enabled=True,\n        auto_protocol_selection=True,\n        protocol_fallback_enabled=True\n    )\n\n    # Sicherheitskonfiguration\n    security_config = SecurityConfig(\n        auth_type=AuthType.BEARER,\n        api_token=\"your-api-token\",\n        rbac_enabled=True,\n        audit_enabled=True,\n        token_refresh_enabled=True\n    )\n\n    # Client mit vollst\u00e4ndiger Konfiguration\n    async with UnifiedKeiAgentClient(\n        config=agent_config,\n        protocol_config=protocol_config,\n        security_config=security_config\n    ) as client:\n        print(\"\ud83d\ude80 Erweiterte Konfiguration aktiv\")\n\n        # Client-Informationen\n        info = client.get_client_info()\n        print(f\"Features: {info['features']}\")\n        print(f\"Security Context: {info['security_context']}\")\n\nasyncio.run(advanced_config_demo())\n</code></pre>"},{"location":"getting-started/quickstart/#praktische-beispiele","title":"\ud83c\udfaf Praktische Beispiele","text":""},{"location":"getting-started/quickstart/#agent-to-agent-kommunikation","title":"Agent-to-Agent Kommunikation","text":"<pre><code>async def agent_communication_demo():\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"sender-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Nachricht an anderen Agent senden\n        response = await client.send_agent_message(\n            target_agent=\"receiver-agent\",\n            message_type=\"task_request\",\n            payload={\n                \"task\": \"data_analysis\",\n                \"dataset\": \"sales_q4_2024\",\n                \"priority\": \"high\"\n            }\n        )\n        print(f\"Nachricht gesendet: {response['message_id']}\")\n\nasyncio.run(agent_communication_demo())\n</code></pre>"},{"location":"getting-started/quickstart/#tool-integration-mit-mcp","title":"Tool-Integration mit MCP","text":"<pre><code>async def tool_integration_demo():\n    config = AgentClientConfig(\n        base_url=\"https://api.kei-framework.com\",\n        api_token=\"your-api-token\",\n        agent_id=\"tool-agent\"\n    )\n\n    async with UnifiedKeiAgentClient(config=config) as client:\n        # Verf\u00fcgbare Tools entdecken\n        tools = await client.discover_available_tools(\"math\")\n        print(f\"Verf\u00fcgbare Math-Tools: {[tool['name'] for tool in tools]}\")\n\n        # Tool verwenden\n        if tools:\n            result = await client.use_tool(\n                \"calculator\",\n                expression=\"(100 * 1.08) - 50\"\n            )\n            print(f\"Berechnungsergebnis: {result['result']}\")\n\nasyncio.run(tool_integration_demo())\n</code></pre>"},{"location":"getting-started/quickstart/#fehlerbehandlung","title":"\ud83d\udea8 Fehlerbehandlung","text":"<pre><code>from kei_agent.exceptions import KeiSDKError, ProtocolError, SecurityError\n\nasync def error_handling_demo():\n    config = AgentClientConfig(\n        base_url=\"https://invalid-url.example.com\",\n        api_token=\"invalid-token\",\n        agent_id=\"error-demo-agent\"\n    )\n\n    try:\n        async with UnifiedKeiAgentClient(config=config) as client:\n            await client.plan_task(\"Test-Plan\")\n\n    except SecurityError as e:\n        print(f\"\ud83d\udd12 Sicherheitsfehler: {e}\")\n    except ProtocolError as e:\n        print(f\"\ud83d\udd0c Protokollfehler: {e}\")\n    except KeiSDKError as e:\n        print(f\"\u26a0\ufe0f SDK-Fehler: {e}\")\n    except Exception as e:\n        print(f\"\u274c Unerwarteter Fehler: {e}\")\n\nasyncio.run(error_handling_demo())\n</code></pre>"},{"location":"getting-started/quickstart/#nachste-schritte","title":"\ud83c\udf89 N\u00e4chste Schritte","text":"<p>Herzlichen Gl\u00fcckwunsch! Sie haben die Grundlagen des KEI-Agent SDK gelernt. Hier sind Ihre n\u00e4chsten Schritte:</p>"},{"location":"getting-started/quickstart/#vertiefen-sie-ihr-wissen","title":"Vertiefen Sie Ihr Wissen","text":"<ul> <li>Basis-Konzepte - Verstehen Sie die Architektur</li> <li>Client-Verwendung - Erweiterte Client-Features</li> <li>Protokolle - Multi-Protocol Deep Dive</li> </ul>"},{"location":"getting-started/quickstart/#enterprise-features-erkunden","title":"Enterprise Features erkunden","text":"<ul> <li>Structured Logging - Production-Logging</li> <li>Health Checks - System-Monitoring</li> <li>Security - Sicherheits-Features</li> </ul>"},{"location":"getting-started/quickstart/#praktische-anwendung","title":"Praktische Anwendung","text":"<ul> <li>Beispiele - Umfassende Code-Beispiele</li> <li>API-Referenz - Vollst\u00e4ndige API-Dokumentation</li> </ul> <p>Bereit f\u00fcr mehr? Erkunden Sie die Basis-Konzepte \u2192</p>"},{"location":"migration/","title":"\ud83d\udd04 Migration Guide","text":"<p>Umfassender Leitfaden f\u00fcr die Migration zu Keiko Personal Assistant v2.0 und neueren Versionen.</p>"},{"location":"migration/#migration-ubersicht","title":"\ud83d\udccb Migration-\u00dcbersicht","text":""},{"location":"migration/#unterstutzte-migration-pfade","title":"Unterst\u00fctzte Migration-Pfade","text":"<pre><code>graph LR\n    subgraph \"Legacy Versions\"\n        V1_0[v1.0.x]\n        V1_5[v1.5.x]\n        V1_9[v1.9.x]\n    end\n\n    subgraph \"Current Version\"\n        V2_0[v2.0.x]\n    end\n\n    subgraph \"Migration Tools\"\n        AUTO[Automatic Migration]\n        MANUAL[Manual Migration]\n        HYBRID[Hybrid Migration]\n    end\n\n    V1_0 --&gt; AUTO\n    V1_5 --&gt; HYBRID\n    V1_9 --&gt; MANUAL\n\n    AUTO --&gt; V2_0\n    HYBRID --&gt; V2_0\n    MANUAL --&gt; V2_0</code></pre>"},{"location":"migration/#migration-strategien","title":"Migration-Strategien","text":"Von Version Zu Version Strategie Aufwand Downtime v1.0.x v2.0.x Vollst\u00e4ndige Migration Hoch 4-8 Stunden v1.5.x v2.0.x Hybride Migration Mittel 2-4 Stunden v1.9.x v2.0.x Inkrementelle Migration Niedrig 1-2 Stunden"},{"location":"migration/#schnellstart-migration","title":"\ud83d\ude80 Schnellstart-Migration","text":""},{"location":"migration/#pre-migration-checklist","title":"Pre-Migration Checklist","text":"<pre><code># 1. Backup erstellen\n./scripts/backup-system.sh --full --verify\n\n# 2. Abh\u00e4ngigkeiten pr\u00fcfen\n./scripts/check-dependencies.sh\n\n# 3. Migration-Tool herunterladen\ncurl -L https://github.com/oscharko/keiko-migration/releases/latest/download/migrate.sh -o migrate.sh\nchmod +x migrate.sh\n\n# 4. Migration-Plan erstellen\n./migrate.sh --plan --from-version=1.9.0 --to-version=2.0.0\n\n# 5. Dry-Run durchf\u00fchren\n./migrate.sh --dry-run --config=migration-config.yml\n</code></pre>"},{"location":"migration/#automatische-migration-v19x-v20x","title":"Automatische Migration (v1.9.x \u2192 v2.0.x)","text":"<pre><code># Migration-Konfiguration\ncat &gt; migration-config.yml &lt;&lt; EOF\nsource:\n  version: \"1.9.0\"\n  database_url: \"postgresql://user:pass@localhost/keiko_v1\"\n  config_path: \"/opt/keiko-v1/config\"\n  data_path: \"/opt/keiko-v1/data\"\n\ntarget:\n  version: \"2.0.0\"\n  database_url: \"postgresql://user:pass@localhost/keiko_v2\"\n  config_path: \"/opt/keiko-v2/config\"\n  data_path: \"/opt/keiko-v2/data\"\n\nmigration:\n  strategy: \"automatic\"\n  preserve_data: true\n  migrate_configs: true\n  migrate_users: true\n  migrate_agents: true\n  migrate_tasks: true\n\nbackup:\n  enabled: true\n  path: \"/backup/keiko-migration\"\n  verify: true\n\nrollback:\n  enabled: true\n  create_checkpoint: true\nEOF\n\n# Migration ausf\u00fchren\n./migrate.sh --config=migration-config.yml --execute\n</code></pre>"},{"location":"migration/#daten-migration","title":"\ud83d\udcca Daten-Migration","text":""},{"location":"migration/#database-schema-migration","title":"Database Schema Migration","text":"<pre><code># migration/database_migrator.py\nfrom keiko.migration import DatabaseMigrator, MigrationStep\n\nclass KeikoV2DatabaseMigrator(DatabaseMigrator):\n    \"\"\"Database-Migrator f\u00fcr Keiko v2.0.\"\"\"\n\n    def __init__(self, source_db_url: str, target_db_url: str):\n        super().__init__(source_db_url, target_db_url)\n        self.migration_steps = self._define_migration_steps()\n\n    def _define_migration_steps(self) -&gt; List[MigrationStep]:\n        \"\"\"Definiert Migration-Schritte.\"\"\"\n\n        return [\n            # Schritt 1: Schema-Updates\n            MigrationStep(\n                name=\"update_user_schema\",\n                description=\"Aktualisiert User-Schema f\u00fcr v2.0\",\n                sql_commands=[\n                    \"ALTER TABLE users ADD COLUMN role VARCHAR(50) DEFAULT 'user'\",\n                    \"ALTER TABLE users ADD COLUMN last_login TIMESTAMP\",\n                    \"ALTER TABLE users ADD COLUMN preferences JSONB DEFAULT '{}'\",\n                    \"CREATE INDEX idx_users_role ON users(role)\",\n                    \"CREATE INDEX idx_users_last_login ON users(last_login)\"\n                ],\n                rollback_commands=[\n                    \"DROP INDEX IF EXISTS idx_users_last_login\",\n                    \"DROP INDEX IF EXISTS idx_users_role\",\n                    \"ALTER TABLE users DROP COLUMN IF EXISTS preferences\",\n                    \"ALTER TABLE users DROP COLUMN IF EXISTS last_login\",\n                    \"ALTER TABLE users DROP COLUMN IF EXISTS role\"\n                ]\n            ),\n\n            # Schritt 2: Agent-Schema\n            MigrationStep(\n                name=\"update_agent_schema\",\n                description=\"Aktualisiert Agent-Schema f\u00fcr v2.0\",\n                sql_commands=[\n                    \"ALTER TABLE agents ADD COLUMN capabilities JSONB DEFAULT '[]'\",\n                    \"ALTER TABLE agents ADD COLUMN metadata JSONB DEFAULT '{}'\",\n                    \"ALTER TABLE agents ADD COLUMN version VARCHAR(20) DEFAULT '2.0.0'\",\n                    \"UPDATE agents SET capabilities = '[]' WHERE capabilities IS NULL\",\n                    \"CREATE INDEX idx_agents_capabilities ON agents USING GIN(capabilities)\",\n                    \"CREATE INDEX idx_agents_version ON agents(version)\"\n                ]\n            ),\n\n            # Schritt 3: Task-Schema\n            MigrationStep(\n                name=\"update_task_schema\",\n                description=\"Aktualisiert Task-Schema f\u00fcr v2.0\",\n                sql_commands=[\n                    \"ALTER TABLE tasks ADD COLUMN priority VARCHAR(20) DEFAULT 'normal'\",\n                    \"ALTER TABLE tasks ADD COLUMN timeout_seconds INTEGER DEFAULT 300\",\n                    \"ALTER TABLE tasks ADD COLUMN retry_count INTEGER DEFAULT 0\",\n                    \"ALTER TABLE tasks ADD COLUMN metadata JSONB DEFAULT '{}'\",\n                    \"CREATE INDEX idx_tasks_priority ON tasks(priority)\",\n                    \"CREATE INDEX idx_tasks_timeout ON tasks(timeout_seconds)\"\n                ]\n            ),\n\n            # Schritt 4: Neue Tabellen\n            MigrationStep(\n                name=\"create_new_tables\",\n                description=\"Erstellt neue Tabellen f\u00fcr v2.0\",\n                sql_commands=[\n                    \"\"\"\n                    CREATE TABLE mcp_servers (\n                        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                        name VARCHAR(100) UNIQUE NOT NULL,\n                        base_url VARCHAR(500) NOT NULL,\n                        auth_config JSONB DEFAULT '{}',\n                        status VARCHAR(20) DEFAULT 'inactive',\n                        created_at TIMESTAMP DEFAULT NOW(),\n                        updated_at TIMESTAMP DEFAULT NOW()\n                    )\n                    \"\"\",\n                    \"\"\"\n                    CREATE TABLE audit_logs (\n                        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n                        user_id UUID REFERENCES users(id),\n                        action VARCHAR(100) NOT NULL,\n                        resource_type VARCHAR(50) NOT NULL,\n                        resource_id VARCHAR(100),\n                        details JSONB DEFAULT '{}',\n                        ip_address INET,\n                        user_agent TEXT,\n                        created_at TIMESTAMP DEFAULT NOW()\n                    )\n                    \"\"\",\n                    \"CREATE INDEX idx_audit_logs_user_action ON audit_logs(user_id, action)\",\n                    \"CREATE INDEX idx_audit_logs_resource ON audit_logs(resource_type, resource_id)\",\n                    \"CREATE INDEX idx_audit_logs_created_at ON audit_logs(created_at)\"\n                ]\n            )\n        ]\n\n    async def migrate(self) -&gt; MigrationResult:\n        \"\"\"F\u00fchrt vollst\u00e4ndige Migration durch.\"\"\"\n\n        result = MigrationResult()\n\n        try:\n            # Pre-Migration-Checks\n            await self._pre_migration_checks()\n\n            # Backup erstellen\n            backup_path = await self._create_backup()\n            result.backup_path = backup_path\n\n            # Migration-Schritte ausf\u00fchren\n            for step in self.migration_steps:\n                step_result = await self._execute_migration_step(step)\n                result.add_step_result(step.name, step_result)\n\n                if not step_result.success:\n                    raise MigrationException(f\"Migration-Schritt fehlgeschlagen: {step.name}\")\n\n            # Post-Migration-Validierung\n            await self._post_migration_validation()\n\n            result.success = True\n            result.message = \"Migration erfolgreich abgeschlossen\"\n\n        except Exception as e:\n            result.success = False\n            result.error = str(e)\n\n            # Rollback bei Fehler\n            await self._rollback_migration()\n\n        return result\n\n    async def _execute_migration_step(self, step: MigrationStep) -&gt; StepResult:\n        \"\"\"F\u00fchrt einzelnen Migration-Schritt aus.\"\"\"\n\n        step_result = StepResult(step_name=step.name)\n\n        try:\n            async with self.target_db.begin() as conn:\n                for command in step.sql_commands:\n                    await conn.execute(text(command))\n\n            step_result.success = True\n            step_result.message = f\"Schritt {step.name} erfolgreich\"\n\n        except Exception as e:\n            step_result.success = False\n            step_result.error = str(e)\n\n            # Rollback f\u00fcr diesen Schritt\n            if step.rollback_commands:\n                try:\n                    async with self.target_db.begin() as conn:\n                        for command in reversed(step.rollback_commands):\n                            await conn.execute(text(command))\n                except Exception as rollback_error:\n                    step_result.rollback_error = str(rollback_error)\n\n        return step_result\n</code></pre>"},{"location":"migration/#daten-transformation","title":"Daten-Transformation","text":"<pre><code># migration/data_transformer.py\nclass DataTransformer:\n    \"\"\"Transformiert Daten zwischen Versionen.\"\"\"\n\n    async def transform_agents_v1_to_v2(self, v1_agents: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:\n        \"\"\"Transformiert Agent-Daten von v1 zu v2.\"\"\"\n\n        v2_agents = []\n\n        for v1_agent in v1_agents:\n            v2_agent = {\n                'id': v1_agent['id'],\n                'name': v1_agent['name'],\n                'type': v1_agent.get('agent_type', 'generic'),\n                'status': v1_agent.get('status', 'inactive'),\n                'created_at': v1_agent['created_at'],\n                'updated_at': v1_agent.get('updated_at', v1_agent['created_at']),\n\n                # Neue Felder in v2\n                'capabilities': self._extract_capabilities(v1_agent),\n                'metadata': self._extract_metadata(v1_agent),\n                'version': '2.0.0'\n            }\n\n            # Konfiguration transformieren\n            if 'config' in v1_agent:\n                v2_agent['configuration'] = self._transform_agent_config(v1_agent['config'])\n\n            v2_agents.append(v2_agent)\n\n        return v2_agents\n\n    def _extract_capabilities(self, v1_agent: Dict[str, Any]) -&gt; List[str]:\n        \"\"\"Extrahiert Capabilities aus v1-Agent.\"\"\"\n\n        capabilities = []\n\n        # Aus v1-Konfiguration ableiten\n        config = v1_agent.get('config', {})\n\n        if config.get('supports_text_processing'):\n            capabilities.append('text_processing')\n\n        if config.get('supports_image_generation'):\n            capabilities.append('image_generation')\n\n        if config.get('supports_data_analysis'):\n            capabilities.append('data_analysis')\n\n        # Fallback basierend auf Agent-Typ\n        agent_type = v1_agent.get('agent_type', 'generic')\n        if agent_type == 'text_processor':\n            capabilities.extend(['text_processing', 'summarization'])\n        elif agent_type == 'image_generator':\n            capabilities.extend(['image_generation', 'image_editing'])\n\n        return list(set(capabilities))  # Duplikate entfernen\n\n    def _extract_metadata(self, v1_agent: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Extrahiert Metadata aus v1-Agent.\"\"\"\n\n        metadata = {\n            'migrated_from': 'v1.x',\n            'migration_date': datetime.utcnow().isoformat(),\n            'original_type': v1_agent.get('agent_type')\n        }\n\n        # Zus\u00e4tzliche Metadaten aus v1-Konfiguration\n        config = v1_agent.get('config', {})\n        if 'description' in config:\n            metadata['description'] = config['description']\n\n        if 'tags' in config:\n            metadata['tags'] = config['tags']\n\n        return metadata\n\n    async def transform_tasks_v1_to_v2(self, v1_tasks: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:\n        \"\"\"Transformiert Task-Daten von v1 zu v2.\"\"\"\n\n        v2_tasks = []\n\n        for v1_task in v1_tasks:\n            v2_task = {\n                'id': v1_task['id'],\n                'user_id': v1_task['user_id'],\n                'agent_id': v1_task['agent_id'],\n                'task_type': v1_task.get('type', 'generic'),\n                'parameters': v1_task.get('params', {}),\n                'status': self._map_task_status(v1_task.get('status')),\n                'created_at': v1_task['created_at'],\n                'started_at': v1_task.get('started_at'),\n                'completed_at': v1_task.get('completed_at'),\n\n                # Neue Felder in v2\n                'priority': self._determine_priority(v1_task),\n                'timeout_seconds': v1_task.get('timeout', 300),\n                'retry_count': v1_task.get('retries', 0),\n                'metadata': {\n                    'migrated_from': 'v1.x',\n                    'original_status': v1_task.get('status')\n                }\n            }\n\n            v2_tasks.append(v2_task)\n\n        return v2_tasks\n\n    def _map_task_status(self, v1_status: str) -&gt; str:\n        \"\"\"Mappt v1-Task-Status zu v2-Status.\"\"\"\n\n        status_mapping = {\n            'created': 'pending',\n            'queued': 'pending',\n            'running': 'running',\n            'finished': 'completed',\n            'failed': 'failed',\n            'cancelled': 'cancelled'\n        }\n\n        return status_mapping.get(v1_status, 'pending')\n\n    def _determine_priority(self, v1_task: Dict[str, Any]) -&gt; str:\n        \"\"\"Bestimmt Priorit\u00e4t basierend auf v1-Task-Daten.\"\"\"\n\n        # Priorit\u00e4t aus v1-Parametern ableiten\n        params = v1_task.get('params', {})\n\n        if params.get('urgent'):\n            return 'high'\n        elif params.get('background'):\n            return 'low'\n        else:\n            return 'normal'\n</code></pre>"},{"location":"migration/#konfigurations-migration","title":"\u2699\ufe0f Konfigurations-Migration","text":""},{"location":"migration/#config-file-migration","title":"Config-File-Migration","text":"<pre><code># migration/config_migrator.py\nimport yaml\nimport json\nfrom pathlib import Path\n\nclass ConfigMigrator:\n    \"\"\"Migriert Konfigurationsdateien zwischen Versionen.\"\"\"\n\n    def __init__(self, source_config_path: str, target_config_path: str):\n        self.source_path = Path(source_config_path)\n        self.target_path = Path(target_config_path)\n\n    async def migrate_configs(self) -&gt; ConfigMigrationResult:\n        \"\"\"Migriert alle Konfigurationsdateien.\"\"\"\n\n        result = ConfigMigrationResult()\n\n        try:\n            # Hauptkonfiguration migrieren\n            main_config = await self._migrate_main_config()\n            result.add_config('main', main_config)\n\n            # Database-Konfiguration migrieren\n            db_config = await self._migrate_database_config()\n            result.add_config('database', db_config)\n\n            # Agent-Konfigurationen migrieren\n            agent_configs = await self._migrate_agent_configs()\n            result.add_config('agents', agent_configs)\n\n            # Security-Konfiguration migrieren\n            security_config = await self._migrate_security_config()\n            result.add_config('security', security_config)\n\n            result.success = True\n\n        except Exception as e:\n            result.success = False\n            result.error = str(e)\n\n        return result\n\n    async def _migrate_main_config(self) -&gt; Dict[str, Any]:\n        \"\"\"Migriert Hauptkonfiguration.\"\"\"\n\n        # v1-Konfiguration laden\n        v1_config_file = self.source_path / 'config.yml'\n        with open(v1_config_file, 'r') as f:\n            v1_config = yaml.safe_load(f)\n\n        # v2-Konfiguration erstellen\n        v2_config = {\n            'version': '2.0.0',\n            'environment': v1_config.get('env', 'development'),\n\n            # Server-Konfiguration\n            'server': {\n                'host': v1_config.get('host', '0.0.0.0'),\n                'port': v1_config.get('port', 8000),\n                'workers': v1_config.get('workers', 4),\n                'reload': v1_config.get('debug', False)\n            },\n\n            # Logging-Konfiguration\n            'logging': {\n                'level': v1_config.get('log_level', 'INFO'),\n                'format': 'json',  # Neu in v2\n                'structured': True,  # Neu in v2\n                'file_path': v1_config.get('log_file', '/var/log/keiko/app.log')\n            },\n\n            # Monitoring-Konfiguration (neu in v2)\n            'monitoring': {\n                'enabled': True,\n                'metrics_port': 9090,\n                'health_check_interval': 30\n            }\n        }\n\n        # v2-Konfiguration speichern\n        v2_config_file = self.target_path / 'config.yml'\n        v2_config_file.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(v2_config_file, 'w') as f:\n            yaml.dump(v2_config, f, default_flow_style=False)\n\n        return v2_config\n\n    async def _migrate_database_config(self) -&gt; Dict[str, Any]:\n        \"\"\"Migriert Database-Konfiguration.\"\"\"\n\n        v1_db_file = self.source_path / 'database.yml'\n        with open(v1_db_file, 'r') as f:\n            v1_db_config = yaml.safe_load(f)\n\n        v2_db_config = {\n            'default': {\n                'url': v1_db_config.get('database_url'),\n                'pool_size': v1_db_config.get('pool_size', 20),\n                'max_overflow': v1_db_config.get('max_overflow', 30),\n                'pool_timeout': 30,  # Neu in v2\n                'pool_recycle': 3600,  # Neu in v2\n                'echo': False\n            },\n\n            # Read-Replicas (neu in v2)\n            'read_replicas': v1_db_config.get('read_replicas', []),\n\n            # Migration-Konfiguration\n            'migrations': {\n                'auto_upgrade': False,\n                'backup_before_migration': True\n            }\n        }\n\n        # v2-Database-Konfiguration speichern\n        v2_db_file = self.target_path / 'database.yml'\n        with open(v2_db_file, 'w') as f:\n            yaml.dump(v2_db_config, f, default_flow_style=False)\n\n        return v2_db_config\n\n    async def _migrate_agent_configs(self) -&gt; Dict[str, Any]:\n        \"\"\"Migriert Agent-Konfigurationen.\"\"\"\n\n        v1_agents_dir = self.source_path / 'agents'\n        v2_agents_dir = self.target_path / 'agents'\n        v2_agents_dir.mkdir(parents=True, exist_ok=True)\n\n        migrated_configs = {}\n\n        # Alle v1-Agent-Konfigurationen durchgehen\n        for v1_config_file in v1_agents_dir.glob('*.yml'):\n            with open(v1_config_file, 'r') as f:\n                v1_agent_config = yaml.safe_load(f)\n\n            # v2-Agent-Konfiguration erstellen\n            v2_agent_config = {\n                'name': v1_agent_config['name'],\n                'type': v1_agent_config.get('type', 'generic'),\n                'version': '2.0.0',\n\n                # Capabilities (neu in v2)\n                'capabilities': self._extract_agent_capabilities(v1_agent_config),\n\n                # Konfiguration\n                'configuration': {\n                    'timeout_seconds': v1_agent_config.get('timeout', 300),\n                    'max_concurrent_tasks': v1_agent_config.get('max_tasks', 1),\n                    'retry_policy': {\n                        'max_retries': v1_agent_config.get('max_retries', 3),\n                        'retry_delay': v1_agent_config.get('retry_delay', 1.0)\n                    }\n                },\n\n                # External-Konfiguration\n                'external_config': v1_agent_config.get('external', {})\n            }\n\n            # v2-Konfiguration speichern\n            v2_config_file = v2_agents_dir / v1_config_file.name\n            with open(v2_config_file, 'w') as f:\n                yaml.dump(v2_agent_config, f, default_flow_style=False)\n\n            migrated_configs[v1_config_file.stem] = v2_agent_config\n\n        return migrated_configs\n</code></pre>"},{"location":"migration/#rollback-strategien","title":"\ud83d\udd04 Rollback-Strategien","text":""},{"location":"migration/#automatischer-rollback","title":"Automatischer Rollback","text":"<pre><code># rollback.sh\n#!/bin/bash\n\nBACKUP_PATH=\"/backup/keiko-migration\"\nROLLBACK_LOG=\"/var/log/keiko/rollback.log\"\n\necho \"$(date): Starting Keiko rollback process\" &gt;&gt; $ROLLBACK_LOG\n\n# 1. Services stoppen\necho \"Stopping Keiko v2 services...\" &gt;&gt; $ROLLBACK_LOG\nsystemctl stop keiko-v2\nsystemctl stop keiko-workers-v2\n\n# 2. Database rollback\necho \"Rolling back database...\" &gt;&gt; $ROLLBACK_LOG\npsql -U postgres -d keiko_v2 &lt; $BACKUP_PATH/database_rollback.sql\n\n# 3. Konfiguration wiederherstellen\necho \"Restoring configuration...\" &gt;&gt; $ROLLBACK_LOG\ncp -r $BACKUP_PATH/config/* /opt/keiko-v1/config/\n\n# 4. Daten wiederherstellen\necho \"Restoring data...\" &gt;&gt; $ROLLBACK_LOG\nrsync -av $BACKUP_PATH/data/ /opt/keiko-v1/data/\n\n# 5. v1 Services starten\necho \"Starting Keiko v1 services...\" &gt;&gt; $ROLLBACK_LOG\nsystemctl start keiko-v1\nsystemctl start keiko-workers-v1\n\n# 6. Health check\nsleep 30\nif curl -f http://localhost:8000/health; then\n    echo \"$(date): Rollback completed successfully\" &gt;&gt; $ROLLBACK_LOG\n    exit 0\nelse\n    echo \"$(date): Rollback failed - manual intervention required\" &gt;&gt; $ROLLBACK_LOG\n    exit 1\nfi\n</code></pre>"},{"location":"migration/#migration-checkliste","title":"\ud83d\udccb Migration-Checkliste","text":""},{"location":"migration/#pre-migration","title":"Pre-Migration","text":"<ul> <li> Vollst\u00e4ndiges Backup erstellt und verifiziert</li> <li> Abh\u00e4ngigkeiten gepr\u00fcft (Python 3.9+, PostgreSQL 13+, Redis 6+)</li> <li> Disk-Space ausreichend (mindestens 2x aktuelle Datengr\u00f6\u00dfe)</li> <li> Downtime-Fenster geplant und kommuniziert</li> <li> Rollback-Plan getestet</li> <li> Migration-Tools heruntergeladen und getestet</li> </ul>"},{"location":"migration/#during-migration","title":"During Migration","text":"<ul> <li> Services gestoppt in korrekter Reihenfolge</li> <li> Database-Migration erfolgreich</li> <li> Daten-Transformation abgeschlossen</li> <li> Konfigurations-Migration durchgef\u00fchrt</li> <li> Post-Migration-Tests bestanden</li> </ul>"},{"location":"migration/#post-migration","title":"Post-Migration","text":"<ul> <li> Funktionalit\u00e4ts-Tests erfolgreich</li> <li> Performance-Tests durchgef\u00fchrt</li> <li> User-Acceptance-Tests bestanden</li> <li> Monitoring aktiviert und konfiguriert</li> <li> Backup-Strategie f\u00fcr v2 implementiert</li> <li> Dokumentation aktualisiert</li> </ul> <p>Wichtige Hinweise</p> <ul> <li>F\u00fchren Sie immer einen vollst\u00e4ndigen Backup vor der Migration durch</li> <li>Testen Sie die Migration in einer Staging-Umgebung</li> <li>Planen Sie ausreichend Zeit f\u00fcr unvorhergesehene Probleme ein</li> <li>Halten Sie den Rollback-Plan bereit</li> </ul> <p>Support</p> <p>Bei Problemen w\u00e4hrend der Migration wenden Sie sich an das Support-Team oder erstellen Sie ein Issue im GitHub-Repository.</p>"},{"location":"migration/breaking-changes/","title":"\u26a0\ufe0f Breaking Changes","text":"<p>\u00dcbersicht \u00fcber Breaking Changes zwischen Keiko Personal Assistant Versionen.</p>"},{"location":"migration/breaking-changes/#v1x-v20-breaking-changes","title":"\ud83d\udd04 v1.x \u2192 v2.0 Breaking Changes","text":""},{"location":"migration/breaking-changes/#architektur-anderungen","title":"\ud83c\udfd7\ufe0f Architektur-\u00c4nderungen","text":""},{"location":"migration/breaking-changes/#agent-system-refactoring","title":"Agent-System Refactoring","text":"<p>v1.x (Deprecated) <pre><code># Alte Agent-Klasse\nclass Agent:\n    def __init__(self, name: str, config: dict):\n        self.name = name\n        self.config = config\n\n    def execute(self, task: dict) -&gt; dict:\n        # Synchrone Ausf\u00fchrung\n        return {\"result\": \"completed\"}\n\n# Alte Verwendung\nagent = Agent(\"text-processor\", {\"type\": \"nlp\"})\nresult = agent.execute({\"text\": \"Hello World\"})\n</code></pre></p> <p>v2.0 (New) <pre><code># Neue Agent-Klasse\nclass Agent:\n    def __init__(self, config: AgentConfig):\n        self.config = config\n        self.id = generate_uuid()\n\n    async def execute_task(self, task: Task) -&gt; TaskResult:\n        # Asynchrone Ausf\u00fchrung\n        return TaskResult.success({\"result\": \"completed\"})\n\n# Neue Verwendung\nconfig = AgentConfig(\n    name=\"text-processor\",\n    type=AgentType.SPECIALIST,\n    capabilities=[\"text_processing\"]\n)\nagent = Agent(config)\nresult = await agent.execute_task(task)\n</code></pre></p> <p>Migration-Schritte: 1. Ersetzen Sie <code>dict</code>-basierte Konfiguration durch <code>AgentConfig</code> 2. Konvertieren Sie synchrone <code>execute()</code> zu asynchronem <code>execute_task()</code> 3. Verwenden Sie <code>Task</code> und <code>TaskResult</code> Objekte statt <code>dict</code></p>"},{"location":"migration/breaking-changes/#database-schema-anderungen","title":"Database-Schema-\u00c4nderungen","text":"<p>Entfernte Tabellen: - <code>agent_configs</code> \u2192 Migriert zu <code>agents.configuration</code> (JSONB) - <code>task_logs</code> \u2192 Migriert zu <code>audit_logs</code> - <code>user_sessions</code> \u2192 Ersetzt durch JWT-Token</p> <p>Neue Tabellen: - <code>mcp_servers</code> - MCP-Server-Registrierung - <code>audit_logs</code> - Umfassendes Audit-Logging - <code>protocol_configs</code> - Protocol-Konfigurationen</p> <p>Schema-Migration: <pre><code>-- Entfernte Spalten\nALTER TABLE users DROP COLUMN IF EXISTS session_token;\nALTER TABLE agents DROP COLUMN IF EXISTS config_json;\n\n-- Neue Spalten\nALTER TABLE users ADD COLUMN role VARCHAR(50) DEFAULT 'user';\nALTER TABLE users ADD COLUMN preferences JSONB DEFAULT '{}';\nALTER TABLE agents ADD COLUMN capabilities JSONB DEFAULT '[]';\nALTER TABLE agents ADD COLUMN metadata JSONB DEFAULT '{}';\nALTER TABLE tasks ADD COLUMN priority VARCHAR(20) DEFAULT 'normal';\nALTER TABLE tasks ADD COLUMN timeout_seconds INTEGER DEFAULT 300;\n</code></pre></p>"},{"location":"migration/breaking-changes/#api-anderungen","title":"\ud83d\udd0c API-\u00c4nderungen","text":""},{"location":"migration/breaking-changes/#rest-api-endpunkte","title":"REST-API-Endpunkte","text":"<p>Entfernte Endpunkte: - <code>GET /api/agents/{id}/config</code> \u2192 Verwenden Sie <code>GET /api/v1/agents/{id}</code> - <code>POST /api/tasks/execute</code> \u2192 Verwenden Sie <code>POST /api/v1/agents/{id}/tasks</code> - <code>GET /api/status</code> \u2192 Verwenden Sie <code>GET /health</code></p> <p>Ge\u00e4nderte Endpunkte: <pre><code># v1.x\nPOST /api/agents\n{\n    \"name\": \"agent-name\",\n    \"type\": \"nlp\",\n    \"config\": {...}\n}\n\n# v2.0\nPOST /api/v1/agents\n{\n    \"name\": \"agent-name\",\n    \"type\": \"specialist\",\n    \"capabilities\": [\"text_processing\"],\n    \"configuration\": {...}\n}\n</code></pre></p> <p>Neue Endpunkte: - <code>GET /api/v1/mcp/servers</code> - MCP-Server-Management - <code>POST /api/v1/protocols/select</code> - Protocol-Selection - <code>GET /api/v1/audit/logs</code> - Audit-Log-Zugriff</p>"},{"location":"migration/breaking-changes/#response-format-anderungen","title":"Response-Format-\u00c4nderungen","text":"<p>v1.x Response: <pre><code>{\n    \"status\": \"success\",\n    \"data\": {...},\n    \"message\": \"Operation completed\"\n}\n</code></pre></p> <p>v2.0 Response: <pre><code>{\n    \"success\": true,\n    \"data\": {...},\n    \"metadata\": {\n        \"request_id\": \"uuid\",\n        \"timestamp\": \"2024-01-01T00:00:00Z\",\n        \"version\": \"2.0.0\"\n    }\n}\n</code></pre></p>"},{"location":"migration/breaking-changes/#konfigurations-anderungen","title":"\ud83d\udd27 Konfigurations-\u00c4nderungen","text":""},{"location":"migration/breaking-changes/#environment-variablen","title":"Environment-Variablen","text":"<p>Entfernte Variablen: - <code>KEIKO_AGENT_CONFIG_PATH</code> \u2192 Verwenden Sie <code>KEIKO_CONFIG_PATH</code> - <code>KEIKO_LOG_FILE</code> \u2192 Verwenden Sie <code>KEIKO_LOG_CONFIG</code> - <code>KEIKO_DB_POOL_SIZE</code> \u2192 Verwenden Sie <code>DATABASE_POOL_SIZE</code></p> <p>Neue Variablen: - <code>KEIKO_MCP_SERVERS_CONFIG</code> - MCP-Server-Konfiguration - <code>KEIKO_PROTOCOL_SELECTOR_CONFIG</code> - Protocol-Selection-Konfiguration - <code>KEIKO_AUDIT_LOG_LEVEL</code> - Audit-Logging-Level</p> <p>Ge\u00e4nderte Variablen: <pre><code># v1.x\nKEIKO_AGENTS_PATH=/opt/keiko/agents\nKEIKO_TASKS_PATH=/opt/keiko/tasks\n\n# v2.0\nKEIKO_CONFIG_PATH=/opt/keiko/config\nKEIKO_DATA_PATH=/opt/keiko/data\n</code></pre></p>"},{"location":"migration/breaking-changes/#konfigurationsdatei-format","title":"Konfigurationsdatei-Format","text":"<p>v1.x config.yml: <pre><code>server:\n  host: 0.0.0.0\n  port: 8000\n\ndatabase:\n  url: postgresql://...\n  pool_size: 10\n\nagents:\n  - name: agent1\n    type: nlp\n    config:\n      model: gpt-3.5\n</code></pre></p> <p>v2.0 config.yml: <pre><code>version: \"2.0.0\"\nserver:\n  host: 0.0.0.0\n  port: 8000\n  workers: 4\n\ndatabase:\n  default:\n    url: postgresql://...\n    pool_size: 20\n    max_overflow: 30\n\nagents:\n  config_path: /opt/keiko/config/agents\n\nmcp:\n  servers_config: /opt/keiko/config/mcp-servers.yml\n\nprotocols:\n  selector_config: /opt/keiko/config/protocols.yml\n</code></pre></p>"},{"location":"migration/breaking-changes/#dependency-anderungen","title":"\ud83d\udce6 Dependency-\u00c4nderungen","text":""},{"location":"migration/breaking-changes/#python-abhangigkeiten","title":"Python-Abh\u00e4ngigkeiten","text":"<p>Entfernte Dependencies: - <code>flask</code> \u2192 Ersetzt durch <code>fastapi</code> - <code>sqlalchemy&lt;1.4</code> \u2192 Upgrade auf <code>sqlalchemy&gt;=2.0</code> - <code>redis-py&lt;4.0</code> \u2192 Upgrade auf <code>redis&gt;=4.0</code></p> <p>Neue Dependencies: - <code>fastapi&gt;=0.104.0</code> - Web-Framework - <code>asyncpg&gt;=0.29.0</code> - Async PostgreSQL-Driver - <code>pydantic&gt;=2.0.0</code> - Data-Validation - <code>prometheus-client&gt;=0.19.0</code> - Metrics</p> <p>Ge\u00e4nderte Dependencies: <pre><code># v1.x requirements.txt\nsqlalchemy==1.3.24\nredis==3.5.3\nrequests==2.28.0\n\n# v2.0 requirements.txt\nsqlalchemy&gt;=2.0.0\nredis&gt;=4.0.0\naiohttp&gt;=3.9.0\n</code></pre></p>"},{"location":"migration/breaking-changes/#python-version-anforderungen","title":"Python-Version-Anforderungen","text":"<ul> <li>v1.x: Python 3.7+</li> <li>v2.0: Python 3.9+ (Breaking Change)</li> </ul>"},{"location":"migration/breaking-changes/#security-anderungen","title":"\ud83d\udd10 Security-\u00c4nderungen","text":""},{"location":"migration/breaking-changes/#authentifizierung","title":"Authentifizierung","text":"<p>v1.x Session-basiert: <pre><code># Session-Token in Database\nsession = create_session(user_id)\nresponse.set_cookie(\"session_id\", session.id)\n</code></pre></p> <p>v2.0 JWT-basiert: <pre><code># JWT-Token\ntoken = create_jwt_token(user_id, expires_in=3600)\nresponse.headers[\"Authorization\"] = f\"Bearer {token}\"\n</code></pre></p> <p>Migration: Alle bestehenden Sessions werden invalidiert. Benutzer m\u00fcssen sich neu anmelden.</p>"},{"location":"migration/breaking-changes/#berechtigungen","title":"Berechtigungen","text":"<p>v1.x Einfache Rollen: <pre><code>user.role in [\"admin\", \"user\"]\n</code></pre></p> <p>v2.0 RBAC-System: <pre><code>user.has_permission(\"agents:create\")\nuser.has_role(\"agent_operator\")\n</code></pre></p>"},{"location":"migration/breaking-changes/#migration-strategien","title":"\ud83d\udee0\ufe0f Migration-Strategien","text":""},{"location":"migration/breaking-changes/#automatische-migration","title":"Automatische Migration","text":"<pre><code># Automatisches Migration-Script\n./scripts/migrate-v1-to-v2.sh --backup --validate\n\n# Schritte:\n# 1. Backup erstellen\n# 2. Database-Schema migrieren\n# 3. Konfiguration konvertieren\n# 4. Code-Anpassungen vorschlagen\n# 5. Validierung durchf\u00fchren\n</code></pre>"},{"location":"migration/breaking-changes/#manuelle-anpassungen","title":"Manuelle Anpassungen","text":""},{"location":"migration/breaking-changes/#1-code-anpassungen","title":"1. Code-Anpassungen","text":"<pre><code># v1.x Code\ndef create_agent(name: str, config: dict):\n    agent = Agent(name, config)\n    return agent.execute({\"task\": \"test\"})\n\n# v2.0 Code\nasync def create_agent(name: str, config: AgentConfig):\n    agent = Agent(config)\n    task = Task.create(\"test\", {})\n    return await agent.execute_task(task)\n</code></pre>"},{"location":"migration/breaking-changes/#2-konfiguration-migration","title":"2. Konfiguration-Migration","text":"<pre><code># migration/config_converter.py\ndef convert_v1_config_to_v2(v1_config: dict) -&gt; dict:\n    \"\"\"Konvertiert v1-Konfiguration zu v2-Format.\"\"\"\n\n    v2_config = {\n        \"version\": \"2.0.0\",\n        \"server\": {\n            \"host\": v1_config.get(\"host\", \"0.0.0.0\"),\n            \"port\": v1_config.get(\"port\", 8000),\n            \"workers\": 4  # Neu in v2\n        },\n        \"database\": {\n            \"default\": {\n                \"url\": v1_config.get(\"database_url\"),\n                \"pool_size\": v1_config.get(\"db_pool_size\", 20)\n            }\n        }\n    }\n\n    # Agents-Konfiguration konvertieren\n    if \"agents\" in v1_config:\n        v2_config[\"agents\"] = {\n            \"config_path\": \"/opt/keiko/config/agents\"\n        }\n\n        # Einzelne Agent-Configs in separate Dateien\n        for agent in v1_config[\"agents\"]:\n            agent_config = {\n                \"name\": agent[\"name\"],\n                \"type\": \"specialist\",  # Default-Typ in v2\n                \"capabilities\": _extract_capabilities(agent),\n                \"configuration\": agent.get(\"config\", {})\n            }\n\n            # Agent-Config-Datei erstellen\n            with open(f\"/opt/keiko/config/agents/{agent['name']}.yml\", \"w\") as f:\n                yaml.dump(agent_config, f)\n\n    return v2_config\n</code></pre>"},{"location":"migration/breaking-changes/#rollback-plan","title":"Rollback-Plan","text":"<pre><code># Rollback zu v1.x\n./scripts/rollback-to-v1.sh\n\n# Schritte:\n# 1. v2.0 Services stoppen\n# 2. Database-Backup wiederherstellen\n# 3. v1.x Konfiguration wiederherstellen\n# 4. v1.x Services starten\n# 5. Funktionalit\u00e4t validieren\n</code></pre>"},{"location":"migration/breaking-changes/#kompatibilitats-matrix","title":"\ud83d\udccb Kompatibilit\u00e4ts-Matrix","text":"Feature v1.x v2.0 Migration-Aufwand Agent-System \u2705 \u2705 (Refactored) Hoch Task-Execution \u2705 \u2705 (Async) Mittel REST-API \u2705 \u2705 (Versioned) Niedrig Database \u2705 \u2705 (Schema-Changes) Hoch Authentication Session JWT Mittel Configuration YAML YAML (Extended) Niedrig MCP-Integration \u274c \u2705 Neu Protocol-Selection \u274c \u2705 Neu Audit-Logging Basic Enterprise Mittel"},{"location":"migration/breaking-changes/#wichtige-hinweise","title":"\u26a0\ufe0f Wichtige Hinweise","text":""},{"location":"migration/breaking-changes/#nicht-ruckwarts-kompatible-anderungen","title":"Nicht-r\u00fcckw\u00e4rts-kompatible \u00c4nderungen","text":"<ol> <li>Python 3.9+ erforderlich - Upgrade der Python-Version notwendig</li> <li>Async/Await \u00fcberall - Alle Agent-Methoden sind jetzt asynchron</li> <li>Neue Database-Schema - Vollst\u00e4ndige Schema-Migration erforderlich</li> <li>JWT statt Sessions - Alle Benutzer m\u00fcssen sich neu anmelden</li> <li>Neue Konfiguration-Struktur - Konfigurationsdateien m\u00fcssen migriert werden</li> </ol>"},{"location":"migration/breaking-changes/#empfohlene-migration-reihenfolge","title":"Empfohlene Migration-Reihenfolge","text":"<ol> <li>Staging-Umgebung - Testen Sie die Migration zuerst in Staging</li> <li>Backup erstellen - Vollst\u00e4ndiges Backup vor Migration</li> <li>Dependencies aktualisieren - Python und Package-Updates</li> <li>Schema migrieren - Database-Schema-Updates</li> <li>Code anpassen - Async/Await und neue APIs</li> <li>Konfiguration migrieren - Neue Konfiguration-Struktur</li> <li>Validierung - Umfassende Tests nach Migration</li> <li>Produktions-Migration - Mit Rollback-Plan</li> </ol>"},{"location":"migration/breaking-changes/#support-timeline","title":"Support-Timeline","text":"<ul> <li>v1.x Support: Bis 31. Dezember 2024</li> <li>v1.x Security-Updates: Bis 30. Juni 2025</li> <li>v2.0 LTS: Langzeit-Support bis 2027</li> </ul> <p>Kritische Breaking Changes</p> <ul> <li>Sofortige Aktion erforderlich: Python 3.9+ und Async/Await-Migration</li> <li>Daten-Migration: Database-Schema-\u00c4nderungen sind nicht optional</li> <li>Security: Session-basierte Auth wird nicht mehr unterst\u00fctzt</li> </ul> <p>Migration-Hilfe</p> <p>Nutzen Sie die bereitgestellten Migration-Scripts und testen Sie ausf\u00fchrlich in einer Staging-Umgebung vor der Produktions-Migration.</p>"},{"location":"migration/from-legacy/","title":"\ud83d\udd04 Migration from Legacy Systems","text":"<p>Leitfaden f\u00fcr die Migration von Legacy-Systemen zu Keiko Personal Assistant.</p>"},{"location":"migration/from-legacy/#legacy-system-unterstutzung","title":"\ud83c\udfd7\ufe0f Legacy-System-Unterst\u00fctzung","text":""},{"location":"migration/from-legacy/#unterstutzte-legacy-systeme","title":"Unterst\u00fctzte Legacy-Systeme","text":"<pre><code>graph TB\n    subgraph \"Legacy Systems\"\n        CUSTOM[Custom AI Systems]\n        LANGCHAIN[LangChain Apps]\n        OPENAI[OpenAI Assistants]\n        AZURE[Azure Bot Framework]\n        RASA[Rasa Chatbots]\n    end\n\n    subgraph \"Migration Tools\"\n        EXTRACTOR[Data Extractor]\n        TRANSFORMER[Data Transformer]\n        VALIDATOR[Migration Validator]\n    end\n\n    subgraph \"Keiko v2.0\"\n        AGENTS[Keiko Agents]\n        TASKS[Task System]\n        MCP[MCP Integration]\n    end\n\n    CUSTOM --&gt; EXTRACTOR\n    LANGCHAIN --&gt; EXTRACTOR\n    OPENAI --&gt; EXTRACTOR\n    AZURE --&gt; EXTRACTOR\n    RASA --&gt; EXTRACTOR\n\n    EXTRACTOR --&gt; TRANSFORMER\n    TRANSFORMER --&gt; VALIDATOR\n    VALIDATOR --&gt; AGENTS\n    VALIDATOR --&gt; TASKS\n    VALIDATOR --&gt; MCP</code></pre>"},{"location":"migration/from-legacy/#openai-assistants-migration","title":"\ud83e\udd16 OpenAI Assistants Migration","text":""},{"location":"migration/from-legacy/#openai-assistant-zu-keiko-agent","title":"OpenAI Assistant zu Keiko Agent","text":"<pre><code># migration/openai_migrator.py\nimport openai\nfrom keiko.core.agent import Agent, AgentConfig\nfrom keiko.migration.base import BaseMigrator\n\nclass OpenAIMigrator(BaseMigrator):\n    \"\"\"Migriert OpenAI Assistants zu Keiko Agents.\"\"\"\n\n    def __init__(self, openai_api_key: str):\n        self.openai_client = openai.OpenAI(api_key=openai_api_key)\n        super().__init__()\n\n    async def extract_assistants(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Extrahiert OpenAI Assistants.\"\"\"\n\n        assistants = []\n\n        # Alle Assistants abrufen\n        response = self.openai_client.beta.assistants.list()\n\n        for assistant in response.data:\n            assistant_data = {\n                'id': assistant.id,\n                'name': assistant.name,\n                'description': assistant.description,\n                'instructions': assistant.instructions,\n                'model': assistant.model,\n                'tools': [tool.type for tool in assistant.tools],\n                'file_ids': assistant.file_ids,\n                'metadata': assistant.metadata,\n                'created_at': assistant.created_at\n            }\n\n            assistants.append(assistant_data)\n\n        return assistants\n\n    async def transform_assistant_to_agent(self, assistant: Dict[str, Any]) -&gt; AgentConfig:\n        \"\"\"Transformiert OpenAI Assistant zu Keiko Agent.\"\"\"\n\n        # Capabilities aus Tools ableiten\n        capabilities = []\n        for tool in assistant.get('tools', []):\n            if tool == 'code_interpreter':\n                capabilities.extend(['code_execution', 'data_analysis'])\n            elif tool == 'retrieval':\n                capabilities.extend(['document_search', 'knowledge_retrieval'])\n            elif tool == 'function':\n                capabilities.append('function_calling')\n\n        # Agent-Konfiguration erstellen\n        config = AgentConfig(\n            name=assistant['name'] or f\"Migrated Assistant {assistant['id']}\",\n            type='specialist',\n            capabilities=capabilities,\n            description=assistant.get('description', ''),\n\n            # Konfiguration\n            timeout_seconds=300,\n            max_concurrent_tasks=1,\n\n            # Externe Konfiguration\n            external_config={\n                'openai_model': assistant.get('model', 'gpt-4'),\n                'instructions': assistant.get('instructions', ''),\n                'migrated_from': 'openai_assistant',\n                'original_id': assistant['id'],\n                'migration_date': datetime.utcnow().isoformat()\n            }\n        )\n\n        return config\n\n    async def migrate_assistant_files(self, assistant: Dict[str, Any]) -&gt; List[str]:\n        \"\"\"Migriert Assistant-Dateien.\"\"\"\n\n        migrated_files = []\n\n        for file_id in assistant.get('file_ids', []):\n            try:\n                # Datei von OpenAI herunterladen\n                file_info = self.openai_client.files.retrieve(file_id)\n                file_content = self.openai_client.files.content(file_id)\n\n                # In Keiko-Storage speichern\n                local_path = f\"/data/migrated_files/{file_info.filename}\"\n\n                with open(local_path, 'wb') as f:\n                    f.write(file_content.read())\n\n                migrated_files.append(local_path)\n\n            except Exception as e:\n                print(f\"Fehler beim Migrieren der Datei {file_id}: {e}\")\n\n        return migrated_files\n\n# Verwendung\nasync def migrate_openai_assistants():\n    \"\"\"Migriert alle OpenAI Assistants.\"\"\"\n\n    migrator = OpenAIMigrator(openai_api_key=\"your-api-key\")\n\n    # Assistants extrahieren\n    assistants = await migrator.extract_assistants()\n    print(f\"Gefunden: {len(assistants)} OpenAI Assistants\")\n\n    # Jeden Assistant migrieren\n    for assistant in assistants:\n        try:\n            # Agent-Konfiguration erstellen\n            agent_config = await migrator.transform_assistant_to_agent(assistant)\n\n            # Dateien migrieren\n            migrated_files = await migrator.migrate_assistant_files(assistant)\n\n            # Agent in Keiko erstellen\n            agent = Agent(agent_config)\n            await agent_service.create_agent(agent)\n\n            print(f\"Assistant '{assistant['name']}' erfolgreich migriert\")\n\n        except Exception as e:\n            print(f\"Fehler beim Migrieren von Assistant '{assistant['name']}': {e}\")\n</code></pre>"},{"location":"migration/from-legacy/#langchain-migration","title":"\ud83e\udd9c LangChain Migration","text":""},{"location":"migration/from-legacy/#langchain-chain-zu-keiko-agent","title":"LangChain Chain zu Keiko Agent","text":"<pre><code># migration/langchain_migrator.py\nfrom langchain.chains import LLMChain, ConversationChain\nfrom langchain.agents import AgentExecutor\nfrom keiko.core.agent import Agent, AgentConfig\n\nclass LangChainMigrator(BaseMigrator):\n    \"\"\"Migriert LangChain Chains zu Keiko Agents.\"\"\"\n\n    async def extract_chain_config(self, chain) -&gt; Dict[str, Any]:\n        \"\"\"Extrahiert Konfiguration aus LangChain Chain.\"\"\"\n\n        config = {\n            'chain_type': type(chain).__name__,\n            'llm_model': getattr(chain.llm, 'model_name', 'unknown'),\n            'prompt_template': None,\n            'tools': [],\n            'memory': None\n        }\n\n        # Prompt-Template extrahieren\n        if hasattr(chain, 'prompt'):\n            config['prompt_template'] = chain.prompt.template\n\n        # Tools extrahieren (f\u00fcr Agent-Chains)\n        if hasattr(chain, 'tools'):\n            config['tools'] = [\n                {\n                    'name': tool.name,\n                    'description': tool.description,\n                    'func': tool.func.__name__ if hasattr(tool, 'func') else None\n                }\n                for tool in chain.tools\n            ]\n\n        # Memory extrahieren\n        if hasattr(chain, 'memory') and chain.memory:\n            config['memory'] = {\n                'type': type(chain.memory).__name__,\n                'return_messages': getattr(chain.memory, 'return_messages', False)\n            }\n\n        return config\n\n    async def transform_chain_to_agent(self, chain_config: Dict[str, Any]) -&gt; AgentConfig:\n        \"\"\"Transformiert LangChain Chain zu Keiko Agent.\"\"\"\n\n        # Capabilities basierend auf Chain-Typ bestimmen\n        capabilities = []\n\n        if chain_config['chain_type'] == 'LLMChain':\n            capabilities.extend(['text_generation', 'conversation'])\n        elif chain_config['chain_type'] == 'ConversationChain':\n            capabilities.extend(['conversation', 'memory_management'])\n        elif 'Agent' in chain_config['chain_type']:\n            capabilities.extend(['tool_usage', 'reasoning', 'planning'])\n\n        # Tools zu Capabilities hinzuf\u00fcgen\n        for tool in chain_config.get('tools', []):\n            if 'search' in tool['name'].lower():\n                capabilities.append('web_search')\n            elif 'calculator' in tool['name'].lower():\n                capabilities.append('calculation')\n            elif 'python' in tool['name'].lower():\n                capabilities.append('code_execution')\n\n        # Agent-Konfiguration erstellen\n        config = AgentConfig(\n            name=f\"Migrated {chain_config['chain_type']}\",\n            type='specialist',\n            capabilities=list(set(capabilities)),\n\n            external_config={\n                'llm_model': chain_config.get('llm_model'),\n                'prompt_template': chain_config.get('prompt_template'),\n                'tools': chain_config.get('tools', []),\n                'memory_config': chain_config.get('memory'),\n                'migrated_from': 'langchain',\n                'original_chain_type': chain_config['chain_type']\n            }\n        )\n\n        return config\n\n# Custom Agent Implementation f\u00fcr LangChain-Migration\nclass MigratedLangChainAgent(Agent):\n    \"\"\"Agent f\u00fcr migrierte LangChain Chains.\"\"\"\n\n    async def execute_task(self, task: Task) -&gt; TaskResult:\n        \"\"\"F\u00fchrt Task mit LangChain-Kompatibilit\u00e4t aus.\"\"\"\n\n        # LangChain-spezifische Logik\n        prompt_template = self.config.external_config.get('prompt_template')\n\n        if prompt_template:\n            # Prompt mit Task-Parametern formatieren\n            formatted_prompt = prompt_template.format(**task.parameters)\n\n            # LLM-Aufruf simulieren\n            result = await self._call_llm(formatted_prompt)\n\n            return TaskResult.success({\n                'response': result,\n                'prompt_used': formatted_prompt\n            })\n        else:\n            return await super().execute_task(task)\n\n    async def _call_llm(self, prompt: str) -&gt; str:\n        \"\"\"Ruft LLM mit Prompt auf.\"\"\"\n\n        # Hier w\u00fcrde der tats\u00e4chliche LLM-Aufruf stehen\n        # F\u00fcr Demo-Zwecke simuliert\n        return f\"Response to: {prompt[:50]}...\"\n</code></pre>"},{"location":"migration/from-legacy/#azure-bot-framework-migration","title":"\ud83e\udd16 Azure Bot Framework Migration","text":""},{"location":"migration/from-legacy/#bot-framework-zu-keiko","title":"Bot Framework zu Keiko","text":"<pre><code># migration/azure_bot_migrator.py\nimport json\nfrom pathlib import Path\n\nclass AzureBotMigrator(BaseMigrator):\n    \"\"\"Migriert Azure Bot Framework Bots zu Keiko.\"\"\"\n\n    async def extract_bot_config(self, bot_project_path: str) -&gt; Dict[str, Any]:\n        \"\"\"Extrahiert Bot-Konfiguration aus Azure Bot Framework.\"\"\"\n\n        project_path = Path(bot_project_path)\n\n        # Bot-Konfiguration laden\n        config_file = project_path / 'appsettings.json'\n        with open(config_file, 'r') as f:\n            app_settings = json.load(f)\n\n        # Dialoge extrahieren\n        dialogs = []\n        dialogs_path = project_path / 'Dialogs'\n\n        if dialogs_path.exists():\n            for dialog_file in dialogs_path.glob('*.cs'):\n                dialog_info = await self._extract_dialog_info(dialog_file)\n                dialogs.append(dialog_info)\n\n        # LUIS-Modelle extrahieren\n        luis_models = []\n        luis_path = project_path / 'CognitiveModels'\n\n        if luis_path.exists():\n            for luis_file in luis_path.glob('*.json'):\n                with open(luis_file, 'r') as f:\n                    luis_model = json.load(f)\n                    luis_models.append(luis_model)\n\n        return {\n            'app_settings': app_settings,\n            'dialogs': dialogs,\n            'luis_models': luis_models,\n            'bot_name': app_settings.get('BotName', 'Migrated Bot')\n        }\n\n    async def _extract_dialog_info(self, dialog_file: Path) -&gt; Dict[str, Any]:\n        \"\"\"Extrahiert Dialog-Informationen aus C#-Datei.\"\"\"\n\n        with open(dialog_file, 'r') as f:\n            content = f.read()\n\n        # Vereinfachte Extraktion (in Realit\u00e4t w\u00fcrde man einen C#-Parser verwenden)\n        dialog_info = {\n            'name': dialog_file.stem,\n            'file_path': str(dialog_file),\n            'has_waterfall': 'WaterfallDialog' in content,\n            'has_prompts': 'Prompt' in content,\n            'has_luis': 'LuisRecognizer' in content\n        }\n\n        return dialog_info\n\n    async def transform_bot_to_agent(self, bot_config: Dict[str, Any]) -&gt; AgentConfig:\n        \"\"\"Transformiert Azure Bot zu Keiko Agent.\"\"\"\n\n        capabilities = ['conversation', 'dialog_management']\n\n        # Capabilities basierend auf Features bestimmen\n        if bot_config.get('luis_models'):\n            capabilities.extend(['intent_recognition', 'entity_extraction'])\n\n        for dialog in bot_config.get('dialogs', []):\n            if dialog.get('has_waterfall'):\n                capabilities.append('workflow_management')\n            if dialog.get('has_prompts'):\n                capabilities.append('user_interaction')\n\n        config = AgentConfig(\n            name=bot_config.get('bot_name', 'Migrated Azure Bot'),\n            type='conversational',\n            capabilities=list(set(capabilities)),\n\n            external_config={\n                'azure_app_id': bot_config['app_settings'].get('MicrosoftAppId'),\n                'dialogs': bot_config.get('dialogs', []),\n                'luis_models': bot_config.get('luis_models', []),\n                'migrated_from': 'azure_bot_framework',\n                'original_settings': bot_config['app_settings']\n            }\n        )\n\n        return config\n</code></pre>"},{"location":"migration/from-legacy/#custom-ai-system-migration","title":"\ud83d\udcca Custom AI System Migration","text":""},{"location":"migration/from-legacy/#generic-ai-system-migration","title":"Generic AI System Migration","text":"<pre><code># migration/custom_migrator.py\nclass CustomAIMigrator(BaseMigrator):\n    \"\"\"Generischer Migrator f\u00fcr Custom AI Systems.\"\"\"\n\n    def __init__(self, system_config: Dict[str, Any]):\n        self.system_config = system_config\n        super().__init__()\n\n    async def analyze_system(self, system_path: str) -&gt; Dict[str, Any]:\n        \"\"\"Analysiert Custom AI System.\"\"\"\n\n        analysis = {\n            'system_type': 'unknown',\n            'components': [],\n            'data_sources': [],\n            'models': [],\n            'apis': [],\n            'dependencies': []\n        }\n\n        system_path = Path(system_path)\n\n        # Python-Dateien analysieren\n        for py_file in system_path.rglob('*.py'):\n            component_info = await self._analyze_python_file(py_file)\n            analysis['components'].append(component_info)\n\n        # Konfigurationsdateien finden\n        for config_file in system_path.rglob('*.json'):\n            with open(config_file, 'r') as f:\n                try:\n                    config_data = json.load(f)\n                    analysis['data_sources'].append({\n                        'file': str(config_file),\n                        'type': 'json_config',\n                        'data': config_data\n                    })\n                except:\n                    pass\n\n        # Requirements analysieren\n        req_file = system_path / 'requirements.txt'\n        if req_file.exists():\n            with open(req_file, 'r') as f:\n                analysis['dependencies'] = [\n                    line.strip() for line in f.readlines()\n                    if line.strip() and not line.startswith('#')\n                ]\n\n        return analysis\n\n    async def _analyze_python_file(self, py_file: Path) -&gt; Dict[str, Any]:\n        \"\"\"Analysiert Python-Datei.\"\"\"\n\n        with open(py_file, 'r') as f:\n            content = f.read()\n\n        component_info = {\n            'file': str(py_file),\n            'classes': [],\n            'functions': [],\n            'imports': [],\n            'ai_frameworks': []\n        }\n\n        # Einfache Analyse (in Realit\u00e4t w\u00fcrde man AST verwenden)\n        lines = content.split('\\n')\n\n        for line in lines:\n            line = line.strip()\n\n            if line.startswith('class '):\n                class_name = line.split('class ')[1].split('(')[0].split(':')[0]\n                component_info['classes'].append(class_name)\n\n            elif line.startswith('def '):\n                func_name = line.split('def ')[1].split('(')[0]\n                component_info['functions'].append(func_name)\n\n            elif line.startswith('import ') or line.startswith('from '):\n                component_info['imports'].append(line)\n\n                # AI-Frameworks erkennen\n                if any(fw in line for fw in ['tensorflow', 'torch', 'sklearn', 'transformers']):\n                    component_info['ai_frameworks'].append(line)\n\n        return component_info\n\n    async def create_migration_plan(self, analysis: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Erstellt Migration-Plan basierend auf System-Analyse.\"\"\"\n\n        plan = {\n            'agents_to_create': [],\n            'data_migration_tasks': [],\n            'configuration_changes': [],\n            'manual_steps': []\n        }\n\n        # Agents basierend auf Komponenten erstellen\n        for component in analysis['components']:\n            if any('AI' in cls or 'Agent' in cls or 'Bot' in cls for cls in component['classes']):\n                agent_plan = {\n                    'name': f\"Migrated {component['file']}\",\n                    'type': 'specialist',\n                    'source_file': component['file'],\n                    'capabilities': self._infer_capabilities(component)\n                }\n                plan['agents_to_create'].append(agent_plan)\n\n        # Daten-Migration-Tasks\n        for data_source in analysis['data_sources']:\n            if data_source['type'] == 'json_config':\n                plan['data_migration_tasks'].append({\n                    'type': 'config_migration',\n                    'source': data_source['file'],\n                    'target': f\"keiko/config/{Path(data_source['file']).name}\"\n                })\n\n        # Manuelle Schritte f\u00fcr komplexe Komponenten\n        if analysis['ai_frameworks']:\n            plan['manual_steps'].append(\n                \"Review AI framework dependencies and adapt to Keiko's architecture\"\n            )\n\n        return plan\n\n    def _infer_capabilities(self, component: Dict[str, Any]) -&gt; List[str]:\n        \"\"\"Leitet Capabilities aus Komponenten-Analyse ab.\"\"\"\n\n        capabilities = []\n\n        # Basierend auf Imports\n        for import_line in component['imports']:\n            if 'requests' in import_line or 'urllib' in import_line:\n                capabilities.append('web_requests')\n            elif 'json' in import_line:\n                capabilities.append('data_processing')\n            elif 'sqlite' in import_line or 'psycopg' in import_line:\n                capabilities.append('database_access')\n\n        # Basierend auf Funktionen\n        for func in component['functions']:\n            if 'process' in func.lower():\n                capabilities.append('data_processing')\n            elif 'generate' in func.lower():\n                capabilities.append('content_generation')\n            elif 'analyze' in func.lower():\n                capabilities.append('analysis')\n\n        return list(set(capabilities))\n</code></pre>"},{"location":"migration/from-legacy/#migration-utilities","title":"\ud83d\udd27 Migration-Utilities","text":""},{"location":"migration/from-legacy/#migration-validator","title":"Migration-Validator","text":"<pre><code># migration/validator.py\nclass MigrationValidator:\n    \"\"\"Validiert Migration-Ergebnisse.\"\"\"\n\n    async def validate_migration(self, migration_result: MigrationResult) -&gt; ValidationResult:\n        \"\"\"Validiert vollst\u00e4ndige Migration.\"\"\"\n\n        validation = ValidationResult()\n\n        # Daten-Integrit\u00e4t pr\u00fcfen\n        data_validation = await self._validate_data_integrity(migration_result)\n        validation.add_check('data_integrity', data_validation)\n\n        # Funktionalit\u00e4t pr\u00fcfen\n        functionality_validation = await self._validate_functionality(migration_result)\n        validation.add_check('functionality', functionality_validation)\n\n        # Performance pr\u00fcfen\n        performance_validation = await self._validate_performance(migration_result)\n        validation.add_check('performance', performance_validation)\n\n        return validation\n\n    async def _validate_data_integrity(self, migration_result: MigrationResult) -&gt; bool:\n        \"\"\"Pr\u00fcft Daten-Integrit\u00e4t nach Migration.\"\"\"\n\n        # Anzahl Datens\u00e4tze vergleichen\n        source_counts = await self._get_source_record_counts()\n        target_counts = await self._get_target_record_counts()\n\n        for table, source_count in source_counts.items():\n            target_count = target_counts.get(table, 0)\n\n            if abs(source_count - target_count) &gt; source_count * 0.01:  # 1% Toleranz\n                return False\n\n        return True\n\n    async def _validate_functionality(self, migration_result: MigrationResult) -&gt; bool:\n        \"\"\"Pr\u00fcft Funktionalit\u00e4t nach Migration.\"\"\"\n\n        # Test-Tasks ausf\u00fchren\n        test_tasks = [\n            {'type': 'text_processing', 'params': {'text': 'Test'}},\n            {'type': 'data_analysis', 'params': {'data': [1, 2, 3]}},\n            {'type': 'conversation', 'params': {'message': 'Hello'}}\n        ]\n\n        for test_task in test_tasks:\n            try:\n                result = await self._execute_test_task(test_task)\n                if not result.success:\n                    return False\n            except Exception:\n                return False\n\n        return True\n</code></pre> <p>Legacy-Migration-Hinweise</p> <ul> <li>Legacy-Migrationen sind komplex und erfordern oft manuelle Anpassungen</li> <li>Testen Sie die Migration ausf\u00fchrlich in einer Staging-Umgebung</li> <li>Dokumentieren Sie alle manuellen Schritte f\u00fcr zuk\u00fcnftige Referenz</li> </ul> <p>Best Practices</p> <ul> <li>Analysieren Sie das Legacy-System gr\u00fcndlich vor der Migration</li> <li>Erstellen Sie einen detaillierten Migration-Plan</li> <li>Implementieren Sie umfassende Validierung und Tests</li> <li>Behalten Sie das Legacy-System als Fallback bei</li> </ul>"},{"location":"migration/upgrade-guide/","title":"\ud83d\ude80 Upgrade Guide","text":"<p>Schritt-f\u00fcr-Schritt-Anleitung f\u00fcr das Upgrade auf Keiko Personal Assistant v2.0.</p>"},{"location":"migration/upgrade-guide/#pre-upgrade-checklist","title":"\ud83d\udccb Pre-Upgrade Checklist","text":""},{"location":"migration/upgrade-guide/#system-anforderungen-prufen","title":"System-Anforderungen pr\u00fcfen","text":"<pre><code># Python-Version pr\u00fcfen (3.9+ erforderlich)\npython --version\n\n# Verf\u00fcgbarer Speicher pr\u00fcfen (mindestens 4GB RAM)\nfree -h\n\n# Disk-Space pr\u00fcfen (mindestens 10GB frei)\ndf -h\n\n# PostgreSQL-Version pr\u00fcfen (13+ erforderlich)\npsql --version\n\n# Redis-Version pr\u00fcfen (6+ erforderlich)\nredis-server --version\n</code></pre>"},{"location":"migration/upgrade-guide/#backup-erstellen","title":"Backup erstellen","text":"<pre><code># Vollst\u00e4ndiges System-Backup\n./scripts/create-full-backup.sh\n\n# Database-Backup\npg_dump -U keiko_user keiko_db &gt; backup/keiko_db_$(date +%Y%m%d_%H%M%S).sql\n\n# Konfiguration-Backup\ntar -czf backup/config_$(date +%Y%m%d_%H%M%S).tar.gz /opt/keiko/config\n\n# Daten-Backup\ntar -czf backup/data_$(date +%Y%m%d_%H%M%S).tar.gz /opt/keiko/data\n\n# Backup-Integrit\u00e4t pr\u00fcfen\n./scripts/verify-backup.sh backup/\n</code></pre>"},{"location":"migration/upgrade-guide/#upgrade-prozess","title":"\ud83d\udd04 Upgrade-Prozess","text":""},{"location":"migration/upgrade-guide/#schritt-1-vorbereitung","title":"Schritt 1: Vorbereitung","text":"<pre><code># 1. Wartungsmodus aktivieren\necho \"Keiko wird gewartet. Bitte versuchen Sie es sp\u00e4ter erneut.\" &gt; /var/www/maintenance.html\n\n# 2. Services stoppen\nsystemctl stop keiko-api\nsystemctl stop keiko-workers\nsystemctl stop keiko-scheduler\n\n# 3. Aktuelle Version sichern\ncp -r /opt/keiko /opt/keiko-v1-backup\n\n# 4. Upgrade-Tools herunterladen\ncurl -L https://github.com/oscharko/keiko-upgrade/releases/latest/download/upgrade-v2.tar.gz -o upgrade-v2.tar.gz\ntar -xzf upgrade-v2.tar.gz\ncd keiko-upgrade-v2\n</code></pre>"},{"location":"migration/upgrade-guide/#schritt-2-dependencies-aktualisieren","title":"Schritt 2: Dependencies aktualisieren","text":"<pre><code># Python-Dependencies aktualisieren\npip install --upgrade pip\npip install -r requirements-v2.txt\n\n# System-Dependencies pr\u00fcfen\n./scripts/check-system-deps.sh\n\n# Neue Dependencies installieren\nsudo apt-get update\nsudo apt-get install -y python3.9 python3.9-dev python3.9-venv\n\n# Virtual Environment neu erstellen\npython3.9 -m venv /opt/keiko/venv\nsource /opt/keiko/venv/bin/activate\npip install -r requirements-v2.txt\n</code></pre>"},{"location":"migration/upgrade-guide/#schritt-3-database-migration","title":"Schritt 3: Database-Migration","text":"<pre><code># Database-Migration-Script ausf\u00fchren\n./scripts/migrate-database.sh --from-version=1.9 --to-version=2.0\n\n# Migration-Log pr\u00fcfen\ntail -f /var/log/keiko/migration.log\n\n# Database-Schema validieren\n./scripts/validate-schema.sh --version=2.0\n</code></pre> <p>Database-Migration-Details:</p> <pre><code>-- Automatische Schema-Updates\nBEGIN;\n\n-- Neue Spalten hinzuf\u00fcgen\nALTER TABLE users ADD COLUMN IF NOT EXISTS role VARCHAR(50) DEFAULT 'user';\nALTER TABLE users ADD COLUMN IF NOT EXISTS preferences JSONB DEFAULT '{}';\nALTER TABLE users ADD COLUMN IF NOT EXISTS last_login TIMESTAMP;\n\nALTER TABLE agents ADD COLUMN IF NOT EXISTS capabilities JSONB DEFAULT '[]';\nALTER TABLE agents ADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}';\nALTER TABLE agents ADD COLUMN IF NOT EXISTS version VARCHAR(20) DEFAULT '2.0.0';\n\nALTER TABLE tasks ADD COLUMN IF NOT EXISTS priority VARCHAR(20) DEFAULT 'normal';\nALTER TABLE tasks ADD COLUMN IF NOT EXISTS timeout_seconds INTEGER DEFAULT 300;\nALTER TABLE tasks ADD COLUMN IF NOT EXISTS retry_count INTEGER DEFAULT 0;\n\n-- Neue Tabellen erstellen\nCREATE TABLE IF NOT EXISTS mcp_servers (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(100) UNIQUE NOT NULL,\n    base_url VARCHAR(500) NOT NULL,\n    auth_config JSONB DEFAULT '{}',\n    status VARCHAR(20) DEFAULT 'inactive',\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS audit_logs (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id UUID REFERENCES users(id),\n    action VARCHAR(100) NOT NULL,\n    resource_type VARCHAR(50) NOT NULL,\n    resource_id VARCHAR(100),\n    details JSONB DEFAULT '{}',\n    ip_address INET,\n    user_agent TEXT,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Indizes erstellen\nCREATE INDEX IF NOT EXISTS idx_users_role ON users(role);\nCREATE INDEX IF NOT EXISTS idx_users_last_login ON users(last_login);\nCREATE INDEX IF NOT EXISTS idx_agents_capabilities ON agents USING GIN(capabilities);\nCREATE INDEX IF NOT EXISTS idx_tasks_priority ON tasks(priority);\nCREATE INDEX IF NOT EXISTS idx_audit_logs_user_action ON audit_logs(user_id, action);\n\n-- Daten migrieren\nUPDATE agents SET capabilities = '[\"text_processing\"]' WHERE type = 'nlp' AND capabilities = '[]';\nUPDATE agents SET capabilities = '[\"image_generation\"]' WHERE type = 'image' AND capabilities = '[]';\nUPDATE tasks SET priority = 'high' WHERE created_at &gt; NOW() - INTERVAL '1 hour';\n\nCOMMIT;\n</code></pre>"},{"location":"migration/upgrade-guide/#schritt-4-konfiguration-migrieren","title":"Schritt 4: Konfiguration migrieren","text":"<pre><code># Konfiguration-Migration\n./scripts/migrate-config.sh --source=/opt/keiko-v1-backup/config --target=/opt/keiko/config\n\n# Neue Konfigurationsdateien erstellen\n./scripts/generate-v2-config.sh\n</code></pre> <p>Konfiguration-Migration-Script:</p> <pre><code>#!/usr/bin/env python3\n# scripts/migrate-config.py\n\nimport yaml\nimport json\nfrom pathlib import Path\n\ndef migrate_main_config():\n    \"\"\"Migriert Hauptkonfiguration von v1 zu v2.\"\"\"\n\n    # v1-Konfiguration laden\n    with open('/opt/keiko-v1-backup/config/config.yml', 'r') as f:\n        v1_config = yaml.safe_load(f)\n\n    # v2-Konfiguration erstellen\n    v2_config = {\n        'version': '2.0.0',\n        'environment': v1_config.get('env', 'production'),\n\n        'server': {\n            'host': v1_config.get('host', '0.0.0.0'),\n            'port': v1_config.get('port', 8000),\n            'workers': v1_config.get('workers', 4),\n            'reload': False\n        },\n\n        'database': {\n            'default': {\n                'url': v1_config.get('database_url'),\n                'pool_size': v1_config.get('db_pool_size', 20),\n                'max_overflow': 30,\n                'pool_timeout': 30,\n                'pool_recycle': 3600\n            }\n        },\n\n        'redis': {\n            'url': v1_config.get('redis_url', 'redis://localhost:6379'),\n            'max_connections': 20\n        },\n\n        'logging': {\n            'level': v1_config.get('log_level', 'INFO'),\n            'format': 'json',\n            'structured': True,\n            'file_path': '/var/log/keiko/app.log'\n        },\n\n        'monitoring': {\n            'enabled': True,\n            'metrics_port': 9090,\n            'health_check_interval': 30\n        },\n\n        'security': {\n            'jwt_secret': v1_config.get('secret_key'),\n            'jwt_expiration': 3600,\n            'password_min_length': 8,\n            'session_timeout': 3600\n        }\n    }\n\n    # v2-Konfiguration speichern\n    with open('/opt/keiko/config/config.yml', 'w') as f:\n        yaml.dump(v2_config, f, default_flow_style=False)\n\ndef migrate_agent_configs():\n    \"\"\"Migriert Agent-Konfigurationen.\"\"\"\n\n    v1_agents_file = '/opt/keiko-v1-backup/config/agents.yml'\n    v2_agents_dir = Path('/opt/keiko/config/agents')\n    v2_agents_dir.mkdir(exist_ok=True)\n\n    with open(v1_agents_file, 'r') as f:\n        v1_agents = yaml.safe_load(f)\n\n    for agent in v1_agents.get('agents', []):\n        v2_agent_config = {\n            'name': agent['name'],\n            'type': 'specialist',\n            'capabilities': extract_capabilities(agent),\n            'configuration': {\n                'timeout_seconds': agent.get('timeout', 300),\n                'max_concurrent_tasks': agent.get('max_tasks', 1),\n                'retry_policy': {\n                    'max_retries': 3,\n                    'retry_delay': 1.0\n                }\n            },\n            'external_config': agent.get('config', {})\n        }\n\n        # Agent-Konfiguration speichern\n        agent_file = v2_agents_dir / f\"{agent['name']}.yml\"\n        with open(agent_file, 'w') as f:\n            yaml.dump(v2_agent_config, f, default_flow_style=False)\n\ndef extract_capabilities(v1_agent):\n    \"\"\"Extrahiert Capabilities aus v1-Agent.\"\"\"\n    capabilities = []\n\n    agent_type = v1_agent.get('type', 'generic')\n    if agent_type == 'nlp':\n        capabilities.extend(['text_processing', 'summarization'])\n    elif agent_type == 'image':\n        capabilities.extend(['image_generation', 'image_editing'])\n    elif agent_type == 'data':\n        capabilities.extend(['data_analysis', 'data_processing'])\n\n    return capabilities\n\nif __name__ == '__main__':\n    migrate_main_config()\n    migrate_agent_configs()\n    print(\"Konfiguration erfolgreich migriert\")\n</code></pre>"},{"location":"migration/upgrade-guide/#schritt-5-code-updates","title":"Schritt 5: Code-Updates","text":"<pre><code># Neue Keiko v2.0 Installation\ngit clone https://github.com/oscharko/keiko-personal-assistant.git /opt/keiko-v2\ncd /opt/keiko-v2\ngit checkout v2.0.0\n\n# Konfiguration kopieren\ncp -r /opt/keiko/config /opt/keiko-v2/\n\n# Custom-Code migrieren (falls vorhanden)\n./scripts/migrate-custom-code.sh --source=/opt/keiko-v1-backup/custom --target=/opt/keiko-v2/custom\n</code></pre>"},{"location":"migration/upgrade-guide/#schritt-6-services-konfigurieren","title":"Schritt 6: Services konfigurieren","text":"<pre><code># Neue Systemd-Services installieren\ncp scripts/systemd/*.service /etc/systemd/system/\nsystemctl daemon-reload\n\n# Services aktivieren\nsystemctl enable keiko-api-v2\nsystemctl enable keiko-workers-v2\nsystemctl enable keiko-scheduler-v2\n\n# Nginx-Konfiguration aktualisieren\ncp scripts/nginx/keiko-v2.conf /etc/nginx/sites-available/\nln -sf /etc/nginx/sites-available/keiko-v2.conf /etc/nginx/sites-enabled/\nnginx -t &amp;&amp; systemctl reload nginx\n</code></pre>"},{"location":"migration/upgrade-guide/#schritt-7-validierung-und-tests","title":"Schritt 7: Validierung und Tests","text":"<pre><code># Services starten\nsystemctl start keiko-api-v2\nsystemctl start keiko-workers-v2\nsystemctl start keiko-scheduler-v2\n\n# Health-Check\ncurl http://localhost:8000/health\n\n# Funktionalit\u00e4ts-Tests\n./scripts/run-upgrade-tests.sh\n\n# Performance-Tests\n./scripts/run-performance-tests.sh\n\n# User-Acceptance-Tests\n./scripts/run-acceptance-tests.sh\n</code></pre>"},{"location":"migration/upgrade-guide/#test-szenarien","title":"\ud83e\uddea Test-Szenarien","text":""},{"location":"migration/upgrade-guide/#funktionalitats-tests","title":"Funktionalit\u00e4ts-Tests","text":"<pre><code># tests/upgrade_tests.py\nimport asyncio\nimport pytest\nfrom keiko.client import KeikoClient\n\n@pytest.mark.asyncio\nasync def test_agent_creation():\n    \"\"\"Testet Agent-Erstellung nach Upgrade.\"\"\"\n\n    client = KeikoClient(\"http://localhost:8000\")\n\n    # Agent erstellen\n    agent_config = {\n        \"name\": \"Test Agent\",\n        \"type\": \"specialist\",\n        \"capabilities\": [\"text_processing\"]\n    }\n\n    agent = await client.create_agent(agent_config)\n    assert agent[\"id\"] is not None\n    assert agent[\"name\"] == \"Test Agent\"\n\n@pytest.mark.asyncio\nasync def test_task_execution():\n    \"\"\"Testet Task-Ausf\u00fchrung nach Upgrade.\"\"\"\n\n    client = KeikoClient(\"http://localhost:8000\")\n\n    # Task ausf\u00fchren\n    task_request = {\n        \"task_type\": \"text_processing\",\n        \"parameters\": {\"text\": \"Hello World\"}\n    }\n\n    result = await client.execute_task(\"agent-id\", task_request)\n    assert result[\"success\"] is True\n\n@pytest.mark.asyncio\nasync def test_mcp_integration():\n    \"\"\"Testet neue MCP-Integration.\"\"\"\n\n    client = KeikoClient(\"http://localhost:8000\")\n\n    # MCP-Server registrieren\n    mcp_config = {\n        \"server_name\": \"test-server\",\n        \"base_url\": \"http://localhost:8080\",\n        \"timeout_seconds\": 30.0\n    }\n\n    server_id = await client.register_mcp_server(mcp_config)\n    assert server_id is not None\n</code></pre>"},{"location":"migration/upgrade-guide/#performance-tests","title":"Performance-Tests","text":"<pre><code># Performance-Benchmark\n./scripts/benchmark.sh --duration=300 --concurrent=50\n\n# Erwartete Ergebnisse:\n# - Response Time: &lt; 200ms (95th percentile)\n# - Throughput: &gt; 1000 requests/second\n# - Error Rate: &lt; 0.1%\n# - Memory Usage: &lt; 2GB\n</code></pre>"},{"location":"migration/upgrade-guide/#rollback-verfahren","title":"\ud83d\udd04 Rollback-Verfahren","text":""},{"location":"migration/upgrade-guide/#automatischer-rollback","title":"Automatischer Rollback","text":"<pre><code># Rollback-Script ausf\u00fchren\n./scripts/rollback-upgrade.sh --to-version=1.9\n\n# Schritte:\n# 1. v2.0 Services stoppen\n# 2. Database-Backup wiederherstellen\n# 3. v1.x Konfiguration wiederherstellen\n# 4. v1.x Code wiederherstellen\n# 5. v1.x Services starten\n# 6. Funktionalit\u00e4t validieren\n</code></pre>"},{"location":"migration/upgrade-guide/#manueller-rollback","title":"Manueller Rollback","text":"<pre><code># 1. Services stoppen\nsystemctl stop keiko-api-v2 keiko-workers-v2 keiko-scheduler-v2\n\n# 2. Database wiederherstellen\npsql -U postgres -d keiko_db &lt; backup/keiko_db_backup.sql\n\n# 3. Code wiederherstellen\nrm -rf /opt/keiko\nmv /opt/keiko-v1-backup /opt/keiko\n\n# 4. v1.x Services starten\nsystemctl start keiko-api keiko-workers keiko-scheduler\n\n# 5. Nginx-Konfiguration zur\u00fccksetzen\nln -sf /etc/nginx/sites-available/keiko-v1.conf /etc/nginx/sites-enabled/keiko.conf\nsystemctl reload nginx\n</code></pre>"},{"location":"migration/upgrade-guide/#post-upgrade-monitoring","title":"\ud83d\udcca Post-Upgrade-Monitoring","text":""},{"location":"migration/upgrade-guide/#monitoring-setup","title":"Monitoring-Setup","text":"<pre><code># Prometheus-Metriken aktivieren\ncurl http://localhost:9090/metrics\n\n# Grafana-Dashboard importieren\n./scripts/import-grafana-dashboard.sh dashboards/keiko-v2-dashboard.json\n\n# Alerting-Regeln konfigurieren\ncp monitoring/alerts/keiko-v2-alerts.yml /etc/prometheus/rules/\n</code></pre>"},{"location":"migration/upgrade-guide/#key-metriken-uberwachen","title":"Key-Metriken \u00fcberwachen","text":"<ul> <li>Response Time: &lt; 200ms (95<sup>th</sup> percentile)</li> <li>Error Rate: &lt; 0.1%</li> <li>Memory Usage: &lt; 2GB</li> <li>CPU Usage: &lt; 70%</li> <li>Database Connections: &lt; 80% Pool-Auslastung</li> <li>Task Success Rate: &gt; 99%</li> </ul>"},{"location":"migration/upgrade-guide/#post-upgrade-checklist","title":"\ud83d\udccb Post-Upgrade-Checklist","text":""},{"location":"migration/upgrade-guide/#sofort-nach-upgrade","title":"Sofort nach Upgrade","text":"<ul> <li> Health-Checks bestanden</li> <li> Funktionalit\u00e4ts-Tests erfolgreich</li> <li> Performance-Tests bestanden</li> <li> User-Login funktioniert</li> <li> Agent-Erstellung m\u00f6glich</li> <li> Task-Ausf\u00fchrung erfolgreich</li> </ul>"},{"location":"migration/upgrade-guide/#24-stunden-nach-upgrade","title":"24 Stunden nach Upgrade","text":"<ul> <li> Monitoring-Metriken normal</li> <li> Error-Logs \u00fcberpr\u00fcft</li> <li> Performance stabil</li> <li> User-Feedback positiv</li> <li> Backup-Strategie aktualisiert</li> </ul>"},{"location":"migration/upgrade-guide/#1-woche-nach-upgrade","title":"1 Woche nach Upgrade","text":"<ul> <li> Langzeit-Performance stabil</li> <li> Memory-Leaks ausgeschlossen</li> <li> User-Training abgeschlossen</li> <li> Dokumentation aktualisiert</li> <li> v1.x Backup archiviert</li> </ul> <p>Upgrade erfolgreich</p> <p>Herzlichen Gl\u00fcckwunsch! Sie haben erfolgreich auf Keiko Personal Assistant v2.0 upgegraded.</p> <p>Support-Hinweis</p> <p>Bei Problemen nach dem Upgrade wenden Sie sich an das Support-Team oder erstellen Sie ein Issue im GitHub-Repository.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>L\u00f6sungen f\u00fcr h\u00e4ufige Probleme und Debugging-Strategien f\u00fcr das KEI-Agent Python SDK.</p>"},{"location":"troubleshooting/#haufige-probleme","title":"\ud83d\udea8 H\u00e4ufige Probleme","text":""},{"location":"troubleshooting/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"troubleshooting/#problem-modulenotfounderror","title":"Problem: ModuleNotFoundError","text":"<pre><code>ModuleNotFoundError: No module named 'kei_agent'\n</code></pre> <p>Ursachen &amp; L\u00f6sungen:</p> <ol> <li> <p>SDK nicht installiert <pre><code>pip install kei-agent-sdk\n</code></pre></p> </li> <li> <p>Falsche virtuelle Umgebung <pre><code># Virtuelle Umgebung aktivieren\nsource venv/bin/activate  # Linux/macOS\nvenv\\Scripts\\activate     # Windows\n\n# SDK installieren\npip install kei-agent-sdk\n</code></pre></p> </li> <li> <p>Python-Path-Problem <pre><code>import sys\nprint(sys.path)  # Pr\u00fcfe Python-Path\n\n# Tempor\u00e4rer Fix\nsys.path.append('/path/to/kei-agent')\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#problem-version-konflikte","title":"Problem: Version-Konflikte","text":"<pre><code>ERROR: pip's dependency resolver does not currently consider all the ways...\n</code></pre> <p>L\u00f6sungen:</p> <ol> <li> <p>Dependency-Resolver verwenden <pre><code>pip install --use-feature=2020-resolver kei-agent-sdk\n</code></pre></p> </li> <li> <p>Pip aktualisieren <pre><code>pip install --upgrade pip\npip install kei-agent-sdk\n</code></pre></p> </li> <li> <p>Saubere Installation <pre><code>pip uninstall kei-agent-sdk\npip cache purge\npip install kei-agent-sdk\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#client-initialisierung","title":"Client-Initialisierung","text":""},{"location":"troubleshooting/#problem-client-nicht-initialisiert","title":"Problem: Client nicht initialisiert","text":"<pre><code>RuntimeError: Client nicht initialisiert. Rufen Sie initialize() auf oder verwenden Sie async context manager.\n</code></pre> <p>L\u00f6sung:</p> <pre><code># \u2705 Empfohlen: Async Context Manager\nasync with UnifiedKeiAgentClient(config=config) as client:\n    result = await client.plan_task(\"objective\")\n\n# \u2705 Alternative: Manuelle Initialisierung\nclient = UnifiedKeiAgentClient(config=config)\ntry:\n    await client.initialize()\n    result = await client.plan_task(\"objective\")\nfinally:\n    await client.close()\n</code></pre>"},{"location":"troubleshooting/#problem-ungultige-konfiguration","title":"Problem: Ung\u00fcltige Konfiguration","text":"<pre><code>ValidationError: Ung\u00fcltige Sicherheitskonfiguration: API Token ist erforderlich f\u00fcr Bearer Auth\n</code></pre> <p>L\u00f6sung:</p> <pre><code># \u2705 Vollst\u00e4ndige Konfiguration\nconfig = AgentClientConfig(\n    base_url=\"https://api.kei-framework.com\",\n    api_token=\"your-api-token\",  # Erforderlich!\n    agent_id=\"unique-agent-id\"   # Erforderlich!\n)\n\n# \u2705 Umgebungsvariablen verwenden\nimport os\nconfig = AgentClientConfig(\n    base_url=os.getenv(\"KEI_API_URL\"),\n    api_token=os.getenv(\"KEI_API_TOKEN\"),\n    agent_id=os.getenv(\"KEI_AGENT_ID\")\n)\n</code></pre>"},{"location":"troubleshooting/#authentifizierung","title":"Authentifizierung","text":""},{"location":"troubleshooting/#problem-401-unauthorized","title":"Problem: 401 Unauthorized","text":"<pre><code>SecurityError: Authentifizierung fehlgeschlagen: 401 Unauthorized\n</code></pre> <p>Debugging-Schritte:</p> <ol> <li> <p>Token validieren <pre><code># Token-Format pr\u00fcfen\nprint(f\"Token length: {len(api_token)}\")\nprint(f\"Token starts with: {api_token[:10]}...\")\n\n# Token-G\u00fcltigkeit testen\nimport httpx\nresponse = httpx.get(\n    \"https://api.kei-framework.com/auth/validate\",\n    headers={\"Authorization\": f\"Bearer {api_token}\"}\n)\nprint(f\"Token validation: {response.status_code}\")\n</code></pre></p> </li> <li> <p>OIDC-Konfiguration pr\u00fcfen <pre><code># OIDC-Endpunkte testen\nimport httpx\nresponse = httpx.get(f\"{oidc_issuer}/.well-known/openid_configuration\")\nprint(f\"OIDC discovery: {response.status_code}\")\n</code></pre></p> </li> <li> <p>mTLS-Zertifikate pr\u00fcfen <pre><code># Zertifikat-G\u00fcltigkeit pr\u00fcfen\nopenssl x509 -in client.crt -text -noout\nopenssl rsa -in client.key -check\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#problem-token-refresh-fehlgeschlagen","title":"Problem: Token-Refresh fehlgeschlagen","text":"<pre><code>SecurityError: OIDC Token-Request fehlgeschlagen: 400 Bad Request\n</code></pre> <p>L\u00f6sungen:</p> <ol> <li> <p>OIDC-Konfiguration validieren <pre><code>security_config = SecurityConfig(\n    auth_type=AuthType.OIDC,\n    oidc_issuer=\"https://auth.example.com\",  # Korrekte URL\n    oidc_client_id=\"valid-client-id\",\n    oidc_client_secret=\"valid-client-secret\",\n    oidc_scope=\"openid profile kei-agent\"    # Korrekte Scopes\n)\n</code></pre></p> </li> <li> <p>Netzwerk-Konnektivit\u00e4t pr\u00fcfen <pre><code>import httpx\nasync with httpx.AsyncClient() as client:\n    response = await client.get(oidc_issuer)\n    print(f\"OIDC issuer reachable: {response.status_code}\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#protokoll-probleme","title":"Protokoll-Probleme","text":""},{"location":"troubleshooting/#problem-protokoll-nicht-verfugbar","title":"Problem: Protokoll nicht verf\u00fcgbar","text":"<pre><code>ProtocolError: Stream-Protokoll nicht verf\u00fcgbar\n</code></pre> <p>Debugging:</p> <pre><code># Verf\u00fcgbare Protokolle pr\u00fcfen\nclient = UnifiedKeiAgentClient(config=config)\nprotocols = client.get_available_protocols()\nprint(f\"Available protocols: {protocols}\")\n\n# Protokoll-Konfiguration pr\u00fcfen\ninfo = client.get_client_info()\nprint(f\"Protocol config: {info['protocol_config']}\")\n\n# Spezifisches Protokoll pr\u00fcfen\nif client.is_protocol_available(ProtocolType.STREAM):\n    print(\"Stream protocol available\")\nelse:\n    print(\"Stream protocol not available\")\n</code></pre> <p>L\u00f6sung:</p> <pre><code># Protokoll explizit aktivieren\nprotocol_config = ProtocolConfig(\n    stream_enabled=True,  # Explizit aktivieren\n    auto_protocol_selection=True\n)\n\nclient = UnifiedKeiAgentClient(\n    config=config,\n    protocol_config=protocol_config\n)\n</code></pre>"},{"location":"troubleshooting/#problem-websocket-verbindung-fehlgeschlagen","title":"Problem: WebSocket-Verbindung fehlgeschlagen","text":"<pre><code>ProtocolError: Stream-Verbindung fehlgeschlagen: Connection refused\n</code></pre> <p>Debugging-Schritte:</p> <ol> <li> <p>WebSocket-Endpunkt pr\u00fcfen <pre><code>import websockets\n\nasync def test_websocket():\n    try:\n        async with websockets.connect(\"wss://api.kei-framework.com/ws\") as ws:\n            print(\"WebSocket connection successful\")\n    except Exception as e:\n        print(f\"WebSocket connection failed: {e}\")\n\nasyncio.run(test_websocket())\n</code></pre></p> </li> <li> <p>Firewall/Proxy pr\u00fcfen <pre><code># Netzwerk-Konnektivit\u00e4t testen\ntelnet api.kei-framework.com 443\ncurl -I https://api.kei-framework.com/ws\n</code></pre></p> </li> <li> <p>SSL-Zertifikate pr\u00fcfen <pre><code>openssl s_client -connect api.kei-framework.com:443\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#performance-probleme","title":"Performance-Probleme","text":""},{"location":"troubleshooting/#problem-langsame-responses","title":"Problem: Langsame Responses","text":"<pre><code># Response-Zeit messen\nimport time\n\nstart_time = time.time()\nresult = await client.plan_task(\"objective\")\nduration = time.time() - start_time\nprint(f\"Response time: {duration:.2f}s\")\n</code></pre> <p>Optimierungen:</p> <ol> <li> <p>Timeout anpassen <pre><code>config = AgentClientConfig(\n    base_url=\"https://api.kei-framework.com\",\n    api_token=\"your-token\",\n    agent_id=\"agent\",\n    timeout=60  # Erh\u00f6hter Timeout\n)\n</code></pre></p> </li> <li> <p>Connection Pooling optimieren <pre><code># Wird automatisch vom SDK verwaltet\n# Bei Bedarf Client-Instanz wiederverwenden\n</code></pre></p> </li> <li> <p>Protokoll-Auswahl optimieren <pre><code># F\u00fcr schnelle Operationen RPC verwenden\nresult = await client.execute_agent_operation(\n    \"fast_operation\",\n    data,\n    protocol=ProtocolType.RPC\n)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#problem-memory-leaks","title":"Problem: Memory Leaks","text":"<pre><code>import psutil\nimport gc\n\ndef monitor_memory():\n    \"\"\"Memory-Usage \u00fcberwachen.\"\"\"\n    process = psutil.Process()\n    memory_mb = process.memory_info().rss / 1024 / 1024\n    print(f\"Memory usage: {memory_mb:.2f} MB\")\n\n    # Garbage Collection forcieren\n    gc.collect()\n\n    memory_after_gc = process.memory_info().rss / 1024 / 1024\n    print(f\"Memory after GC: {memory_after_gc:.2f} MB\")\n\n# Vor und nach Client-Operationen aufrufen\nmonitor_memory()\n</code></pre> <p>L\u00f6sungen:</p> <ol> <li> <p>Async Context Manager verwenden <pre><code># \u2705 Automatisches Cleanup\nasync with UnifiedKeiAgentClient(config=config) as client:\n    result = await client.plan_task(\"objective\")\n</code></pre></p> </li> <li> <p>Explizites Cleanup <pre><code>client = UnifiedKeiAgentClient(config=config)\ntry:\n    await client.initialize()\n    result = await client.plan_task(\"objective\")\nfinally:\n    await client.close()  # Wichtig!\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#debugging-strategien","title":"\ud83d\udd0d Debugging-Strategien","text":""},{"location":"troubleshooting/#logging-aktivieren","title":"Logging aktivieren","text":"<pre><code>import logging\nfrom kei_agent import configure_logging\n\n# Debug-Logging aktivieren\nconfigure_logging(\n    level=logging.DEBUG,\n    enable_structured=True,\n    enable_console=True\n)\n\n# Spezifische Logger konfigurieren\nlogging.getLogger(\"kei_agent\").setLevel(logging.DEBUG)\nlogging.getLogger(\"httpx\").setLevel(logging.DEBUG)\nlogging.getLogger(\"websockets\").setLevel(logging.DEBUG)\n</code></pre>"},{"location":"troubleshooting/#requestresponse-debugging","title":"Request/Response Debugging","text":"<pre><code>import httpx\n\n# HTTP-Client mit Logging\nclass DebugHTTPClient:\n    def __init__(self):\n        self.client = httpx.AsyncClient()\n\n    async def request(self, method, url, **kwargs):\n        print(f\"\ud83d\udd0d {method} {url}\")\n        if 'json' in kwargs:\n            print(f\"\ud83d\udce4 Request: {kwargs['json']}\")\n\n        response = await self.client.request(method, url, **kwargs)\n\n        print(f\"\ud83d\udce5 Response: {response.status_code}\")\n        if response.headers.get('content-type', '').startswith('application/json'):\n            print(f\"\ud83d\udcc4 Body: {response.json()}\")\n\n        return response\n</code></pre>"},{"location":"troubleshooting/#health-check-debugging","title":"Health Check Debugging","text":"<pre><code>from kei_agent import get_health_manager\n\nasync def debug_health_checks():\n    \"\"\"Detailliertes Health Check Debugging.\"\"\"\n\n    health_manager = get_health_manager()\n    summary = await health_manager.run_all_checks()\n\n    print(f\"Overall Status: {summary.overall_status}\")\n    print(f\"Total Checks: {summary.total_checks}\")\n\n    for check in summary.checks:\n        print(f\"\\n--- {check.name} ---\")\n        print(f\"Status: {check.status}\")\n        print(f\"Message: {check.message}\")\n        print(f\"Duration: {check.duration_ms}ms\")\n\n        if check.error:\n            print(f\"Error: {check.error}\")\n\n        if check.details:\n            print(f\"Details: {check.details}\")\n\nasyncio.run(debug_health_checks())\n</code></pre>"},{"location":"troubleshooting/#network-debugging","title":"Network Debugging","text":"<pre><code>import socket\nimport ssl\n\ndef debug_network_connectivity(host: str, port: int = 443):\n    \"\"\"Netzwerk-Konnektivit\u00e4t debuggen.\"\"\"\n\n    try:\n        # TCP-Verbindung testen\n        sock = socket.create_connection((host, port), timeout=10)\n        print(f\"\u2705 TCP connection to {host}:{port} successful\")\n\n        if port == 443:\n            # SSL-Verbindung testen\n            context = ssl.create_default_context()\n            ssl_sock = context.wrap_socket(sock, server_hostname=host)\n            print(f\"\u2705 SSL connection to {host} successful\")\n            print(f\"SSL version: {ssl_sock.version()}\")\n            ssl_sock.close()\n        else:\n            sock.close()\n\n    except socket.timeout:\n        print(f\"\u274c Connection to {host}:{port} timed out\")\n    except socket.gaierror as e:\n        print(f\"\u274c DNS resolution failed for {host}: {e}\")\n    except Exception as e:\n        print(f\"\u274c Connection to {host}:{port} failed: {e}\")\n\n# Testen\ndebug_network_connectivity(\"api.kei-framework.com\")\n</code></pre>"},{"location":"troubleshooting/#diagnostic-tools","title":"\ud83d\udee0\ufe0f Diagnostic Tools","text":""},{"location":"troubleshooting/#sdk-diagnose-script","title":"SDK-Diagnose-Script","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"KEI-Agent SDK Diagnose-Tool.\"\"\"\n\nimport asyncio\nimport sys\nimport traceback\nfrom kei_agent import (\n    UnifiedKeiAgentClient,\n    AgentClientConfig,\n    get_health_manager,\n    get_logger\n)\n\nasync def run_diagnostics():\n    \"\"\"F\u00fchrt umfassende SDK-Diagnose aus.\"\"\"\n\n    print(\"\ud83d\udd0d KEI-Agent SDK Diagnostics\")\n    print(\"=\" * 50)\n\n    # 1. Import-Test\n    try:\n        import kei_agent\n        print(f\"\u2705 SDK Import: Version {kei_agent.__version__}\")\n    except Exception as e:\n        print(f\"\u274c SDK Import failed: {e}\")\n        return False\n\n    # 2. Konfiguration-Test\n    try:\n        config = AgentClientConfig(\n            base_url=\"https://httpbin.org\",  # Test-Endpunkt\n            api_token=\"test-token\",\n            agent_id=\"diagnostic-agent\"\n        )\n        print(\"\u2705 Configuration: Valid\")\n    except Exception as e:\n        print(f\"\u274c Configuration failed: {e}\")\n        return False\n\n    # 3. Client-Erstellung-Test\n    try:\n        client = UnifiedKeiAgentClient(config=config)\n        info = client.get_client_info()\n        print(f\"\u2705 Client Creation: {info['agent_id']}\")\n    except Exception as e:\n        print(f\"\u274c Client creation failed: {e}\")\n        return False\n\n    # 4. Health Manager Test\n    try:\n        health_manager = get_health_manager()\n        print(\"\u2705 Health Manager: Available\")\n    except Exception as e:\n        print(f\"\u274c Health Manager failed: {e}\")\n        return False\n\n    # 5. Logger Test\n    try:\n        logger = get_logger(\"diagnostic\")\n        logger.info(\"Diagnostic test message\")\n        print(\"\u2705 Logger: Working\")\n    except Exception as e:\n        print(f\"\u274c Logger failed: {e}\")\n        return False\n\n    print(\"\\n\ud83c\udf89 All diagnostics passed!\")\n    return True\n\nif __name__ == \"__main__\":\n    try:\n        success = asyncio.run(run_diagnostics())\n        sys.exit(0 if success else 1)\n    except Exception as e:\n        print(f\"\u274c Diagnostic failed with exception: {e}\")\n        traceback.print_exc()\n        sys.exit(1)\n</code></pre>"},{"location":"troubleshooting/#performance-profiling","title":"Performance-Profiling","text":"<pre><code>import cProfile\nimport pstats\nimport asyncio\n\ndef profile_agent_operation():\n    \"\"\"Profiling f\u00fcr Agent-Operationen.\"\"\"\n\n    async def operation():\n        config = AgentClientConfig(\n            base_url=\"https://api.kei-framework.com\",\n            api_token=\"your-token\",\n            agent_id=\"profile-agent\"\n        )\n\n        async with UnifiedKeiAgentClient(config=config) as client:\n            return await client.plan_task(\"Profile test\")\n\n    # Profiling ausf\u00fchren\n    profiler = cProfile.Profile()\n    profiler.enable()\n\n    try:\n        result = asyncio.run(operation())\n    finally:\n        profiler.disable()\n\n    # Ergebnisse anzeigen\n    stats = pstats.Stats(profiler)\n    stats.sort_stats('cumulative')\n    stats.print_stats(20)  # Top 20 Funktionen\n\n# Ausf\u00fchren\nprofile_agent_operation()\n</code></pre> <p>Weitere Troubleshooting-Ressourcen: - H\u00e4ufige Probleme \u2192 - Detaillierte Probleml\u00f6sungen - Debugging \u2192 - Erweiterte Debugging-Techniken - Performance \u2192 - Performance-Optimierung - Security \u2192 - Sicherheits-Troubleshooting</p>"},{"location":"troubleshooting/common-issues/","title":"\ud83d\udd27 Common Issues &amp; Solutions","text":"<p>H\u00e4ufige Probleme und deren L\u00f6sungen bei Keiko Personal Assistant.</p>"},{"location":"troubleshooting/common-issues/#startup-probleme","title":"\ud83d\ude80 Startup-Probleme","text":""},{"location":"troubleshooting/common-issues/#application-startet-nicht","title":"Application startet nicht","text":"<p>Problem: Keiko-Service startet nicht oder st\u00fcrzt sofort ab.</p> <p>Symptome: <pre><code>systemctl status keiko-api\n\u25cf keiko-api.service - Keiko Personal Assistant API\n   Loaded: loaded (/etc/systemd/system/keiko-api.service; enabled)\n   Active: failed (Result: exit-code)\n</code></pre></p> <p>Diagnose: <pre><code># Service-Logs pr\u00fcfen\njournalctl -u keiko-api -f\n\n# Application-Logs pr\u00fcfen\ntail -f /var/log/keiko/app.log\n\n# Konfiguration validieren\n./scripts/validate-config.sh\n</code></pre></p> <p>H\u00e4ufige Ursachen &amp; L\u00f6sungen:</p> <ol> <li> <p>Fehlende Dependencies <pre><code># Python-Dependencies pr\u00fcfen\npip check\n\n# Fehlende Packages installieren\npip install -r requirements.txt\n\n# System-Dependencies pr\u00fcfen\nsudo apt-get install python3-dev postgresql-client redis-tools\n</code></pre></p> </li> <li> <p>Database-Verbindungsfehler <pre><code># Database-Verbindung testen\npsql -h localhost -U keiko_user -d keiko_db -c \"SELECT 1;\"\n\n# Connection-String pr\u00fcfen\necho $DATABASE_URL\n\n# Database-Service starten\nsudo systemctl start postgresql\n</code></pre></p> </li> <li> <p>Port bereits belegt <pre><code># Port-Nutzung pr\u00fcfen\nsudo netstat -tlnp | grep :8000\n\n# Prozess beenden\nsudo kill -9 &lt;PID&gt;\n\n# Alternativen Port konfigurieren\nexport KEIKO_PORT=8001\n</code></pre></p> </li> <li> <p>Berechtigungsprobleme <pre><code># Log-Verzeichnis-Berechtigungen\nsudo chown -R keiko:keiko /var/log/keiko\nsudo chmod 755 /var/log/keiko\n\n# Konfiguration-Berechtigungen\nsudo chown -R keiko:keiko /opt/keiko/config\nsudo chmod 600 /opt/keiko/config/*.yml\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#langsamer-startup","title":"Langsamer Startup","text":"<p>Problem: Application startet sehr langsam (&gt;60 Sekunden).</p> <p>Diagnose: <pre><code># Startup-Zeit messen\ntime systemctl start keiko-api\n\n# Startup-Profiling aktivieren\nexport KEIKO_PROFILE_STARTUP=true\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Database-Connection-Pool optimieren <pre><code># config/database.yml\ndatabase:\n  default:\n    pool_size: 5  # Reduzieren f\u00fcr schnelleren Startup\n    max_overflow: 10\n    pool_timeout: 10\n</code></pre></p> </li> <li> <p>Lazy-Loading aktivieren <pre><code># config/app.py\nLAZY_LOADING = True\nPRELOAD_AGENTS = False\n</code></pre></p> </li> <li> <p>Health-Check-Timeout erh\u00f6hen <pre><code># config/config.yml\nmonitoring:\n  health_check_timeout: 30\n  startup_timeout: 120\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#database-probleme","title":"\ud83d\uddc4\ufe0f Database-Probleme","text":""},{"location":"troubleshooting/common-issues/#connection-pool-erschopfung","title":"Connection-Pool-Ersch\u00f6pfung","text":"<p>Problem: \"QueuePool limit of size X overflow Y reached\"</p> <p>Symptome: <pre><code>sqlalchemy.exc.TimeoutError: QueuePool limit of size 20 overflow 30 reached\n</code></pre></p> <p>Diagnose: <pre><code># Aktive Verbindungen pr\u00fcfen\npsql -d keiko_db -c \"SELECT count(*) FROM pg_stat_activity WHERE datname='keiko_db';\"\n\n# Connection-Pool-Status\ncurl http://localhost:8000/debug/pool-status\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Pool-Gr\u00f6\u00dfe erh\u00f6hen <pre><code># config/database.yml\ndatabase:\n  default:\n    pool_size: 30\n    max_overflow: 50\n    pool_timeout: 60\n</code></pre></p> </li> <li> <p>Connection-Leaks finden <pre><code># debug/connection_tracker.py\nimport logging\nfrom sqlalchemy import event\nfrom sqlalchemy.engine import Engine\n\n@event.listens_for(Engine, \"connect\")\ndef set_sqlite_pragma(dbapi_connection, connection_record):\n    logging.info(f\"New connection: {id(dbapi_connection)}\")\n\n@event.listens_for(Engine, \"close\")\ndef close_connection(dbapi_connection, connection_record):\n    logging.info(f\"Closed connection: {id(dbapi_connection)}\")\n</code></pre></p> </li> <li> <p>Connection-Recycling konfigurieren <pre><code>database:\n  default:\n    pool_recycle: 3600  # 1 Stunde\n    pool_pre_ping: true\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#slow-queries","title":"Slow Queries","text":"<p>Problem: Database-Queries sind langsam (&gt;1 Sekunde).</p> <p>Diagnose: <pre><code>-- Langsame Queries identifizieren\nSELECT query, mean_exec_time, calls\nFROM pg_stat_statements\nWHERE mean_exec_time &gt; 1000\nORDER BY mean_exec_time DESC;\n\n-- Aktive Queries pr\u00fcfen\nSELECT pid, now() - pg_stat_activity.query_start AS duration, query\nFROM pg_stat_activity\nWHERE (now() - pg_stat_activity.query_start) &gt; interval '5 minutes';\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Fehlende Indizes hinzuf\u00fcgen <pre><code>-- H\u00e4ufig ben\u00f6tigte Indizes\nCREATE INDEX CONCURRENTLY idx_tasks_user_status ON tasks(user_id, status);\nCREATE INDEX CONCURRENTLY idx_agents_type_active ON agents(type) WHERE status = 'active';\nCREATE INDEX CONCURRENTLY idx_audit_logs_created_at ON audit_logs(created_at);\n</code></pre></p> </li> <li> <p>Query-Optimierung <pre><code># Vorher: N+1 Query-Problem\nagents = await session.execute(select(Agent))\nfor agent in agents:\n    tasks = await session.execute(select(Task).where(Task.agent_id == agent.id))\n\n# Nachher: Eager Loading\nagents = await session.execute(\n    select(Agent).options(selectinload(Agent.tasks))\n)\n</code></pre></p> </li> <li> <p>Database-Tuning <pre><code>-- PostgreSQL-Konfiguration optimieren\nALTER SYSTEM SET shared_buffers = '256MB';\nALTER SYSTEM SET effective_cache_size = '1GB';\nALTER SYSTEM SET random_page_cost = 1.1;\nSELECT pg_reload_conf();\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#redis-probleme","title":"\ud83d\udd04 Redis-Probleme","text":""},{"location":"troubleshooting/common-issues/#redis-verbindungsfehler","title":"Redis-Verbindungsfehler","text":"<p>Problem: \"Connection refused\" oder \"Redis server went away\"</p> <p>Diagnose: <pre><code># Redis-Status pr\u00fcfen\nredis-cli ping\n\n# Redis-Logs pr\u00fcfen\ntail -f /var/log/redis/redis-server.log\n\n# Verbindung testen\nredis-cli -h localhost -p 6379 info\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Redis-Service starten <pre><code>sudo systemctl start redis-server\nsudo systemctl enable redis-server\n</code></pre></p> </li> <li> <p>Redis-Konfiguration pr\u00fcfen <pre><code># Redis-Config\nsudo nano /etc/redis/redis.conf\n\n# Wichtige Einstellungen:\n# bind 127.0.0.1\n# port 6379\n# maxmemory 512mb\n# maxmemory-policy allkeys-lru\n</code></pre></p> </li> <li> <p>Connection-Pool konfigurieren <pre><code># config/redis.py\nREDIS_CONFIG = {\n    'host': 'localhost',\n    'port': 6379,\n    'db': 0,\n    'max_connections': 20,\n    'retry_on_timeout': True,\n    'socket_timeout': 5,\n    'socket_connect_timeout': 5\n}\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#memory-probleme","title":"Memory-Probleme","text":"<p>Problem: Redis l\u00e4uft aus dem Speicher.</p> <p>Diagnose: <pre><code># Redis-Memory-Usage\nredis-cli info memory\n\n# Top-Keys nach Speicherverbrauch\nredis-cli --bigkeys\n\n# Memory-Usage-Pattern\nredis-cli info stats | grep keyspace\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Memory-Policy konfigurieren <pre><code># redis.conf\nmaxmemory 512mb\nmaxmemory-policy allkeys-lru\n</code></pre></p> </li> <li> <p>Key-Expiration setzen <pre><code># Cache mit TTL\nawait redis_client.setex(\"cache_key\", 3600, value)  # 1 Stunde\n\n# Batch-Expiration\nfor key in large_keys:\n    await redis_client.expire(key, 1800)  # 30 Minuten\n</code></pre></p> </li> <li> <p>Memory-Monitoring <pre><code># memory_monitor.py\nasync def monitor_redis_memory():\n    info = await redis_client.info('memory')\n    used_memory = info['used_memory']\n    max_memory = info['maxmemory']\n\n    if used_memory &gt; max_memory * 0.9:\n        logger.warning(f\"Redis memory usage high: {used_memory}/{max_memory}\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#agent-probleme","title":"\ud83e\udd16 Agent-Probleme","text":""},{"location":"troubleshooting/common-issues/#agent-startet-nicht","title":"Agent startet nicht","text":"<p>Problem: Agent kann nicht gestartet oder aktiviert werden.</p> <p>Diagnose: <pre><code># Agent-Status pr\u00fcfen\ncurl http://localhost:8000/api/v1/agents/{agent_id}/status\n\n# Agent-Logs pr\u00fcfen\ngrep \"agent_id:{agent_id}\" /var/log/keiko/app.log\n\n# Agent-Konfiguration validieren\n./scripts/validate-agent-config.sh {agent_id}\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Konfigurationsfehler beheben <pre><code># agents/example-agent.yml\nname: \"Example Agent\"\ntype: \"specialist\"\ncapabilities:\n  - \"text_processing\"\nconfiguration:\n  timeout_seconds: 300\n  max_concurrent_tasks: 1\n</code></pre></p> </li> <li> <p>Dependencies pr\u00fcfen <pre><code># Agent-Dependencies validieren\nasync def validate_agent_dependencies(agent_config):\n    for capability in agent_config.capabilities:\n        if capability == \"text_processing\":\n            try:\n                import transformers\n            except ImportError:\n                raise AgentDependencyError(\"transformers package required\")\n</code></pre></p> </li> <li> <p>Resource-Limits pr\u00fcfen <pre><code># Memory-Limits\nulimit -v\n\n# File-Descriptor-Limits\nulimit -n\n\n# Process-Limits\nulimit -u\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#task-execution-fehler","title":"Task-Execution-Fehler","text":"<p>Problem: Tasks schlagen fehl oder h\u00e4ngen.</p> <p>Diagnose: <pre><code># Fehlgeschlagene Tasks\ncurl http://localhost:8000/api/v1/tasks?status=failed\n\n# H\u00e4ngende Tasks\ncurl http://localhost:8000/api/v1/tasks?status=running | jq '.[] | select(.created_at &lt; (now - 3600))'\n\n# Task-Logs\ngrep \"task_id:{task_id}\" /var/log/keiko/app.log\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Timeout-Konfiguration <pre><code># Task-Timeout erh\u00f6hen\ntask_config = {\n    \"timeout_seconds\": 600,  # 10 Minuten\n    \"retry_policy\": {\n        \"max_retries\": 3,\n        \"retry_delay\": 5.0\n    }\n}\n</code></pre></p> </li> <li> <p>Error-Handling verbessern <pre><code>async def execute_task_with_error_handling(task):\n    try:\n        result = await agent.execute_task(task)\n        return result\n    except TimeoutError:\n        logger.error(f\"Task {task.id} timed out\")\n        return TaskResult.failure(\"Task timed out\")\n    except Exception as e:\n        logger.error(f\"Task {task.id} failed: {e}\", exc_info=True)\n        return TaskResult.failure(str(e))\n</code></pre></p> </li> <li> <p>Resource-Monitoring <pre><code># Task-Resource-Monitoring\nasync def monitor_task_resources(task_id):\n    process = psutil.Process()\n\n    while task_is_running(task_id):\n        memory_usage = process.memory_info().rss / 1024 / 1024  # MB\n        cpu_usage = process.cpu_percent()\n\n        if memory_usage &gt; 1000:  # 1GB\n            logger.warning(f\"Task {task_id} high memory usage: {memory_usage}MB\")\n\n        if cpu_usage &gt; 90:\n            logger.warning(f\"Task {task_id} high CPU usage: {cpu_usage}%\")\n\n        await asyncio.sleep(10)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#api-probleme","title":"\ud83c\udf10 API-Probleme","text":""},{"location":"troubleshooting/common-issues/#500-internal-server-error","title":"500 Internal Server Error","text":"<p>Problem: API-Endpunkte geben 500-Fehler zur\u00fcck.</p> <p>Diagnose: <pre><code># Error-Logs pr\u00fcfen\ntail -f /var/log/keiko/error.log\n\n# API-Health-Check\ncurl http://localhost:8000/health\n\n# Specific-Endpoint testen\ncurl -v http://localhost:8000/api/v1/agents\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Exception-Handling pr\u00fcfen <pre><code># Unbehandelte Exceptions finden\n@app.exception_handler(Exception)\nasync def general_exception_handler(request: Request, exc: Exception):\n    logger.error(f\"Unhandled exception: {exc}\", exc_info=True)\n    return JSONResponse(\n        status_code=500,\n        content={\"error\": \"Internal server error\", \"request_id\": str(uuid.uuid4())}\n    )\n</code></pre></p> </li> <li> <p>Dependency-Injection-Probleme <pre><code># DI-Container validieren\nasync def validate_dependencies():\n    try:\n        container = get_container()\n        container.check_dependencies()\n    except Exception as e:\n        logger.error(f\"DI validation failed: {e}\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#rate-limiting-probleme","title":"Rate-Limiting-Probleme","text":"<p>Problem: \"Too Many Requests\" (429) Fehler.</p> <p>Diagnose: <pre><code># Rate-Limit-Status pr\u00fcfen\ncurl -I http://localhost:8000/api/v1/agents\n\n# Redis-Rate-Limit-Keys pr\u00fcfen\nredis-cli keys \"rate_limit:*\"\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Rate-Limits anpassen <pre><code># config/rate_limits.py\nRATE_LIMITS = {\n    \"default\": {\"requests\": 100, \"window\": 60},\n    \"auth\": {\"requests\": 10, \"window\": 60},\n    \"tasks\": {\"requests\": 50, \"window\": 60}\n}\n</code></pre></p> </li> <li> <p>Client-seitige Retry-Logic <pre><code>import asyncio\nfrom aiohttp import ClientSession\n\nasync def api_request_with_retry(url, max_retries=3):\n    for attempt in range(max_retries):\n        async with ClientSession() as session:\n            async with session.get(url) as response:\n                if response.status == 429:\n                    retry_after = int(response.headers.get('Retry-After', 60))\n                    await asyncio.sleep(retry_after)\n                    continue\n                return await response.json()\n\n    raise Exception(\"Max retries exceeded\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/common-issues/#performance-probleme","title":"\ud83d\udcca Performance-Probleme","text":""},{"location":"troubleshooting/common-issues/#hohe-response-zeiten","title":"Hohe Response-Zeiten","text":"<p>Problem: API-Responses sind langsam (&gt;2 Sekunden).</p> <p>Diagnose: <pre><code># Response-Zeit messen\ncurl -w \"@curl-format.txt\" -o /dev/null -s http://localhost:8000/api/v1/agents\n\n# APM-Metriken pr\u00fcfen\ncurl http://localhost:8000/metrics | grep http_request_duration\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Caching implementieren <pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=128)\nasync def get_agent_config(agent_id: str):\n    # Expensive operation\n    return await load_agent_config(agent_id)\n</code></pre></p> </li> <li> <p>Database-Query-Optimierung <pre><code># Batch-Loading\nasync def get_agents_with_stats(agent_ids: List[str]):\n    query = (\n        select(Agent, func.count(Task.id))\n        .outerjoin(Task)\n        .where(Agent.id.in_(agent_ids))\n        .group_by(Agent.id)\n    )\n    return await session.execute(query)\n</code></pre></p> </li> <li> <p>Async-Optimierung <pre><code># Parallel-Processing\nasync def process_multiple_tasks(tasks: List[Task]):\n    results = await asyncio.gather(*[\n        process_single_task(task) for task in tasks\n    ])\n    return results\n</code></pre></p> </li> </ol> <p>Debugging-Tools</p> <p>Nutzen Sie die integrierten Debugging-Tools: - <code>/debug/health</code> - Detaillierte Health-Informationen - <code>/debug/metrics</code> - Performance-Metriken - <code>/debug/config</code> - Aktuelle Konfiguration - <code>/debug/logs</code> - Recent-Log-Entries</p> <p>Support-Kan\u00e4le</p> <p>Bei persistenten Problemen: - GitHub Issues: https://github.com/oscharko/keiko-personal-assistant/issues - Community-Forum: https://community.keiko.ai - Enterprise-Support: support@keiko.ai</p>"},{"location":"troubleshooting/debugging/","title":"\ud83d\udc1b Debugging Guide","text":"<p>Umfassender Leitfaden f\u00fcr das Debugging von Keiko Personal Assistant.</p>"},{"location":"troubleshooting/debugging/#debug-modus-aktivieren","title":"\ud83d\udd0d Debug-Modus aktivieren","text":""},{"location":"troubleshooting/debugging/#development-debug-modus","title":"Development-Debug-Modus","text":"<pre><code># Environment-Variable setzen\nexport KEIKO_DEBUG=true\nexport KEIKO_LOG_LEVEL=DEBUG\n\n# Debug-Konfiguration\ncat &gt; config/debug.yml &lt;&lt; EOF\ndebug:\n  enabled: true\n  log_level: DEBUG\n  profiling: true\n  trace_requests: true\n  detailed_errors: true\n\nlogging:\n  level: DEBUG\n  format: detailed\n  include_traceback: true\n  log_sql_queries: true\nEOF\n\n# Application mit Debug-Modus starten\nuvicorn main:app --reload --log-level debug\n</code></pre>"},{"location":"troubleshooting/debugging/#production-debug-modus","title":"Production-Debug-Modus","text":"<pre><code># Tempor\u00e4rer Debug-Modus (nur f\u00fcr spezifische Session)\nexport KEIKO_TEMP_DEBUG=true\n\n# Debug-Endpunkt aktivieren\ncurl -X POST http://localhost:8000/debug/enable \\\n  -H \"Authorization: Bearer $ADMIN_TOKEN\" \\\n  -d '{\"duration_minutes\": 30}'\n</code></pre>"},{"location":"troubleshooting/debugging/#logging-tracing","title":"\ud83d\udcca Logging &amp; Tracing","text":""},{"location":"troubleshooting/debugging/#strukturiertes-logging","title":"Strukturiertes Logging","text":"<pre><code># logging_config.py\nimport structlog\nfrom keiko.logging import configure_logging\n\n# Logger konfigurieren\nlogger = structlog.get_logger(__name__)\n\n# Strukturierte Log-Nachrichten\nlogger.info(\n    \"Agent-Task gestartet\",\n    agent_id=\"agent-123\",\n    task_id=\"task-456\",\n    task_type=\"text_processing\",\n    user_id=\"user-789\",\n    correlation_id=\"corr-abc123\"\n)\n\n# Error-Logging mit Context\ntry:\n    result = await agent.execute_task(task)\nexcept Exception as e:\n    logger.error(\n        \"Task-Ausf\u00fchrung fehlgeschlagen\",\n        agent_id=task.agent_id,\n        task_id=task.id,\n        error_type=type(e).__name__,\n        error_message=str(e),\n        exc_info=True\n    )\n</code></pre>"},{"location":"troubleshooting/debugging/#request-tracing","title":"Request-Tracing","text":"<pre><code># middleware/tracing.py\nimport uuid\nfrom fastapi import Request, Response\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nclass TracingMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware f\u00fcr Request-Tracing.\"\"\"\n\n    async def dispatch(self, request: Request, call_next):\n        # Correlation-ID generieren\n        correlation_id = str(uuid.uuid4())\n        request.state.correlation_id = correlation_id\n\n        # Request-Start protokollieren\n        logger.info(\n            \"Request gestartet\",\n            method=request.method,\n            url=str(request.url),\n            correlation_id=correlation_id,\n            user_agent=request.headers.get(\"user-agent\"),\n            client_ip=request.client.host\n        )\n\n        start_time = time.time()\n\n        try:\n            response = await call_next(request)\n\n            # Request-Ende protokollieren\n            duration = time.time() - start_time\n            logger.info(\n                \"Request abgeschlossen\",\n                correlation_id=correlation_id,\n                status_code=response.status_code,\n                duration_seconds=duration\n            )\n\n            # Correlation-ID in Response-Header\n            response.headers[\"X-Correlation-ID\"] = correlation_id\n\n            return response\n\n        except Exception as e:\n            duration = time.time() - start_time\n            logger.error(\n                \"Request fehlgeschlagen\",\n                correlation_id=correlation_id,\n                error_type=type(e).__name__,\n                error_message=str(e),\n                duration_seconds=duration,\n                exc_info=True\n            )\n            raise\n\n# Middleware registrieren\napp.add_middleware(TracingMiddleware)\n</code></pre>"},{"location":"troubleshooting/debugging/#distributed-tracing","title":"Distributed Tracing","text":"<pre><code># tracing/jaeger_config.py\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\ndef configure_tracing():\n    \"\"\"Konfiguriert Jaeger-Tracing.\"\"\"\n\n    # Tracer-Provider konfigurieren\n    trace.set_tracer_provider(TracerProvider())\n    tracer = trace.get_tracer(__name__)\n\n    # Jaeger-Exporter konfigurieren\n    jaeger_exporter = JaegerExporter(\n        agent_host_name=\"localhost\",\n        agent_port=6831,\n    )\n\n    # Span-Processor hinzuf\u00fcgen\n    span_processor = BatchSpanProcessor(jaeger_exporter)\n    trace.get_tracer_provider().add_span_processor(span_processor)\n\n    return tracer\n\n# Tracing in Agent-Execution\nasync def execute_task_with_tracing(self, task: Task) -&gt; TaskResult:\n    \"\"\"F\u00fchrt Task mit Tracing aus.\"\"\"\n\n    tracer = trace.get_tracer(__name__)\n\n    with tracer.start_as_current_span(\"agent.execute_task\") as span:\n        # Span-Attribute setzen\n        span.set_attribute(\"agent.id\", self.id)\n        span.set_attribute(\"agent.type\", self.config.type)\n        span.set_attribute(\"task.id\", task.id)\n        span.set_attribute(\"task.type\", task.type)\n\n        try:\n            result = await self._execute_task_logic(task)\n\n            span.set_attribute(\"task.success\", True)\n            span.set_attribute(\"task.duration\", result.execution_time)\n\n            return result\n\n        except Exception as e:\n            span.set_attribute(\"task.success\", False)\n            span.set_attribute(\"error.type\", type(e).__name__)\n            span.set_attribute(\"error.message\", str(e))\n            span.record_exception(e)\n            raise\n</code></pre>"},{"location":"troubleshooting/debugging/#debug-tools","title":"\ud83d\udd27 Debug-Tools","text":""},{"location":"troubleshooting/debugging/#interactive-debugger","title":"Interactive Debugger","text":"<pre><code># debug/interactive.py\nimport asyncio\nimport IPython\nfrom keiko.core import get_application_context\n\nasync def start_debug_session():\n    \"\"\"Startet interaktive Debug-Session.\"\"\"\n\n    # Application-Context laden\n    context = await get_application_context()\n\n    # Verf\u00fcgbare Objekte\n    debug_context = {\n        'app': context.app,\n        'db': context.database,\n        'redis': context.redis,\n        'agent_service': context.agent_service,\n        'task_service': context.task_service,\n        'logger': context.logger\n    }\n\n    print(\"Keiko Debug-Session gestartet\")\n    print(\"Verf\u00fcgbare Objekte:\", list(debug_context.keys()))\n\n    # IPython-Session starten\n    IPython.embed(user_ns=debug_context)\n\n# Debug-Session starten\nif __name__ == \"__main__\":\n    asyncio.run(start_debug_session())\n</code></pre>"},{"location":"troubleshooting/debugging/#memory-profiling","title":"Memory-Profiling","text":"<pre><code># debug/memory_profiler.py\nimport psutil\nimport tracemalloc\nfrom memory_profiler import profile\n\nclass MemoryProfiler:\n    \"\"\"Memory-Profiling f\u00fcr Keiko.\"\"\"\n\n    def __init__(self):\n        self.process = psutil.Process()\n        tracemalloc.start()\n\n    def get_memory_usage(self) -&gt; dict:\n        \"\"\"Ruft aktuelle Memory-Usage ab.\"\"\"\n\n        memory_info = self.process.memory_info()\n        memory_percent = self.process.memory_percent()\n\n        # Tracemalloc-Statistiken\n        current, peak = tracemalloc.get_traced_memory()\n\n        return {\n            'rss_mb': memory_info.rss / 1024 / 1024,\n            'vms_mb': memory_info.vms / 1024 / 1024,\n            'percent': memory_percent,\n            'traced_current_mb': current / 1024 / 1024,\n            'traced_peak_mb': peak / 1024 / 1024\n        }\n\n    def get_top_memory_consumers(self, limit: int = 10) -&gt; list:\n        \"\"\"Ruft Top-Memory-Consumer ab.\"\"\"\n\n        snapshot = tracemalloc.take_snapshot()\n        top_stats = snapshot.statistics('lineno')\n\n        return [\n            {\n                'filename': stat.traceback.format()[0],\n                'size_mb': stat.size / 1024 / 1024,\n                'count': stat.count\n            }\n            for stat in top_stats[:limit]\n        ]\n\n# Memory-Profiling-Decorator\ndef memory_profile(func):\n    \"\"\"Decorator f\u00fcr Memory-Profiling.\"\"\"\n\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        profiler = MemoryProfiler()\n\n        # Memory vor Ausf\u00fchrung\n        memory_before = profiler.get_memory_usage()\n\n        try:\n            result = await func(*args, **kwargs)\n\n            # Memory nach Ausf\u00fchrung\n            memory_after = profiler.get_memory_usage()\n\n            # Memory-Diff protokollieren\n            memory_diff = memory_after['rss_mb'] - memory_before['rss_mb']\n\n            logger.info(\n                f\"Memory-Profiling: {func.__name__}\",\n                memory_before_mb=memory_before['rss_mb'],\n                memory_after_mb=memory_after['rss_mb'],\n                memory_diff_mb=memory_diff,\n                function=func.__name__\n            )\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Function {func.__name__} failed during memory profiling: {e}\")\n            raise\n\n    return wrapper\n\n# Verwendung\n@memory_profile\nasync def process_large_dataset(data):\n    \"\"\"Verarbeitet gro\u00dfe Datenmengen.\"\"\"\n    # Implementation\n    pass\n</code></pre>"},{"location":"troubleshooting/debugging/#performance-profiling","title":"Performance-Profiling","text":"<pre><code># debug/performance_profiler.py\nimport cProfile\nimport pstats\nimport time\nfrom functools import wraps\n\nclass PerformanceProfiler:\n    \"\"\"Performance-Profiling f\u00fcr Keiko.\"\"\"\n\n    def __init__(self):\n        self.profiler = cProfile.Profile()\n        self.stats = None\n\n    def start_profiling(self):\n        \"\"\"Startet Profiling.\"\"\"\n        self.profiler.enable()\n\n    def stop_profiling(self):\n        \"\"\"Stoppt Profiling.\"\"\"\n        self.profiler.disable()\n        self.stats = pstats.Stats(self.profiler)\n\n    def get_top_functions(self, limit: int = 20) -&gt; list:\n        \"\"\"Ruft Top-Funktionen nach Ausf\u00fchrungszeit ab.\"\"\"\n\n        if not self.stats:\n            return []\n\n        # Nach cumulative time sortieren\n        self.stats.sort_stats('cumulative')\n\n        # Top-Funktionen extrahieren\n        top_functions = []\n        for func, (cc, nc, tt, ct, callers) in list(self.stats.stats.items())[:limit]:\n            top_functions.append({\n                'function': f\"{func[0]}:{func[1]}({func[2]})\",\n                'calls': nc,\n                'total_time': tt,\n                'cumulative_time': ct,\n                'per_call': ct / nc if nc &gt; 0 else 0\n            })\n\n        return top_functions\n\n    def save_profile(self, filename: str):\n        \"\"\"Speichert Profiling-Ergebnisse.\"\"\"\n        if self.stats:\n            self.stats.dump_stats(filename)\n\n# Performance-Profiling-Decorator\ndef performance_profile(func):\n    \"\"\"Decorator f\u00fcr Performance-Profiling.\"\"\"\n\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        profiler = PerformanceProfiler()\n\n        start_time = time.time()\n        profiler.start_profiling()\n\n        try:\n            result = await func(*args, **kwargs)\n\n            profiler.stop_profiling()\n            execution_time = time.time() - start_time\n\n            # Top-Funktionen protokollieren\n            top_functions = profiler.get_top_functions(5)\n\n            logger.info(\n                f\"Performance-Profiling: {func.__name__}\",\n                execution_time=execution_time,\n                top_functions=top_functions,\n                function=func.__name__\n            )\n\n            # Profiling-Daten speichern (optional)\n            if execution_time &gt; 5.0:  # Nur bei langsamen Funktionen\n                filename = f\"/tmp/profile_{func.__name__}_{int(time.time())}.prof\"\n                profiler.save_profile(filename)\n                logger.info(f\"Profiling-Daten gespeichert: {filename}\")\n\n            return result\n\n        except Exception as e:\n            profiler.stop_profiling()\n            logger.error(f\"Function {func.__name__} failed during profiling: {e}\")\n            raise\n\n    return wrapper\n</code></pre>"},{"location":"troubleshooting/debugging/#debug-endpunkte","title":"\ud83d\udd0d Debug-Endpunkte","text":""},{"location":"troubleshooting/debugging/#debug-api-endpunkte","title":"Debug-API-Endpunkte","text":"<pre><code># api/debug.py\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom keiko.auth import require_admin\n\ndebug_router = APIRouter(prefix=\"/debug\", tags=[\"debug\"])\n\n@debug_router.get(\"/health\")\nasync def debug_health():\n    \"\"\"Detaillierte Health-Informationen.\"\"\"\n\n    health_info = {\n        'timestamp': datetime.utcnow().isoformat(),\n        'version': get_version(),\n        'uptime_seconds': get_uptime(),\n        'memory_usage': get_memory_usage(),\n        'cpu_usage': get_cpu_usage(),\n        'database': await check_database_health(),\n        'redis': await check_redis_health(),\n        'agents': await get_agent_status_summary(),\n        'tasks': await get_task_status_summary()\n    }\n\n    return health_info\n\n@debug_router.get(\"/metrics\")\nasync def debug_metrics():\n    \"\"\"Performance-Metriken.\"\"\"\n\n    return {\n        'request_metrics': get_request_metrics(),\n        'database_metrics': get_database_metrics(),\n        'agent_metrics': get_agent_metrics(),\n        'task_metrics': get_task_metrics(),\n        'system_metrics': get_system_metrics()\n    }\n\n@debug_router.get(\"/config\")\nasync def debug_config(admin_user = Depends(require_admin)):\n    \"\"\"Aktuelle Konfiguration (nur f\u00fcr Admins).\"\"\"\n\n    config = get_current_config()\n\n    # Sensitive Daten entfernen\n    sanitized_config = sanitize_config(config)\n\n    return sanitized_config\n\n@debug_router.get(\"/logs\")\nasync def debug_logs(\n    level: str = \"INFO\",\n    limit: int = 100,\n    admin_user = Depends(require_admin)\n):\n    \"\"\"Recent-Log-Entries.\"\"\"\n\n    logs = await get_recent_logs(level=level, limit=limit)\n\n    return {\n        'logs': logs,\n        'total_count': len(logs),\n        'level_filter': level\n    }\n\n@debug_router.post(\"/gc\")\nasync def debug_garbage_collection(admin_user = Depends(require_admin)):\n    \"\"\"Erzwingt Garbage Collection.\"\"\"\n\n    import gc\n\n    before_count = len(gc.get_objects())\n    collected = gc.collect()\n    after_count = len(gc.get_objects())\n\n    return {\n        'objects_before': before_count,\n        'objects_after': after_count,\n        'objects_collected': collected,\n        'objects_freed': before_count - after_count\n    }\n\n@debug_router.get(\"/agents/{agent_id}/debug\")\nasync def debug_agent(agent_id: str):\n    \"\"\"Debug-Informationen f\u00fcr spezifischen Agent.\"\"\"\n\n    agent = await get_agent(agent_id)\n    if not agent:\n        raise HTTPException(404, \"Agent not found\")\n\n    debug_info = {\n        'agent_id': agent_id,\n        'status': agent.status,\n        'current_tasks': await get_agent_current_tasks(agent_id),\n        'recent_tasks': await get_agent_recent_tasks(agent_id, limit=10),\n        'performance_stats': await get_agent_performance_stats(agent_id),\n        'resource_usage': await get_agent_resource_usage(agent_id),\n        'error_history': await get_agent_error_history(agent_id, limit=5)\n    }\n\n    return debug_info\n</code></pre>"},{"location":"troubleshooting/debugging/#debug-cli-tools","title":"Debug-CLI-Tools","text":"<pre><code># cli/debug.py\nimport click\nimport asyncio\nfrom keiko.debug import DebugSession\n\n@click.group()\ndef debug():\n    \"\"\"Debug-CLI f\u00fcr Keiko.\"\"\"\n    pass\n\n@debug.command()\n@click.option('--agent-id', help='Agent-ID f\u00fcr Debug-Session')\n@click.option('--task-id', help='Task-ID f\u00fcr Debug-Session')\ndef session(agent_id, task_id):\n    \"\"\"Startet interaktive Debug-Session.\"\"\"\n\n    async def start_session():\n        session = DebugSession()\n\n        if agent_id:\n            await session.load_agent(agent_id)\n\n        if task_id:\n            await session.load_task(task_id)\n\n        await session.start_interactive()\n\n    asyncio.run(start_session())\n\n@debug.command()\n@click.option('--duration', default=60, help='Profiling-Dauer in Sekunden')\n@click.option('--output', default='profile.prof', help='Output-Datei')\ndef profile(duration, output):\n    \"\"\"Startet Performance-Profiling.\"\"\"\n\n    async def run_profiling():\n        profiler = PerformanceProfiler()\n\n        print(f\"Starte Profiling f\u00fcr {duration} Sekunden...\")\n        profiler.start_profiling()\n\n        await asyncio.sleep(duration)\n\n        profiler.stop_profiling()\n        profiler.save_profile(output)\n\n        print(f\"Profiling-Daten gespeichert: {output}\")\n\n        # Top-Funktionen anzeigen\n        top_functions = profiler.get_top_functions(10)\n        print(\"\\nTop-Funktionen:\")\n        for func in top_functions:\n            print(f\"  {func['function']}: {func['cumulative_time']:.3f}s\")\n\n    asyncio.run(run_profiling())\n\n@debug.command()\n@click.option('--level', default='ERROR', help='Log-Level')\n@click.option('--follow', '-f', is_flag=True, help='Follow-Modus')\ndef logs(level, follow):\n    \"\"\"Zeigt Logs an.\"\"\"\n\n    if follow:\n        # Tail-\u00e4hnliche Funktionalit\u00e4t\n        import time\n\n        while True:\n            logs = get_recent_logs(level=level, limit=10)\n            for log in logs:\n                print(f\"{log['timestamp']} [{log['level']}] {log['message']}\")\n\n            time.sleep(1)\n    else:\n        logs = get_recent_logs(level=level, limit=50)\n        for log in logs:\n            print(f\"{log['timestamp']} [{log['level']}] {log['message']}\")\n\nif __name__ == '__main__':\n    debug()\n</code></pre>"},{"location":"troubleshooting/debugging/#testing-debugging","title":"\ud83e\uddea Testing &amp; Debugging","text":""},{"location":"troubleshooting/debugging/#unit-test-debugging","title":"Unit-Test-Debugging","text":"<pre><code># tests/debug_test.py\nimport pytest\nimport asyncio\nfrom keiko.testing import DebugTestCase\n\nclass TestAgentDebugging(DebugTestCase):\n    \"\"\"Debug-Tests f\u00fcr Agenten.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_agent_execution_with_debugging(self):\n        \"\"\"Testet Agent-Ausf\u00fchrung mit Debugging.\"\"\"\n\n        # Debug-Modus aktivieren\n        self.enable_debug_mode()\n\n        # Agent erstellen\n        agent = await self.create_test_agent()\n\n        # Task mit Debug-Informationen ausf\u00fchren\n        task = self.create_test_task()\n\n        with self.debug_context() as debug:\n            result = await agent.execute_task(task)\n\n            # Debug-Informationen pr\u00fcfen\n            assert debug.get_call_count('execute_task') == 1\n            assert debug.get_execution_time('execute_task') &lt; 5.0\n            assert len(debug.get_log_entries()) &gt; 0\n\n        assert result.success\n\n    @pytest.mark.asyncio\n    async def test_memory_leak_detection(self):\n        \"\"\"Testet Memory-Leak-Detection.\"\"\"\n\n        initial_memory = self.get_memory_usage()\n\n        # Viele Tasks ausf\u00fchren\n        for i in range(100):\n            agent = await self.create_test_agent()\n            task = self.create_test_task()\n            await agent.execute_task(task)\n\n        final_memory = self.get_memory_usage()\n        memory_increase = final_memory - initial_memory\n\n        # Memory-Increase sollte begrenzt sein\n        assert memory_increase &lt; 100  # MB\n</code></pre> <p>Debug-Best-Practices</p> <ul> <li>Verwenden Sie strukturiertes Logging f\u00fcr bessere Nachverfolgbarkeit</li> <li>Aktivieren Sie Tracing nur bei Bedarf (Performance-Impact)</li> <li>Nutzen Sie Memory-Profiling bei Verdacht auf Memory-Leaks</li> <li>Implementieren Sie umfassende Debug-Endpunkte f\u00fcr Production-Debugging</li> </ul> <p>Production-Debugging</p> <p>Seien Sie vorsichtig beim Aktivieren von Debug-Modi in Production: - Begrenzen Sie Debug-Sessions zeitlich - Beschr\u00e4nken Sie Zugriff auf Admin-Benutzer - \u00dcberwachen Sie Performance-Impact - Deaktivieren Sie Debug-Modi nach Probleml\u00f6sung</p>"},{"location":"troubleshooting/performance/","title":"\u26a1 Performance Troubleshooting","text":"<p>Leitfaden zur Diagnose und Behebung von Performance-Problemen in Keiko Personal Assistant.</p>"},{"location":"troubleshooting/performance/#performance-monitoring","title":"\ud83d\udcca Performance-Monitoring","text":""},{"location":"troubleshooting/performance/#key-performance-indicators-kpis","title":"Key Performance Indicators (KPIs)","text":"<pre><code># monitoring/performance_kpis.py\nfrom dataclasses import dataclass\nfrom typing import Dict, List\n\n@dataclass\nclass PerformanceKPIs:\n    \"\"\"Performance-KPIs f\u00fcr Keiko.\"\"\"\n\n    # Response-Zeit-Ziele\n    api_response_time_p95: float = 200.0  # ms\n    api_response_time_p99: float = 500.0  # ms\n\n    # Durchsatz-Ziele\n    requests_per_second: float = 1000.0\n    tasks_per_minute: float = 500.0\n\n    # Resource-Ziele\n    cpu_usage_max: float = 70.0  # %\n    memory_usage_max: float = 80.0  # %\n    database_connections_max: float = 80.0  # % of pool\n\n    # Fehler-Ziele\n    error_rate_max: float = 0.1  # %\n    task_failure_rate_max: float = 1.0  # %\n\nclass PerformanceMonitor:\n    \"\"\"Performance-Monitor f\u00fcr KPI-\u00dcberwachung.\"\"\"\n\n    def __init__(self):\n        self.kpis = PerformanceKPIs()\n        self.metrics_collector = MetricsCollector()\n\n    async def check_performance_health(self) -&gt; Dict[str, bool]:\n        \"\"\"Pr\u00fcft Performance-Health gegen KPIs.\"\"\"\n\n        current_metrics = await self.metrics_collector.get_current_metrics()\n\n        health_status = {\n            'api_response_time': current_metrics['api_p95'] &lt;= self.kpis.api_response_time_p95,\n            'throughput': current_metrics['rps'] &gt;= self.kpis.requests_per_second,\n            'cpu_usage': current_metrics['cpu_percent'] &lt;= self.kpis.cpu_usage_max,\n            'memory_usage': current_metrics['memory_percent'] &lt;= self.kpis.memory_usage_max,\n            'error_rate': current_metrics['error_rate'] &lt;= self.kpis.error_rate_max\n        }\n\n        return health_status\n\n    async def get_performance_alerts(self) -&gt; List[Dict[str, str]]:\n        \"\"\"Ruft aktuelle Performance-Alerts ab.\"\"\"\n\n        health_status = await self.check_performance_health()\n        alerts = []\n\n        for metric, is_healthy in health_status.items():\n            if not is_healthy:\n                alerts.append({\n                    'metric': metric,\n                    'severity': 'warning' if metric in ['cpu_usage', 'memory_usage'] else 'critical',\n                    'message': f\"Performance-KPI verletzt: {metric}\"\n                })\n\n        return alerts\n</code></pre>"},{"location":"troubleshooting/performance/#real-time-performance-dashboard","title":"Real-Time Performance Dashboard","text":"<pre><code># monitoring/dashboard.py\nfrom fastapi import APIRouter\nfrom fastapi.responses import HTMLResponse\n\nperformance_router = APIRouter(prefix=\"/performance\", tags=[\"performance\"])\n\n@performance_router.get(\"/dashboard\")\nasync def performance_dashboard():\n    \"\"\"Performance-Dashboard.\"\"\"\n\n    dashboard_html = \"\"\"\n    &lt;!DOCTYPE html&gt;\n    &lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;Keiko Performance Dashboard&lt;/title&gt;\n        &lt;script src=\"https://cdn.plot.ly/plotly-latest.min.js\"&gt;&lt;/script&gt;\n        &lt;style&gt;\n            .metric-card {\n                border: 1px solid #ddd;\n                padding: 20px;\n                margin: 10px;\n                border-radius: 5px;\n            }\n            .metric-value {\n                font-size: 2em;\n                font-weight: bold;\n            }\n            .metric-good { color: green; }\n            .metric-warning { color: orange; }\n            .metric-critical { color: red; }\n        &lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt;Keiko Performance Dashboard&lt;/h1&gt;\n\n        &lt;div id=\"metrics-container\"&gt;\n            &lt;div class=\"metric-card\"&gt;\n                &lt;h3&gt;API Response Time (P95)&lt;/h3&gt;\n                &lt;div id=\"response-time\" class=\"metric-value\"&gt;Loading...&lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"metric-card\"&gt;\n                &lt;h3&gt;Requests per Second&lt;/h3&gt;\n                &lt;div id=\"rps\" class=\"metric-value\"&gt;Loading...&lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"metric-card\"&gt;\n                &lt;h3&gt;CPU Usage&lt;/h3&gt;\n                &lt;div id=\"cpu-usage\" class=\"metric-value\"&gt;Loading...&lt;/div&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"metric-card\"&gt;\n                &lt;h3&gt;Memory Usage&lt;/h3&gt;\n                &lt;div id=\"memory-usage\" class=\"metric-value\"&gt;Loading...&lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;div id=\"response-time-chart\" style=\"width:100%;height:400px;\"&gt;&lt;/div&gt;\n        &lt;div id=\"throughput-chart\" style=\"width:100%;height:400px;\"&gt;&lt;/div&gt;\n\n        &lt;script&gt;\n            async function updateMetrics() {\n                const response = await fetch('/performance/metrics');\n                const metrics = await response.json();\n\n                // Metriken aktualisieren\n                document.getElementById('response-time').textContent =\n                    metrics.api_p95.toFixed(1) + ' ms';\n                document.getElementById('rps').textContent =\n                    metrics.rps.toFixed(0);\n                document.getElementById('cpu-usage').textContent =\n                    metrics.cpu_percent.toFixed(1) + '%';\n                document.getElementById('memory-usage').textContent =\n                    metrics.memory_percent.toFixed(1) + '%';\n\n                // Farben basierend auf Thresholds\n                updateMetricColor('response-time', metrics.api_p95, 200, 500);\n                updateMetricColor('cpu-usage', metrics.cpu_percent, 70, 90);\n                updateMetricColor('memory-usage', metrics.memory_percent, 80, 95);\n            }\n\n            function updateMetricColor(elementId, value, warning, critical) {\n                const element = document.getElementById(elementId);\n                element.className = 'metric-value ' +\n                    (value &lt; warning ? 'metric-good' :\n                     value &lt; critical ? 'metric-warning' : 'metric-critical');\n            }\n\n            // Charts erstellen\n            async function createCharts() {\n                const response = await fetch('/performance/history');\n                const history = await response.json();\n\n                // Response-Time-Chart\n                Plotly.newPlot('response-time-chart', [{\n                    x: history.timestamps,\n                    y: history.response_times,\n                    type: 'scatter',\n                    mode: 'lines',\n                    name: 'Response Time (ms)'\n                }], {\n                    title: 'API Response Time History',\n                    xaxis: { title: 'Time' },\n                    yaxis: { title: 'Response Time (ms)' }\n                });\n\n                // Throughput-Chart\n                Plotly.newPlot('throughput-chart', [{\n                    x: history.timestamps,\n                    y: history.throughput,\n                    type: 'scatter',\n                    mode: 'lines',\n                    name: 'Requests/sec'\n                }], {\n                    title: 'Throughput History',\n                    xaxis: { title: 'Time' },\n                    yaxis: { title: 'Requests per Second' }\n                });\n            }\n\n            // Initial load\n            updateMetrics();\n            createCharts();\n\n            // Auto-refresh alle 5 Sekunden\n            setInterval(updateMetrics, 5000);\n        &lt;/script&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\n    \"\"\"\n\n    return HTMLResponse(content=dashboard_html)\n\n@performance_router.get(\"/metrics\")\nasync def get_current_metrics():\n    \"\"\"Aktuelle Performance-Metriken.\"\"\"\n\n    monitor = PerformanceMonitor()\n    metrics = await monitor.metrics_collector.get_current_metrics()\n\n    return metrics\n\n@performance_router.get(\"/history\")\nasync def get_performance_history(hours: int = 24):\n    \"\"\"Performance-Historie.\"\"\"\n\n    # Historie aus Monitoring-System abrufen\n    history = await get_metrics_history(hours=hours)\n\n    return {\n        'timestamps': history['timestamps'],\n        'response_times': history['api_p95'],\n        'throughput': history['rps'],\n        'cpu_usage': history['cpu_percent'],\n        'memory_usage': history['memory_percent']\n    }\n</code></pre>"},{"location":"troubleshooting/performance/#slow-query-diagnosis","title":"\ud83d\udc0c Slow Query Diagnosis","text":""},{"location":"troubleshooting/performance/#database-performance-analysis","title":"Database Performance Analysis","text":"<pre><code># diagnosis/database_analyzer.py\nimport asyncio\nfrom sqlalchemy import text\n\nclass DatabasePerformanceAnalyzer:\n    \"\"\"Analysiert Database-Performance.\"\"\"\n\n    def __init__(self, db_session):\n        self.db_session = db_session\n\n    async def analyze_slow_queries(self, min_duration_ms: int = 1000) -&gt; List[Dict[str, Any]]:\n        \"\"\"Analysiert langsame Queries.\"\"\"\n\n        query = text(\"\"\"\n            SELECT\n                query,\n                mean_exec_time,\n                calls,\n                total_exec_time,\n                rows,\n                100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent\n            FROM pg_stat_statements\n            WHERE mean_exec_time &gt; :min_duration\n            ORDER BY mean_exec_time DESC\n            LIMIT 20\n        \"\"\")\n\n        result = await self.db_session.execute(query, {\"min_duration\": min_duration_ms})\n\n        slow_queries = []\n        for row in result:\n            slow_queries.append({\n                'query': row.query[:200] + '...' if len(row.query) &gt; 200 else row.query,\n                'mean_exec_time_ms': float(row.mean_exec_time),\n                'calls': row.calls,\n                'total_exec_time_ms': float(row.total_exec_time),\n                'avg_rows': row.rows / row.calls if row.calls &gt; 0 else 0,\n                'cache_hit_percent': float(row.hit_percent or 0)\n            })\n\n        return slow_queries\n\n    async def analyze_missing_indexes(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Analysiert fehlende Indizes.\"\"\"\n\n        query = text(\"\"\"\n            SELECT\n                schemaname,\n                tablename,\n                attname,\n                n_distinct,\n                correlation\n            FROM pg_stats\n            WHERE schemaname = 'public'\n            AND n_distinct &gt; 100\n            AND correlation &lt; 0.1\n            ORDER BY n_distinct DESC\n        \"\"\")\n\n        result = await self.db_session.execute(query)\n\n        missing_indexes = []\n        for row in result:\n            # Pr\u00fcfen ob Index bereits existiert\n            index_exists = await self._check_index_exists(row.tablename, row.attname)\n\n            if not index_exists:\n                missing_indexes.append({\n                    'table': row.tablename,\n                    'column': row.attname,\n                    'distinct_values': row.n_distinct,\n                    'correlation': float(row.correlation),\n                    'suggested_index': f\"CREATE INDEX idx_{row.tablename}_{row.attname} ON {row.tablename}({row.attname});\"\n                })\n\n        return missing_indexes\n\n    async def _check_index_exists(self, table_name: str, column_name: str) -&gt; bool:\n        \"\"\"Pr\u00fcft ob Index f\u00fcr Spalte existiert.\"\"\"\n\n        query = text(\"\"\"\n            SELECT COUNT(*)\n            FROM pg_indexes\n            WHERE tablename = :table_name\n            AND indexdef LIKE '%' || :column_name || '%'\n        \"\"\")\n\n        result = await self.db_session.execute(query, {\n            \"table_name\": table_name,\n            \"column_name\": column_name\n        })\n\n        return result.scalar() &gt; 0\n\n    async def get_table_statistics(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Ruft Tabellen-Statistiken ab.\"\"\"\n\n        query = text(\"\"\"\n            SELECT\n                schemaname,\n                tablename,\n                n_tup_ins as inserts,\n                n_tup_upd as updates,\n                n_tup_del as deletes,\n                n_live_tup as live_tuples,\n                n_dead_tup as dead_tuples,\n                last_vacuum,\n                last_autovacuum,\n                last_analyze,\n                last_autoanalyze\n            FROM pg_stat_user_tables\n            ORDER BY n_live_tup DESC\n        \"\"\")\n\n        result = await self.db_session.execute(query)\n\n        table_stats = []\n        for row in result:\n            table_stats.append({\n                'table': f\"{row.schemaname}.{row.tablename}\",\n                'inserts': row.inserts,\n                'updates': row.updates,\n                'deletes': row.deletes,\n                'live_tuples': row.live_tuples,\n                'dead_tuples': row.dead_tuples,\n                'dead_tuple_ratio': row.dead_tuples / max(row.live_tuples, 1),\n                'last_vacuum': row.last_vacuum,\n                'last_analyze': row.last_analyze,\n                'needs_vacuum': row.dead_tuples &gt; 1000 and row.dead_tuples / max(row.live_tuples, 1) &gt; 0.1\n            })\n\n        return table_stats\n</code></pre>"},{"location":"troubleshooting/performance/#query-optimization-recommendations","title":"Query Optimization Recommendations","text":"<pre><code># diagnosis/query_optimizer.py\nclass QueryOptimizer:\n    \"\"\"Gibt Query-Optimierungs-Empfehlungen.\"\"\"\n\n    async def analyze_query_plan(self, query: str) -&gt; Dict[str, Any]:\n        \"\"\"Analysiert Query-Execution-Plan.\"\"\"\n\n        explain_query = f\"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) {query}\"\n\n        result = await self.db_session.execute(text(explain_query))\n        plan_data = result.scalar()\n\n        analysis = {\n            'total_cost': plan_data[0]['Plan']['Total Cost'],\n            'execution_time': plan_data[0]['Execution Time'],\n            'planning_time': plan_data[0]['Planning Time'],\n            'recommendations': []\n        }\n\n        # Analyse des Plans\n        plan = plan_data[0]['Plan']\n        analysis['recommendations'].extend(self._analyze_plan_node(plan))\n\n        return analysis\n\n    def _analyze_plan_node(self, node: Dict[str, Any]) -&gt; List[str]:\n        \"\"\"Analysiert einzelnen Plan-Node.\"\"\"\n\n        recommendations = []\n\n        # Sequential Scan Detection\n        if node.get('Node Type') == 'Seq Scan':\n            table_name = node.get('Relation Name', 'unknown')\n            recommendations.append(\n                f\"Sequential Scan auf {table_name} - Index k\u00f6nnte helfen\"\n            )\n\n        # Nested Loop mit hohen Kosten\n        if node.get('Node Type') == 'Nested Loop' and node.get('Total Cost', 0) &gt; 1000:\n            recommendations.append(\n                \"Nested Loop mit hohen Kosten - JOIN-Optimierung pr\u00fcfen\"\n            )\n\n        # Sort mit hohem Memory-Verbrauch\n        if node.get('Node Type') == 'Sort' and node.get('Sort Space Used', 0) &gt; 1000:\n            recommendations.append(\n                \"Sort-Operation mit hohem Memory-Verbrauch - work_mem erh\u00f6hen\"\n            )\n\n        # Hash Join ohne Index\n        if node.get('Node Type') == 'Hash Join':\n            recommendations.append(\n                \"Hash Join - Index auf JOIN-Spalten pr\u00fcfen\"\n            )\n\n        # Rekursive Analyse f\u00fcr Child-Nodes\n        for child in node.get('Plans', []):\n            recommendations.extend(self._analyze_plan_node(child))\n\n        return recommendations\n\n    async def suggest_index_optimizations(self, table_name: str) -&gt; List[str]:\n        \"\"\"Schl\u00e4gt Index-Optimierungen vor.\"\"\"\n\n        suggestions = []\n\n        # H\u00e4ufig verwendete WHERE-Spalten\n        frequent_where_columns = await self._get_frequent_where_columns(table_name)\n        for column in frequent_where_columns:\n            suggestions.append(\n                f\"CREATE INDEX idx_{table_name}_{column} ON {table_name}({column});\"\n            )\n\n        # H\u00e4ufig verwendete ORDER BY-Spalten\n        frequent_order_columns = await self._get_frequent_order_columns(table_name)\n        for column in frequent_order_columns:\n            suggestions.append(\n                f\"CREATE INDEX idx_{table_name}_{column}_order ON {table_name}({column});\"\n            )\n\n        # Composite-Indizes f\u00fcr h\u00e4ufige WHERE-Kombinationen\n        frequent_combinations = await self._get_frequent_column_combinations(table_name)\n        for combination in frequent_combinations:\n            columns = ', '.join(combination)\n            suggestions.append(\n                f\"CREATE INDEX idx_{table_name}_{'_'.join(combination)} ON {table_name}({columns});\"\n            )\n\n        return suggestions\n</code></pre>"},{"location":"troubleshooting/performance/#application-performance-tuning","title":"\ud83d\ude80 Application Performance Tuning","text":""},{"location":"troubleshooting/performance/#async-performance-optimization","title":"Async Performance Optimization","text":"<pre><code># optimization/async_optimizer.py\nimport asyncio\nfrom typing import List, Callable, Any\n\nclass AsyncPerformanceOptimizer:\n    \"\"\"Optimiert Async-Performance.\"\"\"\n\n    def __init__(self, max_concurrent: int = 100):\n        self.max_concurrent = max_concurrent\n        self.semaphore = asyncio.Semaphore(max_concurrent)\n\n    async def batch_process_with_concurrency(\n        self,\n        items: List[Any],\n        processor: Callable,\n        batch_size: int = 50\n    ) -&gt; List[Any]:\n        \"\"\"Verarbeitet Items in Batches mit Concurrency-Control.\"\"\"\n\n        results = []\n\n        # Items in Batches aufteilen\n        for i in range(0, len(items), batch_size):\n            batch = items[i:i + batch_size]\n\n            # Batch parallel verarbeiten\n            batch_tasks = [\n                self._process_with_semaphore(processor, item)\n                for item in batch\n            ]\n\n            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)\n\n            # Erfolgreiche Ergebnisse sammeln\n            for result in batch_results:\n                if not isinstance(result, Exception):\n                    results.append(result)\n                else:\n                    logger.error(f\"Batch processing error: {result}\")\n\n            # Kurze Pause zwischen Batches\n            await asyncio.sleep(0.1)\n\n        return results\n\n    async def _process_with_semaphore(self, processor: Callable, item: Any) -&gt; Any:\n        \"\"\"Verarbeitet Item mit Semaphore-Control.\"\"\"\n\n        async with self.semaphore:\n            return await processor(item)\n\n    async def optimize_database_operations(self, operations: List[Callable]) -&gt; List[Any]:\n        \"\"\"Optimiert Database-Operationen.\"\"\"\n\n        # Operationen nach Typ gruppieren\n        read_ops = [op for op in operations if getattr(op, 'is_read', True)]\n        write_ops = [op for op in operations if not getattr(op, 'is_read', True)]\n\n        # Read-Operationen parallel ausf\u00fchren\n        read_results = await asyncio.gather(*read_ops, return_exceptions=True)\n\n        # Write-Operationen sequenziell ausf\u00fchren (f\u00fcr Konsistenz)\n        write_results = []\n        for write_op in write_ops:\n            try:\n                result = await write_op()\n                write_results.append(result)\n            except Exception as e:\n                logger.error(f\"Write operation failed: {e}\")\n                write_results.append(e)\n\n        return read_results + write_results\n</code></pre>"},{"location":"troubleshooting/performance/#memory-optimization","title":"Memory Optimization","text":"<pre><code># optimization/memory_optimizer.py\nimport gc\nimport weakref\nfrom typing import Dict, Any, Optional\n\nclass MemoryOptimizer:\n    \"\"\"Optimiert Memory-Nutzung.\"\"\"\n\n    def __init__(self):\n        self.object_cache: Dict[str, weakref.WeakValueDictionary] = {}\n        self.memory_threshold_mb = 1000  # 1GB\n\n    def get_cached_object(self, cache_key: str, object_id: str) -&gt; Optional[Any]:\n        \"\"\"Ruft Objekt aus Cache ab.\"\"\"\n\n        if cache_key not in self.object_cache:\n            self.object_cache[cache_key] = weakref.WeakValueDictionary()\n\n        return self.object_cache[cache_key].get(object_id)\n\n    def cache_object(self, cache_key: str, object_id: str, obj: Any) -&gt; None:\n        \"\"\"Cached Objekt.\"\"\"\n\n        if cache_key not in self.object_cache:\n            self.object_cache[cache_key] = weakref.WeakValueDictionary()\n\n        self.object_cache[cache_key][object_id] = obj\n\n    def check_memory_usage(self) -&gt; Dict[str, float]:\n        \"\"\"Pr\u00fcft aktuelle Memory-Nutzung.\"\"\"\n\n        import psutil\n        process = psutil.Process()\n        memory_info = process.memory_info()\n\n        return {\n            'rss_mb': memory_info.rss / 1024 / 1024,\n            'vms_mb': memory_info.vms / 1024 / 1024,\n            'percent': process.memory_percent()\n        }\n\n    async def optimize_memory_if_needed(self) -&gt; bool:\n        \"\"\"Optimiert Memory wenn n\u00f6tig.\"\"\"\n\n        memory_usage = self.check_memory_usage()\n\n        if memory_usage['rss_mb'] &gt; self.memory_threshold_mb:\n            logger.warning(f\"High memory usage: {memory_usage['rss_mb']:.1f}MB\")\n\n            # Garbage Collection erzwingen\n            collected = gc.collect()\n            logger.info(f\"Garbage collection freed {collected} objects\")\n\n            # Cache leeren\n            self.clear_caches()\n\n            # Memory-Usage nach Optimierung pr\u00fcfen\n            new_memory_usage = self.check_memory_usage()\n            memory_freed = memory_usage['rss_mb'] - new_memory_usage['rss_mb']\n\n            logger.info(f\"Memory optimization freed {memory_freed:.1f}MB\")\n\n            return memory_freed &gt; 50  # Erfolgreich wenn &gt;50MB befreit\n\n        return False\n\n    def clear_caches(self) -&gt; None:\n        \"\"\"Leert alle Caches.\"\"\"\n\n        for cache in self.object_cache.values():\n            cache.clear()\n\n        logger.info(\"All caches cleared\")\n\n# Memory-optimierter Decorator\ndef memory_optimized(func):\n    \"\"\"Decorator f\u00fcr Memory-Optimierung.\"\"\"\n\n    optimizer = MemoryOptimizer()\n\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        # Memory vor Ausf\u00fchrung pr\u00fcfen\n        await optimizer.optimize_memory_if_needed()\n\n        try:\n            result = await func(*args, **kwargs)\n            return result\n        finally:\n            # Memory nach Ausf\u00fchrung pr\u00fcfen\n            await optimizer.optimize_memory_if_needed()\n\n    return wrapper\n</code></pre>"},{"location":"troubleshooting/performance/#performance-testing","title":"\ud83d\udcc8 Performance Testing","text":""},{"location":"troubleshooting/performance/#load-testing","title":"Load Testing","text":"<pre><code># testing/load_test.py\nimport asyncio\nimport aiohttp\nimport time\nfrom dataclasses import dataclass\nfrom typing import List\n\n@dataclass\nclass LoadTestResult:\n    \"\"\"Load-Test-Ergebnis.\"\"\"\n    total_requests: int\n    successful_requests: int\n    failed_requests: int\n    avg_response_time: float\n    p95_response_time: float\n    p99_response_time: float\n    requests_per_second: float\n    error_rate: float\n\nclass LoadTester:\n    \"\"\"Load-Tester f\u00fcr Keiko API.\"\"\"\n\n    def __init__(self, base_url: str, auth_token: str):\n        self.base_url = base_url\n        self.auth_token = auth_token\n        self.response_times: List[float] = []\n        self.errors: List[str] = []\n\n    async def run_load_test(\n        self,\n        endpoint: str,\n        concurrent_users: int = 50,\n        duration_seconds: int = 300,\n        request_data: dict = None\n    ) -&gt; LoadTestResult:\n        \"\"\"F\u00fchrt Load-Test aus.\"\"\"\n\n        start_time = time.time()\n        end_time = start_time + duration_seconds\n\n        # Semaphore f\u00fcr Concurrency-Control\n        semaphore = asyncio.Semaphore(concurrent_users)\n\n        # Tasks f\u00fcr alle User starten\n        tasks = []\n        for user_id in range(concurrent_users):\n            task = asyncio.create_task(\n                self._user_session(semaphore, endpoint, end_time, request_data, user_id)\n            )\n            tasks.append(task)\n\n        # Auf alle Tasks warten\n        await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Ergebnisse berechnen\n        return self._calculate_results(duration_seconds)\n\n    async def _user_session(\n        self,\n        semaphore: asyncio.Semaphore,\n        endpoint: str,\n        end_time: float,\n        request_data: dict,\n        user_id: int\n    ):\n        \"\"\"Simuliert einzelne User-Session.\"\"\"\n\n        async with aiohttp.ClientSession() as session:\n            while time.time() &lt; end_time:\n                async with semaphore:\n                    await self._make_request(session, endpoint, request_data, user_id)\n\n                # Kurze Pause zwischen Requests\n                await asyncio.sleep(0.1)\n\n    async def _make_request(\n        self,\n        session: aiohttp.ClientSession,\n        endpoint: str,\n        request_data: dict,\n        user_id: int\n    ):\n        \"\"\"Macht einzelnen Request.\"\"\"\n\n        url = f\"{self.base_url}{endpoint}\"\n        headers = {\"Authorization\": f\"Bearer {self.auth_token}\"}\n\n        start_time = time.time()\n\n        try:\n            if request_data:\n                async with session.post(url, json=request_data, headers=headers) as response:\n                    await response.text()  # Response lesen\n                    response_time = time.time() - start_time\n                    self.response_times.append(response_time * 1000)  # ms\n\n                    if response.status &gt;= 400:\n                        self.errors.append(f\"HTTP {response.status}\")\n            else:\n                async with session.get(url, headers=headers) as response:\n                    await response.text()\n                    response_time = time.time() - start_time\n                    self.response_times.append(response_time * 1000)  # ms\n\n                    if response.status &gt;= 400:\n                        self.errors.append(f\"HTTP {response.status}\")\n\n        except Exception as e:\n            response_time = time.time() - start_time\n            self.response_times.append(response_time * 1000)\n            self.errors.append(str(e))\n\n    def _calculate_results(self, duration_seconds: int) -&gt; LoadTestResult:\n        \"\"\"Berechnet Test-Ergebnisse.\"\"\"\n\n        total_requests = len(self.response_times)\n        failed_requests = len(self.errors)\n        successful_requests = total_requests - failed_requests\n\n        if self.response_times:\n            avg_response_time = sum(self.response_times) / len(self.response_times)\n            sorted_times = sorted(self.response_times)\n            p95_index = int(len(sorted_times) * 0.95)\n            p99_index = int(len(sorted_times) * 0.99)\n            p95_response_time = sorted_times[p95_index]\n            p99_response_time = sorted_times[p99_index]\n        else:\n            avg_response_time = 0\n            p95_response_time = 0\n            p99_response_time = 0\n\n        requests_per_second = total_requests / duration_seconds\n        error_rate = (failed_requests / total_requests * 100) if total_requests &gt; 0 else 0\n\n        return LoadTestResult(\n            total_requests=total_requests,\n            successful_requests=successful_requests,\n            failed_requests=failed_requests,\n            avg_response_time=avg_response_time,\n            p95_response_time=p95_response_time,\n            p99_response_time=p99_response_time,\n            requests_per_second=requests_per_second,\n            error_rate=error_rate\n        )\n\n# Load-Test ausf\u00fchren\nasync def run_api_load_test():\n    \"\"\"F\u00fchrt API-Load-Test aus.\"\"\"\n\n    tester = LoadTester(\n        base_url=\"http://localhost:8000\",\n        auth_token=\"your-auth-token\"\n    )\n\n    # Agent-Listing-Test\n    result = await tester.run_load_test(\n        endpoint=\"/api/v1/agents\",\n        concurrent_users=50,\n        duration_seconds=300\n    )\n\n    print(f\"Load Test Results:\")\n    print(f\"Total Requests: {result.total_requests}\")\n    print(f\"Successful: {result.successful_requests}\")\n    print(f\"Failed: {result.failed_requests}\")\n    print(f\"Avg Response Time: {result.avg_response_time:.1f}ms\")\n    print(f\"P95 Response Time: {result.p95_response_time:.1f}ms\")\n    print(f\"P99 Response Time: {result.p99_response_time:.1f}ms\")\n    print(f\"Requests/sec: {result.requests_per_second:.1f}\")\n    print(f\"Error Rate: {result.error_rate:.2f}%\")\n\nif __name__ == \"__main__\":\n    asyncio.run(run_api_load_test())\n</code></pre> <p>Performance-Optimierung-Tipps</p> <ul> <li>\u00dcberwachen Sie kontinuierlich die Key-Performance-Indicators</li> <li>Nutzen Sie Database-Query-Analyse f\u00fcr Optimierungen</li> <li>Implementieren Sie effektive Caching-Strategien</li> <li>Optimieren Sie Async-Operations f\u00fcr bessere Concurrency</li> <li>F\u00fchren Sie regelm\u00e4\u00dfige Load-Tests durch</li> </ul> <p>Performance-Monitoring</p> <ul> <li>Setzen Sie realistische Performance-Ziele</li> <li>\u00dcberwachen Sie Trends, nicht nur absolute Werte</li> <li>Ber\u00fccksichtigen Sie Business-Kontext bei Optimierungen</li> <li>Dokumentieren Sie Performance-\u00c4nderungen</li> </ul>"},{"location":"troubleshooting/security/","title":"\ud83d\udd12 Security Troubleshooting","text":"<p>Leitfaden zur Diagnose und Behebung von Sicherheitsproblemen in Keiko Personal Assistant.</p>"},{"location":"troubleshooting/security/#authentication-issues","title":"\ud83d\udd10 Authentication Issues","text":""},{"location":"troubleshooting/security/#jwt-token-problems","title":"JWT Token Problems","text":"<p>Problem: JWT-Token werden nicht akzeptiert oder sind ung\u00fcltig.</p> <p>Diagnose: <pre><code># Token-Validierung testen\ncurl -H \"Authorization: Bearer $TOKEN\" http://localhost:8000/api/v1/auth/validate\n\n# Token-Details dekodieren (ohne Verifikation)\necho $TOKEN | cut -d. -f2 | base64 -d | jq\n\n# Token-Expiration pr\u00fcfen\npython3 -c \"\nimport jwt\nimport json\ntoken = '$TOKEN'\ndecoded = jwt.decode(token, options={'verify_signature': False})\nprint(json.dumps(decoded, indent=2))\n\"\n</code></pre></p> <p>H\u00e4ufige Ursachen &amp; L\u00f6sungen:</p> <ol> <li> <p>Abgelaufene Tokens <pre><code># auth/token_validator.py\nimport jwt\nfrom datetime import datetime, timezone\n\ndef validate_token_expiration(token: str) -&gt; bool:\n    \"\"\"Pr\u00fcft Token-Expiration.\"\"\"\n    try:\n        decoded = jwt.decode(token, options={\"verify_signature\": False})\n        exp = decoded.get('exp')\n\n        if exp:\n            exp_datetime = datetime.fromtimestamp(exp, tz=timezone.utc)\n            now = datetime.now(timezone.utc)\n\n            if exp_datetime &lt; now:\n                logger.warning(f\"Token expired at {exp_datetime}, current time: {now}\")\n                return False\n\n        return True\n    except Exception as e:\n        logger.error(f\"Token validation error: {e}\")\n        return False\n\n# Token-Refresh implementieren\nasync def refresh_token_if_needed(token: str) -&gt; str:\n    \"\"\"Refresht Token wenn n\u00f6tig.\"\"\"\n\n    if not validate_token_expiration(token):\n        # Token refresh\n        refresh_token = get_refresh_token()\n        new_token = await auth_service.refresh_access_token(refresh_token)\n        return new_token\n\n    return token\n</code></pre></p> </li> <li> <p>Falsche Signatur <pre><code># config/jwt_config.py\nimport os\nfrom cryptography.hazmat.primitives import serialization\n\n# JWT-Konfiguration validieren\nJWT_SECRET = os.getenv('JWT_SECRET')\nJWT_ALGORITHM = os.getenv('JWT_ALGORITHM', 'HS256')\n\nif not JWT_SECRET:\n    raise ValueError(\"JWT_SECRET environment variable required\")\n\n# F\u00fcr RS256/ES256 - Public/Private Key validieren\nif JWT_ALGORITHM.startswith('RS') or JWT_ALGORITHM.startswith('ES'):\n    private_key_path = os.getenv('JWT_PRIVATE_KEY_PATH')\n    public_key_path = os.getenv('JWT_PUBLIC_KEY_PATH')\n\n    if not private_key_path or not public_key_path:\n        raise ValueError(\"Private/Public key paths required for asymmetric algorithms\")\n\n    # Keys laden und validieren\n    with open(private_key_path, 'rb') as f:\n        private_key = serialization.load_pem_private_key(f.read(), password=None)\n\n    with open(public_key_path, 'rb') as f:\n        public_key = serialization.load_pem_public_key(f.read())\n</code></pre></p> </li> <li> <p>Token-Format-Probleme <pre><code># auth/token_extractor.py\nimport re\nfrom fastapi import HTTPException, Request\n\ndef extract_bearer_token(request: Request) -&gt; str:\n    \"\"\"Extrahiert Bearer-Token aus Request.\"\"\"\n\n    auth_header = request.headers.get('Authorization')\n\n    if not auth_header:\n        raise HTTPException(401, \"Authorization header missing\")\n\n    # Bearer-Token-Format validieren\n    bearer_pattern = r'^Bearer\\s+([A-Za-z0-9\\-_]+\\.[A-Za-z0-9\\-_]+\\.[A-Za-z0-9\\-_]+)$'\n    match = re.match(bearer_pattern, auth_header)\n\n    if not match:\n        raise HTTPException(401, \"Invalid Authorization header format\")\n\n    return match.group(1)\n\n# Alternative Token-Quellen\ndef extract_token_from_multiple_sources(request: Request) -&gt; str:\n    \"\"\"Extrahiert Token aus verschiedenen Quellen.\"\"\"\n\n    # 1. Authorization Header\n    auth_header = request.headers.get('Authorization')\n    if auth_header and auth_header.startswith('Bearer '):\n        return auth_header[7:]\n\n    # 2. Query Parameter (f\u00fcr WebSocket)\n    token = request.query_params.get('token')\n    if token:\n        return token\n\n    # 3. Cookie (falls konfiguriert)\n    token = request.cookies.get('access_token')\n    if token:\n        return token\n\n    raise HTTPException(401, \"No valid token found\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/security/#session-management-issues","title":"Session Management Issues","text":"<p>Problem: Session-Probleme bei Multi-Instance-Deployment.</p> <p>Diagnose: <pre><code># Redis-Session-Keys pr\u00fcfen\nredis-cli keys \"session:*\"\n\n# Session-Details anzeigen\nredis-cli hgetall \"session:user123\"\n\n# Session-Expiration pr\u00fcfen\nredis-cli ttl \"session:user123\"\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Sticky Sessions konfigurieren <pre><code># nginx.conf\nupstream keiko_backend {\n    ip_hash;  # Sticky sessions basierend auf Client-IP\n    server keiko-app-1:8000;\n    server keiko-app-2:8000;\n    server keiko-app-3:8000;\n}\n</code></pre></p> </li> <li> <p>Shared Session Storage <pre><code># session/redis_session_store.py\nimport redis.asyncio as redis\nimport json\nfrom typing import Dict, Any, Optional\n\nclass RedisSessionStore:\n    \"\"\"Redis-basierter Session-Store.\"\"\"\n\n    def __init__(self, redis_url: str, session_ttl: int = 3600):\n        self.redis = redis.from_url(redis_url)\n        self.session_ttl = session_ttl\n\n    async def create_session(self, user_id: str, session_data: Dict[str, Any]) -&gt; str:\n        \"\"\"Erstellt neue Session.\"\"\"\n\n        session_id = generate_session_id()\n        session_key = f\"session:{session_id}\"\n\n        session_data.update({\n            'user_id': user_id,\n            'created_at': time.time(),\n            'last_accessed': time.time()\n        })\n\n        await self.redis.hset(session_key, mapping={\n            k: json.dumps(v) if not isinstance(v, str) else v\n            for k, v in session_data.items()\n        })\n\n        await self.redis.expire(session_key, self.session_ttl)\n\n        return session_id\n\n    async def get_session(self, session_id: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Ruft Session-Daten ab.\"\"\"\n\n        session_key = f\"session:{session_id}\"\n        session_data = await self.redis.hgetall(session_key)\n\n        if not session_data:\n            return None\n\n        # Last-accessed aktualisieren\n        await self.redis.hset(session_key, 'last_accessed', time.time())\n        await self.redis.expire(session_key, self.session_ttl)\n\n        # JSON-Daten dekodieren\n        decoded_data = {}\n        for key, value in session_data.items():\n            try:\n                decoded_data[key] = json.loads(value)\n            except (json.JSONDecodeError, TypeError):\n                decoded_data[key] = value\n\n        return decoded_data\n\n    async def delete_session(self, session_id: str) -&gt; bool:\n        \"\"\"L\u00f6scht Session.\"\"\"\n\n        session_key = f\"session:{session_id}\"\n        deleted = await self.redis.delete(session_key)\n\n        return deleted &gt; 0\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/security/#authorization-problems","title":"\ud83d\udee1\ufe0f Authorization Problems","text":""},{"location":"troubleshooting/security/#rbac-permission-issues","title":"RBAC Permission Issues","text":"<p>Problem: Benutzer haben nicht die erwarteten Berechtigungen.</p> <p>Diagnose: <pre><code># debug/permission_debugger.py\nasync def debug_user_permissions(user_id: str) -&gt; Dict[str, Any]:\n    \"\"\"Debuggt Benutzer-Berechtigungen.\"\"\"\n\n    user = await user_service.get_user(user_id)\n    if not user:\n        return {\"error\": \"User not found\"}\n\n    # Rollen abrufen\n    user_roles = await rbac_service.get_user_roles(user_id)\n\n    # Berechtigungen f\u00fcr jede Rolle\n    role_permissions = {}\n    for role in user_roles:\n        permissions = await rbac_service.get_role_permissions(role.name)\n        role_permissions[role.name] = [p.name for p in permissions]\n\n    # Effektive Berechtigungen\n    effective_permissions = await rbac_service.get_user_permissions(user_id)\n\n    return {\n        \"user_id\": user_id,\n        \"username\": user.username,\n        \"roles\": [r.name for r in user_roles],\n        \"role_permissions\": role_permissions,\n        \"effective_permissions\": [p.name for p in effective_permissions],\n        \"permission_count\": len(effective_permissions)\n    }\n\n# Permission-Check mit Debugging\nasync def check_permission_with_debug(user_id: str, permission: str) -&gt; Dict[str, Any]:\n    \"\"\"Pr\u00fcft Berechtigung mit Debug-Informationen.\"\"\"\n\n    has_permission = await rbac_service.check_permission(user_id, permission)\n\n    debug_info = await debug_user_permissions(user_id)\n    debug_info.update({\n        \"requested_permission\": permission,\n        \"has_permission\": has_permission,\n        \"permission_source\": None\n    })\n\n    # Quelle der Berechtigung finden\n    if has_permission:\n        for role, permissions in debug_info[\"role_permissions\"].items():\n            if permission in permissions:\n                debug_info[\"permission_source\"] = role\n                break\n\n    return debug_info\n</code></pre></p> <p>L\u00f6sungen:</p> <ol> <li> <p>Permission-Inheritance pr\u00fcfen <pre><code># rbac/permission_resolver.py\nclass PermissionResolver:\n    \"\"\"L\u00f6st Berechtigungen mit Inheritance auf.\"\"\"\n\n    async def resolve_user_permissions(self, user_id: str) -&gt; Set[str]:\n        \"\"\"L\u00f6st alle Benutzer-Berechtigungen auf.\"\"\"\n\n        permissions = set()\n\n        # Direkte Benutzer-Berechtigungen\n        user_permissions = await self.get_direct_user_permissions(user_id)\n        permissions.update(p.name for p in user_permissions)\n\n        # Rollen-basierte Berechtigungen\n        user_roles = await self.get_user_roles(user_id)\n        for role in user_roles:\n            role_permissions = await self.resolve_role_permissions(role.name)\n            permissions.update(role_permissions)\n\n        return permissions\n\n    async def resolve_role_permissions(self, role_name: str) -&gt; Set[str]:\n        \"\"\"L\u00f6st Rollen-Berechtigungen mit Inheritance auf.\"\"\"\n\n        permissions = set()\n        visited_roles = set()\n\n        await self._resolve_role_permissions_recursive(role_name, permissions, visited_roles)\n\n        return permissions\n\n    async def _resolve_role_permissions_recursive(\n        self,\n        role_name: str,\n        permissions: Set[str],\n        visited_roles: Set[str]\n    ):\n        \"\"\"Rekursive Aufl\u00f6sung von Rollen-Inheritance.\"\"\"\n\n        if role_name in visited_roles:\n            return  # Zirkul\u00e4re Abh\u00e4ngigkeit vermeiden\n\n        visited_roles.add(role_name)\n\n        # Direkte Rollen-Berechtigungen\n        role_permissions = await self.get_direct_role_permissions(role_name)\n        permissions.update(p.name for p in role_permissions)\n\n        # Parent-Rollen\n        parent_roles = await self.get_parent_roles(role_name)\n        for parent_role in parent_roles:\n            await self._resolve_role_permissions_recursive(\n                parent_role.name, permissions, visited_roles\n            )\n</code></pre></p> </li> <li> <p>Permission-Caching optimieren <pre><code># rbac/permission_cache.py\nimport asyncio\nfrom typing import Set, Optional\n\nclass PermissionCache:\n    \"\"\"Cache f\u00fcr Berechtigungen.\"\"\"\n\n    def __init__(self, redis_client, cache_ttl: int = 300):\n        self.redis = redis_client\n        self.cache_ttl = cache_ttl\n        self.local_cache: Dict[str, Set[str]] = {}\n        self.cache_timestamps: Dict[str, float] = {}\n\n    async def get_user_permissions(self, user_id: str) -&gt; Optional[Set[str]]:\n        \"\"\"Ruft Benutzer-Berechtigungen aus Cache ab.\"\"\"\n\n        # L1: Local Cache\n        if self._is_local_cache_valid(user_id):\n            return self.local_cache[user_id]\n\n        # L2: Redis Cache\n        cache_key = f\"permissions:user:{user_id}\"\n        cached_permissions = await self.redis.smembers(cache_key)\n\n        if cached_permissions:\n            permissions = set(cached_permissions)\n            self._update_local_cache(user_id, permissions)\n            return permissions\n\n        return None\n\n    async def cache_user_permissions(self, user_id: str, permissions: Set[str]):\n        \"\"\"Cached Benutzer-Berechtigungen.\"\"\"\n\n        # L1: Local Cache\n        self._update_local_cache(user_id, permissions)\n\n        # L2: Redis Cache\n        cache_key = f\"permissions:user:{user_id}\"\n\n        if permissions:\n            await self.redis.sadd(cache_key, *permissions)\n            await self.redis.expire(cache_key, self.cache_ttl)\n\n    async def invalidate_user_permissions(self, user_id: str):\n        \"\"\"Invalidiert Benutzer-Berechtigungen-Cache.\"\"\"\n\n        # Local Cache\n        self.local_cache.pop(user_id, None)\n        self.cache_timestamps.pop(user_id, None)\n\n        # Redis Cache\n        cache_key = f\"permissions:user:{user_id}\"\n        await self.redis.delete(cache_key)\n\n    def _is_local_cache_valid(self, user_id: str) -&gt; bool:\n        \"\"\"Pr\u00fcft ob Local-Cache g\u00fcltig ist.\"\"\"\n\n        if user_id not in self.local_cache:\n            return False\n\n        timestamp = self.cache_timestamps.get(user_id, 0)\n        return time.time() - timestamp &lt; self.cache_ttl\n\n    def _update_local_cache(self, user_id: str, permissions: Set[str]):\n        \"\"\"Aktualisiert Local-Cache.\"\"\"\n\n        self.local_cache[user_id] = permissions\n        self.cache_timestamps[user_id] = time.time()\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/security/#security-audit-monitoring","title":"\ud83d\udd0d Security Audit &amp; Monitoring","text":""},{"location":"troubleshooting/security/#security-event-detection","title":"Security Event Detection","text":"<pre><code># security/event_detector.py\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Any\nfrom enum import Enum\n\nclass SecurityEventType(Enum):\n    FAILED_LOGIN = \"failed_login\"\n    SUSPICIOUS_ACTIVITY = \"suspicious_activity\"\n    PRIVILEGE_ESCALATION = \"privilege_escalation\"\n    DATA_ACCESS_VIOLATION = \"data_access_violation\"\n    RATE_LIMIT_EXCEEDED = \"rate_limit_exceeded\"\n\n@dataclass\nclass SecurityEvent:\n    event_type: SecurityEventType\n    user_id: Optional[str]\n    ip_address: str\n    user_agent: str\n    timestamp: datetime\n    details: Dict[str, Any]\n    severity: str  # low, medium, high, critical\n\nclass SecurityEventDetector:\n    \"\"\"Erkennt Security-Events.\"\"\"\n\n    def __init__(self):\n        self.failed_login_attempts: Dict[str, List[datetime]] = {}\n        self.suspicious_ips: Set[str] = set()\n\n    async def detect_failed_login_pattern(\n        self,\n        user_id: str,\n        ip_address: str,\n        user_agent: str\n    ) -&gt; Optional[SecurityEvent]:\n        \"\"\"Erkennt Failed-Login-Patterns.\"\"\"\n\n        now = datetime.utcnow()\n        key = f\"{user_id}:{ip_address}\"\n\n        # Failed-Login-Attempts tracken\n        if key not in self.failed_login_attempts:\n            self.failed_login_attempts[key] = []\n\n        self.failed_login_attempts[key].append(now)\n\n        # Alte Attempts entfernen (\u00e4lter als 1 Stunde)\n        cutoff = now - timedelta(hours=1)\n        self.failed_login_attempts[key] = [\n            attempt for attempt in self.failed_login_attempts[key]\n            if attempt &gt; cutoff\n        ]\n\n        # Threshold pr\u00fcfen\n        if len(self.failed_login_attempts[key]) &gt;= 5:\n            return SecurityEvent(\n                event_type=SecurityEventType.FAILED_LOGIN,\n                user_id=user_id,\n                ip_address=ip_address,\n                user_agent=user_agent,\n                timestamp=now,\n                details={\n                    \"failed_attempts\": len(self.failed_login_attempts[key]),\n                    \"time_window\": \"1 hour\"\n                },\n                severity=\"high\"\n            )\n\n        return None\n\n    async def detect_privilege_escalation(\n        self,\n        user_id: str,\n        old_permissions: Set[str],\n        new_permissions: Set[str],\n        ip_address: str\n    ) -&gt; Optional[SecurityEvent]:\n        \"\"\"Erkennt Privilege-Escalation.\"\"\"\n\n        added_permissions = new_permissions - old_permissions\n\n        # Kritische Berechtigungen pr\u00fcfen\n        critical_permissions = {\n            \"system:admin\", \"users:delete\", \"agents:delete\",\n            \"system:config\", \"security:manage\"\n        }\n\n        critical_added = added_permissions &amp; critical_permissions\n\n        if critical_added:\n            return SecurityEvent(\n                event_type=SecurityEventType.PRIVILEGE_ESCALATION,\n                user_id=user_id,\n                ip_address=ip_address,\n                user_agent=\"\",\n                timestamp=datetime.utcnow(),\n                details={\n                    \"added_permissions\": list(added_permissions),\n                    \"critical_permissions\": list(critical_added)\n                },\n                severity=\"critical\"\n            )\n\n        return None\n\n    async def detect_suspicious_activity(\n        self,\n        user_id: str,\n        action: str,\n        resource: str,\n        ip_address: str,\n        user_agent: str\n    ) -&gt; Optional[SecurityEvent]:\n        \"\"\"Erkennt verd\u00e4chtige Aktivit\u00e4ten.\"\"\"\n\n        # Ungew\u00f6hnliche IP-Adressen\n        user_ips = await self.get_user_ip_history(user_id)\n        if ip_address not in user_ips and len(user_ips) &gt; 0:\n            # Geolocation-Check\n            user_country = await self.get_ip_country(user_ips[0])\n            current_country = await self.get_ip_country(ip_address)\n\n            if user_country != current_country:\n                return SecurityEvent(\n                    event_type=SecurityEventType.SUSPICIOUS_ACTIVITY,\n                    user_id=user_id,\n                    ip_address=ip_address,\n                    user_agent=user_agent,\n                    timestamp=datetime.utcnow(),\n                    details={\n                        \"reason\": \"unusual_location\",\n                        \"user_country\": user_country,\n                        \"current_country\": current_country,\n                        \"action\": action,\n                        \"resource\": resource\n                    },\n                    severity=\"medium\"\n                )\n\n        # Ungew\u00f6hnliche Zeiten\n        now = datetime.utcnow()\n        if now.hour &lt; 6 or now.hour &gt; 22:  # Au\u00dferhalb Gesch\u00e4ftszeiten\n            return SecurityEvent(\n                event_type=SecurityEventType.SUSPICIOUS_ACTIVITY,\n                user_id=user_id,\n                ip_address=ip_address,\n                user_agent=user_agent,\n                timestamp=now,\n                details={\n                    \"reason\": \"unusual_time\",\n                    \"hour\": now.hour,\n                    \"action\": action,\n                    \"resource\": resource\n                },\n                severity=\"low\"\n            )\n\n        return None\n\n# Security-Event-Handler\nclass SecurityEventHandler:\n    \"\"\"Behandelt Security-Events.\"\"\"\n\n    async def handle_security_event(self, event: SecurityEvent):\n        \"\"\"Behandelt Security-Event.\"\"\"\n\n        # Event protokollieren\n        await self.log_security_event(event)\n\n        # Automatische Reaktionen\n        if event.severity == \"critical\":\n            await self.handle_critical_event(event)\n        elif event.severity == \"high\":\n            await self.handle_high_severity_event(event)\n\n        # Benachrichtigungen senden\n        await self.send_security_notification(event)\n\n    async def handle_critical_event(self, event: SecurityEvent):\n        \"\"\"Behandelt kritische Security-Events.\"\"\"\n\n        if event.event_type == SecurityEventType.PRIVILEGE_ESCALATION:\n            # Benutzer tempor\u00e4r sperren\n            await self.temporarily_lock_user(event.user_id, duration_minutes=30)\n\n            # Admin-Benachrichtigung\n            await self.notify_security_team(event)\n\n        elif event.event_type == SecurityEventType.DATA_ACCESS_VIOLATION:\n            # Zugriff protokollieren und blockieren\n            await self.block_ip_address(event.ip_address, duration_hours=24)\n\n    async def handle_high_severity_event(self, event: SecurityEvent):\n        \"\"\"Behandelt High-Severity-Events.\"\"\"\n\n        if event.event_type == SecurityEventType.FAILED_LOGIN:\n            # IP-Adresse tempor\u00e4r blockieren\n            await self.rate_limit_ip(event.ip_address, duration_minutes=15)\n\n            # Benutzer \u00fcber verd\u00e4chtige Aktivit\u00e4t informieren\n            await self.notify_user_suspicious_activity(event.user_id, event)\n</code></pre>"},{"location":"troubleshooting/security/#security-compliance-monitoring","title":"Security Compliance Monitoring","text":"<pre><code># security/compliance_monitor.py\nclass ComplianceMonitor:\n    \"\"\"\u00dcberwacht Security-Compliance.\"\"\"\n\n    async def check_gdpr_compliance(self) -&gt; Dict[str, bool]:\n        \"\"\"Pr\u00fcft GDPR-Compliance.\"\"\"\n\n        checks = {\n            \"data_encryption\": await self.check_data_encryption(),\n            \"access_logging\": await self.check_access_logging(),\n            \"data_retention\": await self.check_data_retention_policy(),\n            \"user_consent\": await self.check_user_consent_tracking(),\n            \"data_portability\": await self.check_data_portability_support(),\n            \"right_to_erasure\": await self.check_erasure_capability()\n        }\n\n        return checks\n\n    async def check_security_headers(self) -&gt; Dict[str, bool]:\n        \"\"\"Pr\u00fcft Security-Headers.\"\"\"\n\n        # Test-Request an API\n        async with aiohttp.ClientSession() as session:\n            async with session.get(\"http://localhost:8000/health\") as response:\n                headers = response.headers\n\n                return {\n                    \"strict_transport_security\": \"Strict-Transport-Security\" in headers,\n                    \"content_security_policy\": \"Content-Security-Policy\" in headers,\n                    \"x_frame_options\": \"X-Frame-Options\" in headers,\n                    \"x_content_type_options\": \"X-Content-Type-Options\" in headers,\n                    \"x_xss_protection\": \"X-XSS-Protection\" in headers,\n                    \"referrer_policy\": \"Referrer-Policy\" in headers\n                }\n\n    async def check_password_policy_compliance(self) -&gt; Dict[str, Any]:\n        \"\"\"Pr\u00fcft Password-Policy-Compliance.\"\"\"\n\n        # Schwache Passw\u00f6rter in Database pr\u00fcfen\n        weak_passwords = await self.find_weak_passwords()\n\n        # Password-Policy-Einstellungen pr\u00fcfen\n        policy = await self.get_password_policy()\n\n        return {\n            \"min_length_enforced\": policy.min_length &gt;= 8,\n            \"complexity_enforced\": policy.require_special_chars and policy.require_numbers,\n            \"weak_passwords_count\": len(weak_passwords),\n            \"password_expiry_enabled\": policy.max_age_days is not None,\n            \"password_history_enabled\": policy.history_count &gt; 0\n        }\n</code></pre> <p>Security-Alerts</p> <p>Bei kritischen Security-Events: - Sofortige Benachrichtigung des Security-Teams - Automatische Sperrung betroffener Accounts - Detaillierte Forensik-Logs erstellen - Incident-Response-Prozess aktivieren</p> <p>Security-Best-Practices</p> <ul> <li>Implementieren Sie umfassende Security-Event-Detection</li> <li>Nutzen Sie Multi-Factor-Authentication f\u00fcr privilegierte Accounts</li> <li>\u00dcberwachen Sie kontinuierlich Compliance-Status</li> <li>F\u00fchren Sie regelm\u00e4\u00dfige Security-Audits durch</li> <li>Dokumentieren Sie alle Security-Incidents</li> </ul>"},{"location":"user-guide/","title":"Benutzerhandbuch","text":"<p>Willkommen zum Benutzerhandbuch des KEI-Agent Python SDK! Dieses Handbuch f\u00fchrt Sie durch alle wichtigen Konzepte und Funktionen des SDK.</p>"},{"location":"user-guide/#ubersicht","title":"\ud83d\udcda \u00dcbersicht","text":"<p>Das KEI-Agent Python SDK bietet eine umfassende, typisierte API f\u00fcr die Interaktion mit dem KEI-Agent Framework. Es unterst\u00fctzt mehrere Kommunikationsprotokolle und bietet Enterprise-Features f\u00fcr produktive Umgebungen.</p>"},{"location":"user-guide/#zielgruppe","title":"\ud83c\udfaf Zielgruppe","text":"<p>Dieses Handbuch richtet sich an:</p> <ul> <li>Python-Entwickler, die Agent-basierte Anwendungen entwickeln</li> <li>DevOps-Engineers, die KEI-Agent in produktive Umgebungen integrieren</li> <li>Architekten, die Multi-Agent-Systeme entwerfen</li> </ul>"},{"location":"user-guide/#kapitel","title":"\ud83d\udcd6 Kapitel","text":""},{"location":"user-guide/#basis-konzepte","title":"Basis-Konzepte","text":"<p>Verstehen Sie die grundlegenden Konzepte des KEI-Agent Framework: - Agent-Architektur - Protokoll-Typen - Sicherheitsmodell - Konfigurationsmanagement</p>"},{"location":"user-guide/#client-verwendung","title":"Client-Verwendung","text":"<p>Lernen Sie, wie Sie den UnifiedKeiAgentClient verwenden: - Client-Initialisierung - Basis-Operationen - Asynchrone Programmierung - Fehlerbehandlung</p>"},{"location":"user-guide/#protokolle","title":"Protokolle","text":"<p>Detaillierte Informationen zu den unterst\u00fctzten Protokollen: - RPC (Remote Procedure Call) - Stream (WebSocket-basiert) - Bus (Message Bus) - MCP (Model Context Protocol)</p>"},{"location":"user-guide/#authentifizierung","title":"Authentifizierung","text":"<p>Sicherheitsaspekte und Authentifizierung: - Bearer Token - OIDC (OpenID Connect) - mTLS (Mutual TLS) - Sicherheitskonfiguration</p>"},{"location":"user-guide/#fehlerbehandlung","title":"Fehlerbehandlung","text":"<p>Robuste Fehlerbehandlung und Retry-Strategien: - Exception-Hierarchie - Retry-Policies - Circuit Breaker - Fallback-Mechanismen</p>"},{"location":"user-guide/#schnellstart","title":"\ud83d\ude80 Schnellstart","text":"<pre><code>from kei_agent import UnifiedKeiAgentClient, AgentClientConfig\n\n# Client konfigurieren\nconfig = AgentClientConfig(\n    base_url=\"https://your-kei-agent.com\",\n    api_token=\"your-api-token\",\n    agent_id=\"your-agent-id\"\n)\n\n# Client erstellen und verwenden\nasync with UnifiedKeiAgentClient(config) as client:\n    # Agent-Operation ausf\u00fchren\n    result = await client.plan_task(\"Analysiere die Verkaufsdaten\")\n    print(f\"Plan: {result}\")\n</code></pre>"},{"location":"user-guide/#tipps-fur-einsteiger","title":"\ud83d\udca1 Tipps f\u00fcr Einsteiger","text":"<ol> <li>Beginnen Sie mit den Basis-Konzepten - Verstehen Sie die Grundlagen</li> <li>Folgen Sie dem Quick Start Guide - Erste praktische Schritte</li> <li>Experimentieren Sie mit Beispielen - Lernen Sie durch Praxis</li> <li>Nutzen Sie die API-Referenz - Detaillierte Dokumentation</li> </ol>"},{"location":"user-guide/#weiterfuhrende-ressourcen","title":"\ud83d\udd17 Weiterf\u00fchrende Ressourcen","text":"<ul> <li>Enterprise Features - Produktive Funktionen</li> <li>Architektur - Technische Details</li> <li>Troubleshooting - Probleml\u00f6sung</li> <li>Migration - Upgrade-Anleitungen</li> </ul>"},{"location":"user-guide/#support","title":"\ud83d\udcde Support","text":"<p>Bei Fragen oder Problemen:</p> <ul> <li>\ud83d\udcd6 Konsultieren Sie die Troubleshooting-Sektion</li> <li>\ud83d\udc1b Melden Sie Bugs im GitHub Repository</li> <li>\ud83d\udcac Diskutieren Sie in der Community</li> <li>\ud83d\udce7 Kontaktieren Sie den Support f\u00fcr Enterprise-Kunden</li> </ul>"},{"location":"user-guide/authentication/","title":"Authentifizierung","text":"<p>Diese Seite wird noch entwickelt.</p>"},{"location":"user-guide/authentication/#ubersicht","title":"\u00dcbersicht","text":"<p>Das KEI-Agent SDK unterst\u00fctzt verschiedene Authentifizierungsmethoden.</p>"},{"location":"user-guide/authentication/#authentifizierungstypen","title":"Authentifizierungstypen","text":""},{"location":"user-guide/authentication/#bearer-token","title":"Bearer Token","text":"<pre><code>config = AgentClientConfig(\n    api_token=\"your-bearer-token\",\n    auth_type=AuthType.BEARER\n)\n</code></pre>"},{"location":"user-guide/authentication/#oidc-openid-connect","title":"OIDC (OpenID Connect)","text":"<pre><code>config = SecurityConfig(\n    auth_type=AuthType.OIDC,\n    oidc_issuer=\"https://your-oidc-provider.com\",\n    oidc_client_id=\"your-client-id\"\n)\n</code></pre>"},{"location":"user-guide/authentication/#mtls-mutual-tls","title":"mTLS (Mutual TLS)","text":"<pre><code>config = SecurityConfig(\n    auth_type=AuthType.MTLS,\n    mtls_cert_path=\"/path/to/client.crt\",\n    mtls_key_path=\"/path/to/client.key\"\n)\n</code></pre>"},{"location":"user-guide/authentication/#weitere-informationen","title":"Weitere Informationen","text":"<ul> <li>Basis-Konzepte</li> <li>Client-Verwendung</li> </ul>"},{"location":"user-guide/client-usage/","title":"Client-Verwendung","text":"<p>Diese Seite wird noch entwickelt.</p>"},{"location":"user-guide/client-usage/#ubersicht","title":"\u00dcbersicht","text":"<p>Hier finden Sie detaillierte Informationen zur Verwendung des UnifiedKeiAgentClient.</p>"},{"location":"user-guide/client-usage/#grundlegende-verwendung","title":"Grundlegende Verwendung","text":"<pre><code>from kei_agent import UnifiedKeiAgentClient, AgentClientConfig\n\n# Client konfigurieren\nconfig = AgentClientConfig(\n    base_url=\"https://your-kei-agent.com\",\n    api_token=\"your-api-token\",\n    agent_id=\"your-agent-id\"\n)\n\n# Client verwenden\nasync with UnifiedKeiAgentClient(config) as client:\n    result = await client.plan_task(\"Ihre Aufgabe\")\n    print(result)\n</code></pre>"},{"location":"user-guide/client-usage/#weitere-informationen","title":"Weitere Informationen","text":"<ul> <li>Basis-Konzepte</li> <li>Protokolle</li> <li>Authentifizierung</li> </ul>"},{"location":"user-guide/concepts/","title":"Basis-Konzepte","text":"<p>Dieses Kapitel erkl\u00e4rt die grundlegenden Konzepte des KEI-Agent Python SDK und des zugrunde liegenden KEI-Agent Framework.</p>"},{"location":"user-guide/concepts/#agent-architektur","title":"\ud83e\udd16 Agent-Architektur","text":""},{"location":"user-guide/concepts/#was-ist-ein-kei-agent","title":"Was ist ein KEI-Agent?","text":"<p>Ein KEI-Agent ist eine autonome Software-Einheit, die:</p> <ul> <li>Aufgaben planen und ausf\u00fchren kann</li> <li>Mit anderen Agents kommuniziert \u00fcber verschiedene Protokolle</li> <li>Kontextbewusst arbeitet und Entscheidungen trifft</li> <li>Tools und Services nutzen kann</li> <li>Sicherheitsrichtlinien befolgt</li> </ul>"},{"location":"user-guide/concepts/#agent-lebenszyklus","title":"Agent-Lebenszyklus","text":"<pre><code>graph TD\n    A[Agent Initialisierung] --&gt; B[Konfiguration laden]\n    B --&gt; C[Protokolle aktivieren]\n    C --&gt; D[Sicherheit einrichten]\n    D --&gt; E[Bereit f\u00fcr Operationen]\n    E --&gt; F[Task-Verarbeitung]\n    F --&gt; G[Agent-Kommunikation]\n    G --&gt; H[Tool-Verwendung]\n    H --&gt; E\n    E --&gt; I[Graceful Shutdown]</code></pre>"},{"location":"user-guide/concepts/#protokoll-typen","title":"\ud83d\udd0c Protokoll-Typen","text":"<p>Das KEI-Agent SDK unterst\u00fctzt vier Hauptprotokolle:</p>"},{"location":"user-guide/concepts/#1-rpc-remote-procedure-call","title":"1. RPC (Remote Procedure Call)","text":"<ul> <li>Synchrone Request-Response-Kommunikation</li> <li>Ideal f\u00fcr direkte Agent-Aufrufe</li> <li>HTTP-basiert mit JSON-Payloads</li> </ul> <pre><code># RPC-Beispiel\nresult = await client.plan_task(\"Analysiere Daten\")\n</code></pre>"},{"location":"user-guide/concepts/#2-stream-websocket","title":"2. Stream (WebSocket)","text":"<ul> <li>Bidirektionale Echtzeit-Kommunikation</li> <li>Ideal f\u00fcr kontinuierliche Datenstr\u00f6me</li> <li>WebSocket-basiert</li> </ul> <pre><code># Stream-Beispiel\nasync for message in client.start_streaming_session():\n    print(f\"Empfangen: {message}\")\n</code></pre>"},{"location":"user-guide/concepts/#3-bus-message-bus","title":"3. Bus (Message Bus)","text":"<ul> <li>Asynchrone Publish-Subscribe-Kommunikation</li> <li>Ideal f\u00fcr Event-basierte Architekturen</li> <li>Entkoppelte Agent-Kommunikation</li> </ul> <pre><code># Bus-Beispiel\nawait client.send_agent_message(\"target-agent\", \"task_request\", data)\n</code></pre>"},{"location":"user-guide/concepts/#4-mcp-model-context-protocol","title":"4. MCP (Model Context Protocol)","text":"<ul> <li>Tool-Discovery und -Verwendung</li> <li>Ideal f\u00fcr KI-Model-Integration</li> <li>Standardisierte Tool-Schnittstelle</li> </ul> <pre><code># MCP-Beispiel\ntools = await client.discover_available_tools()\nresult = await client.use_tool(\"calculator\", expression=\"2+2\")\n</code></pre>"},{"location":"user-guide/concepts/#sicherheitsmodell","title":"\ud83d\udd12 Sicherheitsmodell","text":""},{"location":"user-guide/concepts/#authentifizierung","title":"Authentifizierung","text":"<p>Das SDK unterst\u00fctzt drei Authentifizierungsmethoden:</p>"},{"location":"user-guide/concepts/#bearer-token","title":"Bearer Token","text":"<pre><code>config = AgentClientConfig(\n    api_token=\"your-bearer-token\",\n    auth_type=AuthType.BEARER\n)\n</code></pre>"},{"location":"user-guide/concepts/#oidc-openid-connect","title":"OIDC (OpenID Connect)","text":"<pre><code>config = SecurityConfig(\n    auth_type=AuthType.OIDC,\n    oidc_issuer=\"https://your-oidc-provider.com\",\n    oidc_client_id=\"your-client-id\",\n    oidc_client_secret=\"your-client-secret\"\n)\n</code></pre>"},{"location":"user-guide/concepts/#mtls-mutual-tls","title":"mTLS (Mutual TLS)","text":"<pre><code>config = SecurityConfig(\n    auth_type=AuthType.MTLS,\n    mtls_cert_path=\"/path/to/client.crt\",\n    mtls_key_path=\"/path/to/client.key\",\n    mtls_ca_path=\"/path/to/ca.crt\"\n)\n</code></pre>"},{"location":"user-guide/concepts/#autorisierung","title":"Autorisierung","text":"<ul> <li>RBAC (Role-Based Access Control)</li> <li>Audit-Logging f\u00fcr Compliance</li> <li>Token-Refresh f\u00fcr langlebige Sessions</li> </ul>"},{"location":"user-guide/concepts/#konfigurationsmanagement","title":"\u2699\ufe0f Konfigurationsmanagement","text":""},{"location":"user-guide/concepts/#hierarchische-konfiguration","title":"Hierarchische Konfiguration","text":"<pre><code># 1. Agent-Basis-Konfiguration\nagent_config = AgentClientConfig(\n    base_url=\"https://kei-agent.com\",\n    api_token=\"token\",\n    agent_id=\"my-agent\"\n)\n\n# 2. Protokoll-Konfiguration\nprotocol_config = ProtocolConfig(\n    rpc_enabled=True,\n    stream_enabled=True,\n    auto_protocol_selection=True\n)\n\n# 3. Sicherheits-Konfiguration\nsecurity_config = SecurityConfig(\n    auth_type=AuthType.BEARER,\n    rbac_enabled=True,\n    audit_enabled=True\n)\n\n# 4. Client erstellen\nclient = UnifiedKeiAgentClient(\n    config=agent_config,\n    protocol_config=protocol_config,\n    security_config=security_config\n)\n</code></pre>"},{"location":"user-guide/concepts/#umgebungsvariablen","title":"Umgebungsvariablen","text":"<pre><code># Basis-Konfiguration\nKEI_AGENT_BASE_URL=https://kei-agent.com\nKEI_AGENT_API_TOKEN=your-token\nKEI_AGENT_ID=my-agent\n\n# Protokoll-Einstellungen\nKEI_AGENT_RPC_ENABLED=true\nKEI_AGENT_STREAM_ENABLED=true\n\n# Sicherheit\nKEI_AGENT_AUTH_TYPE=bearer\nKEI_AGENT_RBAC_ENABLED=true\n</code></pre>"},{"location":"user-guide/concepts/#asynchrone-programmierung","title":"\ud83d\udd04 Asynchrone Programmierung","text":""},{"location":"user-guide/concepts/#asyncawait-pattern","title":"Async/Await Pattern","text":"<p>Das SDK ist vollst\u00e4ndig asynchron:</p> <pre><code>import asyncio\n\nasync def main():\n    async with UnifiedKeiAgentClient(config) as client:\n        # Alle Operationen sind async\n        result = await client.plan_task(\"Task\")\n\n        # Parallele Ausf\u00fchrung\n        tasks = [\n            client.plan_task(\"Task 1\"),\n            client.plan_task(\"Task 2\"),\n            client.plan_task(\"Task 3\")\n        ]\n        results = await asyncio.gather(*tasks)\n\n# Ausf\u00fchrung\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/concepts/#context-manager","title":"Context Manager","text":"<pre><code># Automatisches Resource-Management\nasync with UnifiedKeiAgentClient(config) as client:\n    # Client wird automatisch initialisiert\n    result = await client.plan_task(\"Task\")\n    # Client wird automatisch geschlossen\n</code></pre>"},{"location":"user-guide/concepts/#monitoring-und-observability","title":"\ud83d\udcca Monitoring und Observability","text":""},{"location":"user-guide/concepts/#structured-logging","title":"Structured Logging","text":"<pre><code>from kei_agent import get_logger\n\nlogger = get_logger(\"my-component\")\nlogger.info(\"Operation started\", extra={\n    \"operation\": \"plan_task\",\n    \"agent_id\": \"my-agent\",\n    \"correlation_id\": \"req-123\"\n})\n</code></pre>"},{"location":"user-guide/concepts/#health-checks","title":"Health Checks","text":"<pre><code>from kei_agent import get_health_manager\n\nhealth = get_health_manager()\nstatus = await health.check_health()\nprint(f\"System Health: {status}\")\n</code></pre>"},{"location":"user-guide/concepts/#tracing","title":"Tracing","text":"<pre><code># Automatisches Tracing f\u00fcr alle Operationen\nasync with client.trace_operation(\"complex-task\") as span:\n    result = await client.plan_task(\"Task\")\n    span.set_attribute(\"result_size\", len(result))\n</code></pre>"},{"location":"user-guide/concepts/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"user-guide/concepts/#1-konfiguration","title":"1. Konfiguration","text":"<ul> <li>Verwenden Sie Umgebungsvariablen f\u00fcr Deployment-spezifische Werte</li> <li>Nutzen Sie Type-Hints f\u00fcr bessere IDE-Unterst\u00fctzung</li> <li>Implementieren Sie Konfigurationsvalidierung</li> </ul>"},{"location":"user-guide/concepts/#2-fehlerbehandlung","title":"2. Fehlerbehandlung","text":"<ul> <li>Verwenden Sie spezifische Exception-Types</li> <li>Implementieren Sie Retry-Strategien</li> <li>Nutzen Sie Circuit Breaker f\u00fcr externe Services</li> </ul>"},{"location":"user-guide/concepts/#3-performance","title":"3. Performance","text":"<ul> <li>Verwenden Sie Connection Pooling</li> <li>Implementieren Sie Caching wo sinnvoll</li> <li>Nutzen Sie Batch-Operationen f\u00fcr mehrere Requests</li> </ul>"},{"location":"user-guide/concepts/#4-sicherheit","title":"4. Sicherheit","text":"<ul> <li>Rotieren Sie Tokens regelm\u00e4\u00dfig</li> <li>Verwenden Sie mTLS in produktiven Umgebungen</li> <li>Aktivieren Sie Audit-Logging</li> </ul>"},{"location":"user-guide/concepts/#nachste-schritte","title":"\ud83d\udd17 N\u00e4chste Schritte","text":"<ul> <li>Client-Verwendung - Praktische Anwendung</li> <li>Protokolle - Detaillierte Protokoll-Informationen</li> <li>Authentifizierung - Sicherheitsaspekte</li> <li>Beispiele - Praktische Beispiele</li> </ul>"},{"location":"user-guide/error-handling/","title":"Fehlerbehandlung","text":"<p>Diese Seite wird noch entwickelt.</p>"},{"location":"user-guide/error-handling/#ubersicht","title":"\u00dcbersicht","text":"<p>Robuste Fehlerbehandlung und Retry-Strategien im KEI-Agent SDK.</p>"},{"location":"user-guide/error-handling/#exception-hierarchie","title":"Exception-Hierarchie","text":"<pre><code>from kei_agent.exceptions import (\n    KeiSDKError,\n    ProtocolError,\n    SecurityError,\n    ValidationError\n)\n\ntry:\n    result = await client.plan_task(\"task\")\nexcept ProtocolError as e:\n    print(f\"Protokoll-Fehler: {e}\")\nexcept SecurityError as e:\n    print(f\"Sicherheits-Fehler: {e}\")\nexcept KeiSDKError as e:\n    print(f\"Allgemeiner SDK-Fehler: {e}\")\n</code></pre>"},{"location":"user-guide/error-handling/#retry-strategien","title":"Retry-Strategien","text":"<p>Das SDK bietet automatische Retry-Mechanismen f\u00fcr transiente Fehler.</p>"},{"location":"user-guide/error-handling/#weitere-informationen","title":"Weitere Informationen","text":"<ul> <li>Basis-Konzepte</li> <li>Client-Verwendung</li> </ul>"},{"location":"user-guide/protocols/","title":"Protokolle","text":"<p>Diese Seite wird noch entwickelt.</p>"},{"location":"user-guide/protocols/#ubersicht","title":"\u00dcbersicht","text":"<p>Das KEI-Agent SDK unterst\u00fctzt verschiedene Kommunikationsprotokolle:</p>"},{"location":"user-guide/protocols/#unterstutzte-protokolle","title":"Unterst\u00fctzte Protokolle","text":""},{"location":"user-guide/protocols/#rpc-remote-procedure-call","title":"RPC (Remote Procedure Call)","text":"<ul> <li>Synchrone Request-Response-Kommunikation</li> <li>HTTP-basiert</li> </ul>"},{"location":"user-guide/protocols/#stream-websocket","title":"Stream (WebSocket)","text":"<ul> <li>Bidirektionale Echtzeit-Kommunikation</li> <li>WebSocket-basiert</li> </ul>"},{"location":"user-guide/protocols/#bus-message-bus","title":"Bus (Message Bus)","text":"<ul> <li>Asynchrone Publish-Subscribe-Kommunikation</li> <li>Event-basierte Architektur</li> </ul>"},{"location":"user-guide/protocols/#mcp-model-context-protocol","title":"MCP (Model Context Protocol)","text":"<ul> <li>Tool-Discovery und -Verwendung</li> <li>KI-Model-Integration</li> </ul>"},{"location":"user-guide/protocols/#weitere-informationen","title":"Weitere Informationen","text":"<ul> <li>Basis-Konzepte</li> <li>Client-Verwendung</li> </ul>"}]}